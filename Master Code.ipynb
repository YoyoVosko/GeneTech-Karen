{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import graphviz;from graphviz import Digraph;import math;import multiprocessing\n",
    "import random;from joblib import Parallel, delayed;from collections import ChainMap;from matplotlib.patches import Patch\n",
    "num_cores = 5;import pandas as pd;import numpy as np\n",
    "import seaborn as sb;import matplotlib.pyplot as plt;import matplotlib as mpl;import glob;import os\n",
    "from matplotlib_venn import venn2;import gzip;import shutil;from tqdm import tqdm_notebook as tq;import warnings\n",
    "import scipy.stats as stats;import pdb;import gseapy as GSEA;import gc;import networkx as nx\n",
    "warnings.simplefilter('ignore');cmapSpecial = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"blue\",'white',\"red\"])\n",
    "cmapSpecial2 = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",'white',\"blue\"])\n",
    "cmapSpecial3 = mpl.colors.LinearSegmentedColormap.from_list(\"\", ['white',\"red\"])\n",
    "cmapSpecial4 = mpl.colors.LinearSegmentedColormap.from_list(\"\", [(0,'black'),(0.4999,'grey'),(0.5,\"blue\"),\n",
    "                                                                 (0.75,'white'),(1,\"red\")],N=256)\n",
    "__debug=False;mpl.rcParams['figure.dpi'] = 300;plt.rcParams[\"figure.facecolor\"] = \"w\";import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __removeLstFunc(lst,rmLst,isLst=False):\n",
    "    out=[]\n",
    "    if not(isLst):rmLst = [rmLst]\n",
    "    for i in lst:\n",
    "        if not(i in rmLst):out.append(i)\n",
    "    return out\n",
    "def readLst(file):\n",
    "    \"\"\"\n",
    "    readLst:\n",
    "        Input:\n",
    "            file, name of the file you want to get a list from\n",
    "        Actions: \n",
    "            Reads through the given file, turing each line into an element of a list\n",
    "        Returns: \n",
    "            List of the files contents\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    with open(file) as f:\n",
    "        for line in f:out += line.split()\n",
    "    return out\n",
    "def saveLst(lst,file):\n",
    "    \"\"\"\n",
    "    saveLst:\n",
    "        Input:\n",
    "            lst, a list\n",
    "            file, name of the file to create and save output to\n",
    "        Actions: \n",
    "            Each element in the given list, is saved as a line in the file \n",
    "        Returns: \n",
    "            The name of the created file\n",
    "    \"\"\"\n",
    "    with open(file,'w') as f:\n",
    "        for num in range(len(lst)-1):\n",
    "            elem = str(lst[num]);f.write(elem+'\\n')\n",
    "        elem = str(lst[len(lst)-1]);f.write(elem)\n",
    "    return file\n",
    "def __renameTPM(tpm,num=3,inplace=True):\n",
    "    if(inplace):df = tpm\n",
    "    else:df = tpm.copy()\n",
    "    colLst=[]\n",
    "    for col in df.columns:\n",
    "        col = '.'.join(col.split('.')[0:num])\n",
    "        if(col in colLst):col = col+'.1'\n",
    "        colLst.append(col)\n",
    "    df.columns=colLst;noDups=[]\n",
    "    for i in df.columns:\n",
    "        if not('.1' in i):noDups.append(i)\n",
    "    df = df[noDups]\n",
    "    return df\n",
    "def __renameLst(lst,num=3):\n",
    "    colLst=[]\n",
    "    for col in lst:\n",
    "        col = '.'.join(col.split('.')[0:num])\n",
    "        if(col in colLst):col = col+'.1'\n",
    "        colLst.append(col)\n",
    "    lst=colLst\n",
    "    return lst\n",
    "def __rmvTCGA(lst,num=2):\n",
    "    outLst=[]\n",
    "    for i in __renameLst(lst):\n",
    "        j = '.'.join(i.split('.')[0:num]);k = i.split('.')[num];k = k.replace('TCGA','');j += '.'+k;outLst.append(j)\n",
    "    return outLst\n",
    "def __repeatAppend(lst,num,elem):\n",
    "    for i in range(num):lst.append(elem)\n",
    "    return lst\n",
    "def __colDataFunc(hot,cold,hotName='Hot',coldName='Cold',groupName='Group'):\n",
    "    names=[];colData=[]\n",
    "    for i in hot:\n",
    "        if not(i in names):\n",
    "            names.append(i);colData.append(hotName)\n",
    "    for i in cold:\n",
    "        if not(i in names):\n",
    "            names.append(i);colData.append(coldName)\n",
    "    test = pd.DataFrame(colData,names,columns=[groupName])\n",
    "    return test\n",
    "\n",
    "__kobePathways = pd.read_excel('Genelist_desert.xlsx',index_col=1);__msigDict={};__msigDict['T-effector'] = []\n",
    "__msigDict['IFNG induced'] = ['HALLMARK_INTERFERON_GAMMA_RESPONSE','BIOCARTA_IFNG_PATHWAY','PID_IFNG_PATHWAY',\n",
    "                            'REACTOME_REGULATION_OF_IFNG_SIGNALING']\n",
    "__msigDict['Antigen processing machinery'] = ['KEGG_ANTIGEN_PROCESSING_AND_PRESENTATION',\n",
    "                                            'REACTOME_ANTIGEN_PROCESSING_CROSS_PRESENTATION']\n",
    "__msigDict['GABA'] = ['BIOCARTA_GABA_PATHWAY','REACTOME_GABA_RECEPTOR_ACTIVATION']\n",
    "__msigDict['Wnt'] = ['HALLMARK_WNT_BETA_CATENIN_SIGNALING','BIOCARTA_WNT_PATHWAY','KEGG_WNT_SIGNALING_PATHWAY',\n",
    "                   'PID_WNT_SIGNALING_PATHWAY','REACTOME_SIGNALING_BY_WNT_IN_CANCER']\n",
    "__msigDict['Fatty acid'] = ['HALLMARK_FATTY_ACID_METABOLISM','KEGG_FATTY_ACID_METABOLISM','REACTOME_FATTY_ACYL_COA_BIOSYNTHESIS']\n",
    "__msigDict['Cholesterol synthesis'] = ['HALLMARK_CHOLESTEROL_HOMEOSTASIS','REACTOME_CHOLESTEROL_BIOSYNTHESIS']\n",
    "__msigDict['PI3K/AKT'] = ['HALLMARK_PI3K_AKT_MTOR_SIGNALING','BIOCARTA_AKT_PATHWAY','PID_PI3KCI_AKT_PATHWAY',\n",
    "                        'REACTOME_PI3K_AKT_SIGNALING_IN_CANCER']\n",
    "__msigDict['MTOR'] = ['HALLMARK_MTORC1_SIGNALING','BIOCARTA_MTOR_PATHWAY','KEGG_MTOR_SIGNALING_PATHWAY','PID_MTOR_4PATHWAY',\n",
    "                   'REACTOME_MTOR_SIGNALLING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests;__tpyDict={}\n",
    "for __path in __msigDict:\n",
    "    __pathLst = __msigDict[__path];__tpyLst=[]\n",
    "    for __name in __pathLst:\n",
    "        __tpy = __name.split('_')[0]\n",
    "        __url='https://www.gsea-msigdb.org/gsea/msigdb/download_geneset.jsp?geneSetName='+__name+'&fileType=txt'\n",
    "        __r = requests.get(__url);__test = str(__r.content);__test = __test.split('\\\\n')[2:]\n",
    "        __test[len(__test)-1] = __test[len(__test)-1].replace(\"'\",\"\");__tpyLst.append((__tpy,__test))\n",
    "    __kobeLst = list(__kobePathways.loc[__path]['genes']);__tpyLst.append(('KOBE',__kobeLst));__tpyDict[__path] = __tpyLst\n",
    "overAllDict={}\n",
    "for __path in __tpyDict:\n",
    "    __pathDict={};__pathLst = __tpyDict[__path];__hallLst=[];__bioLst=[];__keggLst=[];__reactLst=[];__pidLst=[];__kobeLst=[]\n",
    "    for __group in __pathLst:\n",
    "        __name = __group[0];__lst = __group[1]\n",
    "        if(__name == 'HALLMARK'):__hallLst += __lst\n",
    "        if(__name == 'BIOCARTA'):__bioLst += __lst\n",
    "        if(__name == 'KEGG'):__keggLst += __lst\n",
    "        if(__name == 'REACTOME'):__reactLst += __lst\n",
    "        if(__name =='PID'):__pidLst += __lst\n",
    "        if(__name =='KOBE'):__kobeLst += __lst\n",
    "    __pathDict['HALLMARK'] = __hallLst\n",
    "    if(__path =='PI3K/AKT'):__path = 'PI3K-AKT'\n",
    "    __pathDict['KEGG'] = __keggLst;__pathDict['REACTOME'] = __reactLst;__pathDict['KOBE'] = __kobeLst\n",
    "    overAllDict[__path] = __pathDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __runGenes(dic):\n",
    "    out=[];final=[]\n",
    "    for path in dic:\n",
    "        lst = dic[path];out += lst\n",
    "    for gene in out:\n",
    "        if not(gene in final):final.append(gene)\n",
    "    return final\n",
    "def __getPaths(lst,dic,path):\n",
    "    __pathLst = dic[path];heatLst=[]\n",
    "    for gene in lst:\n",
    "        if(gene in __pathLst):heatLst.append('Hot')\n",
    "        else:heatLst.append('Cold')\n",
    "    df=pd.DataFrame(heatLst,lst,columns=['Group'])\n",
    "    return df\n",
    "def __getRowColors(path,color,col='Group'):\n",
    "    row_palette = dict(zip(['Hot','Cold'], [color,\"white\"]));row_colors = path[col].map(row_palette)\n",
    "    return row_colors\n",
    "# __goodGenes: takes 2 lists and outputs all elements they have in common\n",
    "def __goodGenes(lst1,lst2):\n",
    "    out = [value for value in lst1 if value in lst2] \n",
    "    return out\n",
    "\n",
    "def __reOrderLst(genes,path):\n",
    "    reOrder = readLst('ClusterOrder/'+path+'RowCorrelationReorder.txt');orderLst=[];length = len(genes)\n",
    "    for idx in reOrder:\n",
    "        idx = int(idx)\n",
    "        if(idx < length):\n",
    "            g = genes[idx];orderLst.append(g)\n",
    "    return orderLst\n",
    "def __numCompare(gene,df,compare,num=0.35):\n",
    "    x = 0\n",
    "    for g in df.columns:\n",
    "        value = df.loc[gene][g]\n",
    "        if(compare=='Up'):\n",
    "            if(value > num):x += 1\n",
    "        if(compare=='Down'):\n",
    "            if(value < num):x += 1\n",
    "    return x\n",
    "def __getPurityLst(cor,threshold,compare='Up',num=0.35,percent=False):\n",
    "    outLst=[]\n",
    "    for g in cor.index:\n",
    "        numAbove = __numCompare(g,cor,compare,num)\n",
    "        if(percent):\n",
    "            if not(len(cor.index)==0):numAbove = numAbove/len(cor.index)\n",
    "            else:numAbove = 0\n",
    "        if(numAbove > threshold):outLst.append(g)\n",
    "    return outLst\n",
    "def clusterHeatMap(out,colData,path,title='',clusterRow=True,clusterCol=True,show=True,vmin=-1,vmax=1):\n",
    "    genes = out.index;HallColors = __getRowColors(__getPaths(genes,overAllDict[path],'HALLMARK'),'orange')\n",
    "    KeggColors = __getRowColors(__getPaths(genes,overAllDict[path],'KEGG'),'blue')\n",
    "    ReactomeColors = __getRowColors(__getPaths(genes,overAllDict[path],'REACTOME'),'green')\n",
    "    BiocartaColors = __getRowColors(__getPaths(genes,overAllDict[path],'BIOCARTA'),'purple')\n",
    "    PidColors = __getRowColors(__getPaths(genes,overAllDict[path],'PID'),'red')\n",
    "    KobeColors = __getRowColors(__getPaths(genes,overAllDict[path],'KOBE'),'black')\n",
    "    row_colors=[HallColors,KeggColors,ReactomeColors,BiocartaColors,PidColors,KobeColors]\n",
    "    if(colData is not None):\n",
    "        col_palette = dict(zip(colData.Group.unique(), [\"Red\",\"Blue\",'White'])) ;col_colors1 = colData.Group.map(col_palette)\n",
    "    else:\n",
    "        col_colors1 = None\n",
    "    cg = sb.clustermap(out,cmap=cmapSpecial,row_cluster=clusterRow,standard_scale=None,col_cluster=clusterCol,\n",
    "                       row_colors=row_colors,col_colors=col_colors1,vmin=vmin,vmax=vmax,yticklabels=1,xticklabels=1)\n",
    "    c = ['orange','blue','green','purple','red','black']\n",
    "    for x,y in zip([\"Hallmark\", \"KEGG\", \"Reactome\", \"Biocarta\", \"Pid\", \"Kobe\"], c):\n",
    "        cg.ax_heatmap.plot(0, 0, color=y, label=x, linewidth=10, solid_capstyle=\"butt\")\n",
    "    cg.ax_heatmap.legend(loc=(0,1), title=\"Gene List\")\n",
    "    if(show):\n",
    "        plt.title(title);plt.show();print(title);return title\n",
    "    else:return row\n",
    "def __pureLst(df):\n",
    "    purity = pd.read_csv('TCGA_Purity_Ploidy.txt',index_col=0,sep='\\t');sampleLst=[];pureL=[]\n",
    "    for i in df.columns:\n",
    "        if(i in purity.index):\n",
    "            sampleLst.append(i);pure = purity.loc[i]['purity'];pureL.append(pure)\n",
    "    return sampleLst, pureL\n",
    "def __pureDf(dfIn,zscore=False):\n",
    "    df = dfIn.copy();__renameTPM(df);sampleLst,pLst = __pureLst(df)\n",
    "    if(zscore):pLst = list(stats.zscore(pLst))\n",
    "    df2 = df[sampleLst];just__pureDf = pd.DataFrame([pLst],['Purity Scores'], columns=sampleLst)\n",
    "    pDf = just__pureDf.append(df2);pDf.index.name = 'Genes';return pDf\n",
    "def __withinThres(y,threshold=1):\n",
    "    num = 0;total = len(y)\n",
    "    for val in y:\n",
    "        absVal = abs(val)\n",
    "        if(absVal<=threshold):num += 1\n",
    "    percent = num/total;return percent\n",
    "def __skinyGene(gene,threshold=1,skinyPercent=0.9):\n",
    "    percent = __withinThres(gene,threshold)\n",
    "    if(percent >= skinyPercent):return True\n",
    "    return False\n",
    "def __PurityCorrection(df,save=False,fileName='',place='',correctNeg=False,thres=1,\n",
    "                       percent=0.9,skiny=False,shiftZeros=False,scale=0.2):\n",
    "    pDf = __pureDf(df);pDf.dropna(inplace=True);out = pd.DataFrame();x = pDf.loc['Purity Scores'];x2 = x.copy()\n",
    "    for gene in tq(pDf.index,desc='Correcting Genes for '+place):\n",
    "        if (not gene=='Purity Scores'):\n",
    "            y = pDf.loc[gene];y2 = y.copy()\n",
    "            if(shiftZeros):\n",
    "                minArea = y.min() + 0.4;y2 = y[y > minArea];x2 = x[y2.index];y3 = y[y <= minArea];maxZero = y3.max()\n",
    "            residual = y.copy()\n",
    "            if(not __skinyGene(y,thres,percent)):\n",
    "                try:m, b = np.polyfit(x2, y2, 1)\n",
    "                except:m, b = np.polyfit(x2, y2, 1)\n",
    "                if(m>0 or correctNeg):\n",
    "                    regLine = m*x + b;residual = y - regLine\n",
    "                    if(shiftZeros):\n",
    "                        y2Res = residual.loc[y2.index];curVal = y2Res.min();lst=[]\n",
    "                        for i in y.index:\n",
    "                            if(i in y2.index):lst.append(residual[i])\n",
    "                            else:\n",
    "                                dif = abs(maxZero-y3[i]);newVal=dif*scale;newVal=curVal-newVal;lst.append(newVal)\n",
    "                        data = np.array(lst);residual = pd.Series(data, index = y.index)\n",
    "            out[gene] = residual\n",
    "    out.index=pDf.columns;out = out.T\n",
    "    if(save):out.to_csv(fileName+'_tpm.tsv',sep='\\t')\n",
    "    return out\n",
    "def masterPurityCorrection(placeLst,skipLst=[],save=True,correctNeg=False,onlyDict=False,dictIn={},\n",
    "                           correctSkinny=False,fixOut=True,thres=1,percent=0.9,shiftZeros=True,scale=0.2):\n",
    "    \"\"\"masterPurityCorrection:\n",
    "                                Input:\n",
    "                                    placeLst, a list of cancer areas to correct\n",
    "                                        no default\n",
    "                                    skipLst, a list of cancer areas that are already corrected and can be skipped,\n",
    "                                             though they arn't skiped in sparse removal\n",
    "                                        defualt = []\n",
    "                                    save, boolean telling if to save the data (True) or not (False, but its a big waste of time for nothing)\n",
    "                                        default = True\n",
    "                                    correctNeg, boolean telling if to correct genes negatively correlated with purity (True)\n",
    "                                                or leave them as is (False)\n",
    "                                        default = False\n",
    "                                    correctSkinny, boolean telling if to correct low variance genes, based on thres and percent (True)\n",
    "                                                   or leave them as is (False)\n",
    "                                        default = False\n",
    "                                    fixOut, boolean telling if to correct outliers (True)\n",
    "                                            or leave them as is (False)\n",
    "                                        default = False\n",
    "                                    thres, float telling the STD threshold a certain number (defined by percent) that a gene's samples\n",
    "                                           must be below to be considered \"skinny\"/low variance\n",
    "                                        default = 1\n",
    "                                    percent, float between 0 and 1 telling the percentage of a gene's samples that need to be \n",
    "                                             below a certain STD value (defned by thres) in order to be considered \"skinny\"/low variance\n",
    "                                        default = 0.9\n",
    "                                Actions:\n",
    "                                        1) Removes Sparse genes from all data\n",
    "                                        2) Corrects the given cancer areas data to be post-purity (eliminating correlation with purity)\n",
    "                                           with the correction being based on the parameters given\n",
    "                                        3) For each cancer area, saves the newly corrected data in the folder matching the correction type\n",
    "                                Returns:\n",
    "                                        On success return 1\n",
    "    \"\"\"\n",
    "    for place in tq(placeLst,desc='Overall'):\n",
    "        if not(place in skipLst):\n",
    "            if(fixOut):prePure = pd.read_csv('Purity/TPM/Outliers Fixed/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "            else:\n",
    "                prePure = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "                __renameTPM(prePure);prePure = np.log2(prePure+1);prePure = __removeBadPlace(prePure)\n",
    "                prePure = pd.DataFrame(stats.zscore(prePure,axis=1),prePure.index,columns=prePure.columns)\n",
    "            if(onlyDict):\n",
    "                lst = __getSuperLst(dictIn);lst = __goodGenes(lst,prePure.index);prePure = prePure.loc[lst]\n",
    "            if(len(prePure.columns)>0):\n",
    "                if not(correctNeg):fileName='Purity/TPM/v1/TCGA_'+place\n",
    "                else:\n",
    "                    if not(correctSkinny):\n",
    "                        if(fixOut):\n",
    "                            if(shiftZeros):fileName='Purity/TPM/v7/TCGA_'+place\n",
    "                            else:fileName='Purity/TPM/v8/TCGA_'+place\n",
    "                        else:fileName='Purity/TPM/v2/TCGA_'+place\n",
    "                    else:\n",
    "                        if(fixOut):\n",
    "                            if(shiftZeros):fileName='Purity/TPM/v7.2/TCGA_'+place\n",
    "                            else:fileName='Purity/TPM/v8.2/TCGA_'+place\n",
    "                        else:fileName='Purity/TPM/v3/TCGA_'+place\n",
    "                out = __PurityCorrection(prePure,save=save,place=place,fileName=fileName,\n",
    "                                         correctNeg=correctNeg,thres=thres,percent=percent,\n",
    "                                         skiny=correctSkinny,shiftZeros=shiftZeros,scale=scale)\n",
    "    return 1\n",
    "def __removeSparse(placeLst,percentThres=0.1,samThres=3):\n",
    "    dfLst=[]\n",
    "    for place in placeLst:\n",
    "        prePure = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "        __renameTPM(prePure);dfLst.append(prePure)\n",
    "    bad=[]\n",
    "    for gene in tq(dfLst[0].index,desc='Sparse Genes'):\n",
    "        samNum=0\n",
    "        for df in dfLst:\n",
    "            zeros = list(df.loc[gene].values).count(0);sams = len(df.columns);div = zeros/sams;div = 1 - div\n",
    "            if(div>percentThres):samNum +=1\n",
    "            if(samNum > samThres):break\n",
    "        if(samNum <= samThres):bad.append(gene)\n",
    "    return bad\n",
    "def __renamePathCards(name):\n",
    "    if not(name =='Immune Response CCR3 Signaling in Eosinophils'):\n",
    "        name = name.lower();name = name.replace(' ','_');name = name.replace(':','');name= name.replace(',','')\n",
    "        name = name.replace('/','');name = name.replace('.','')\n",
    "    else:name = 'immune_response__ccr3_signaling_in_eosinophils'\n",
    "    return name\n",
    "\n",
    "def __getPathCards(nameIn):\n",
    "    import requests;name = __renamePathCards(nameIn);url='https://pathcards.genecards.org/Card/'+name\n",
    "    r = requests.get(url);test = str(r.content);test = test.split('<table class=\"table\">\\\\r\\\\n')[2];lst=[]\n",
    "    for i in range(len(test.split('</a>\\\\r\\\\n'))-2):lst.append(test.split('</a>\\\\r\\\\n')[i].split('>')[-1])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "__pcDict={};__pcDict['T-effector'] = 'T cell receptor signaling pathway'\n",
    "__pcDict['IFNG induced'] = 'Type II interferon signaling (IFNG)'\n",
    "__pcDict['Antigen processing machinery'] = 'Antigen processing-Cross presentation'\n",
    "__pcDict['GABA'] = 'GABA receptor activation';__pcDict['Wnt'] = 'WNT Signaling'\n",
    "__pcDict['Fatty acid'] = 'Fatty Acyl-CoA Biosynthesis'\n",
    "__pcDict['Cholesterol synthesis'] = 'cholesterol biosynthesis III (via desmosterol)'\n",
    "__pcDict['PI3K-AKT'] = 'PI3K / Akt Signaling';__pcDict['MTOR'] = 'mTOR signalling';pathCardsDict={}\n",
    "for path in __pcDict:\n",
    "    __card = __pcDict[path];__lst = __getPathCards(__card);pathCardsDict[path] = __lst\n",
    "everyDict={}\n",
    "for path in overAllDict:\n",
    "    pathDict = overAllDict[path].copy();pathCardsLst = pathCardsDict[path]\n",
    "    pathDict['Path Cards'] = pathCardsLst;everyDict[path] = pathDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterLst=['IFNg','WNT Signaling','Antigen presentation','GABA','Cholesterol','Fatty Acid','T-effector','PI3K-AKT-mTOR']\n",
    "def setupGSEA(placeLst,DictIn,removeBad=False,purity=True,correctNeg=True,directory='GSEA Input/',title='',preRank=False,\n",
    "               dbs=False,skipSets=False,skipExpres=False,shiftZeros=True,HvC=True,skipImmune=False,useEveryDict=True):\n",
    "    \"\"\"setupGSEA:\n",
    "                Input:\n",
    "                    placeLst, a list of the cancer areas you wish to use, \n",
    "                        no default\n",
    "                    Dict, a dictionary with the paths you want you want to use for your gene sets\n",
    "                          and the genes within each set\n",
    "                        no defualt\n",
    "                    removeBad, boolean telling if you want to remove 'bad' genes (True) \n",
    "                               based on their correlation to other genes in a path, or keep them in (False) \n",
    "                        default = False\n",
    "                    puriy, a boolean telling if you want to use pre (False) or post (True) purity values\n",
    "                        default = True\n",
    "                    correctAll, boolean telling if you want to have\n",
    "                                genes negativly correlated with purity corrected or not\n",
    "                        default = True\n",
    "                    directory, the directory in which you want the files saved, \n",
    "                               each cancer area will be saved within its own folder within this directory\n",
    "                        default = 'GSEA Input/'\n",
    "                    dbs, boolean telling if to create seperate gene sets for each database (True),\n",
    "                         or one superList (False)\n",
    "                        default = False\n",
    "                    HvC, boolean telling if to order gsea output as Hot vs Cold (True) or Cold vs Hot (False)\n",
    "                        default = True\n",
    "                    skipImmune, boolean telling if to skip immune pathways (True) or include them in the gene sets (False)\n",
    "                        deafult = False\n",
    "                Action:\n",
    "                    Saves a geneSet file, \n",
    "                          as well as geneExpression and PhenotypeLabels files for each cancer area.\n",
    "                          In the given directory. \n",
    "                    All of which can be used as input into GSEA\n",
    "                Ouput:\n",
    "                    The name of the directory in which all those files are saved.\"\"\"\n",
    "    Dict = DictIn.copy()\n",
    "    if not(skipSets):\n",
    "        if(dbs and useEveryDict):\n",
    "            frstDic = list(Dict.keys())[0];dbLst=[]\n",
    "            for db in Dict[frstDic]:dbLst.append(db)\n",
    "            for db in dbLst:\n",
    "                dbDict = __getDBList(Dict,db)\n",
    "                __GSEAGeneSet(dbDict,placeLst,removeBad,Setname=db+'_GeneSet',skipImmune=skipImmune)\n",
    "        else:\n",
    "            if useEveryDict:name = 'SuperLst_GeneSet'\n",
    "            else:name = 'MSigDB'+title+'_GeneSet'\n",
    "            __GSEAGeneSet(Dict,placeLst,removeBad,Setname=name,skipImmune=skipImmune,useEveryDict=useEveryDict)\n",
    "    if preRank:__GSEAPreRank(placeLst,purity,correctNeg,shiftZeros,setName=title)\n",
    "    if not(skipExpres):\n",
    "        outDict = __GSEAGeneExpression(placeLst,purity,correctNeg=correctNeg,directory=directory,shiftZeros=shiftZeros,HvC=HvC)\n",
    "        __GSEAPhenLabels(placeLst,outDict,directory,purity,HvC=HvC)\n",
    "    return directory\n",
    "\n",
    "def __GSEAPreRank(placeLst,purity,correctNeg,shiftZeros,setName=''):\n",
    "    out = 'GSEA Input/Ranks'\n",
    "    if not os.path.exists(out):os.makedirs(out)\n",
    "    candLst=['CD8A','GZMA','GZMB','PRF1']\n",
    "    for place in tq(placeLst,desc='Making Rnk Files'):\n",
    "        if(purity):\n",
    "            if(correctNeg):\n",
    "                if(shiftZeros):fileName = 'Purity/TPM/v7/TCGA_'+place+'_tpm.tsv'\n",
    "                else:fileName = 'Purity/TPM/v8/TCGA_'+place+'_tpm.tsv'\n",
    "            else:fileName = 'Purity/TPM/v1/TCGA_'+place+'_tpm.tsv'\n",
    "            df = pd.read_csv(fileName,index_col=0,sep='\\t');heat=df.loc[candLst].mean();df=df.T\n",
    "            pear=df.corrwith(heat,method='pearson');spear=df.corrwith(heat,method='spearman')\n",
    "            corr = (pear+spear)/2;out2 = out+'/'+place\n",
    "            if not os.path.exists(out2):os.makedirs(out2)\n",
    "            out2 = out2+'/'+setName+'.rnk'\n",
    "            with open(out2,'w') as f:\n",
    "                for g in corr.index:\n",
    "                    num=round(corr[g],3);f.write(g+'\\t'+str(num)+'\\n')\n",
    "            f.close()\n",
    "    return 1\n",
    "def __GSEAGeneSet(Dict,placeLst,removeBad=False,Setname='',skipImmune=False,useEveryDict=True):\n",
    "    if removeBad:placeLst2 = placeLst.copy()\n",
    "    else:placeLst2=[placeLst[0]]\n",
    "    for place in placeLst2:\n",
    "        geneSet=pd.Series()\n",
    "        for path in Dict:\n",
    "            forward=True\n",
    "            if(skipImmune):\n",
    "                immuneLst=['T-effector','IFNG induced','Antigen processing machinery']\n",
    "                if path in immuneLst:forward=False\n",
    "            if(forward):\n",
    "                pathGSEA = Dict[path]\n",
    "                if useEveryDict:pathGSEA = __runGenes(pathGSEA)\n",
    "                if(removeBad):\n",
    "                    prePure = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "                    goodPathGSEA = __goodGenes(pathGSEA,prePure.index)\n",
    "                    cor = prePure.loc[goodPathGSEA].T.corr(method='spearman')\n",
    "                    badLst = __getPurityLst(cor,0.5,'Down',0,percent=True)\n",
    "                    pathGSEA = __removeLstFunc(pathGSEA,badLst,True)\n",
    "                signature=pathGSEA;signature.insert(0,'na');geneSet[path]=signature\n",
    "    out = 'GSEA Input/GeneSets'\n",
    "    if not os.path.exists(out):os.makedirs(out)\n",
    "    out = out+'/'+Setname+'.gmt'\n",
    "    with open(out,'w') as f:\n",
    "        for clus in geneSet.index:\n",
    "            f.write(clus+'\\t')\n",
    "            for i in geneSet[clus]:f.write(i+'\\t')\n",
    "            f.write('\\n')\n",
    "    f.close();return Setname\n",
    "\n",
    "def __GSEAGeneExpression(placeLst,purity=True,correctNeg=True,directory='GSEA Input/',\n",
    "                         shiftZeros=True,name='GeneExpression',HvC=True):\n",
    "    outDict={}\n",
    "    for place in tq(placeLst,desc='GSEA Gene Expression'):\n",
    "        fileName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "        df = pd.read_csv(fileName,index_col=0,sep='\\t');__renameTPM(df);Hot,Cold = __getHotCold(df)\n",
    "        if(purity):\n",
    "            if(correctNeg):\n",
    "                if(shiftZeros):fileName = 'Purity/TPM/v7/TCGA_'+place+'_tpm.tsv'\n",
    "                else:fileName = 'Purity/TPM/v8/TCGA_'+place+'_tpm.tsv'\n",
    "            else:fileName = 'Purity/TPM/v1/TCGA_'+place+'_tpm.tsv'\n",
    "            df = pd.read_csv(fileName,index_col=0,sep='\\t');name = 'GeneExpression'+'PostPurity'\n",
    "        else:name = 'GeneExpression'+'PrePurity'\n",
    "        __renameTPM(df);__renameTPM(Hot);__renameTPM(Cold);df.dropna(inplace=True)\n",
    "        Hot = __goodGenes(Hot.columns,df.columns);Cold = __goodGenes(Cold.columns,df.columns)\n",
    "        if(HvC):colData = __colDataFunc(Hot,Cold)\n",
    "        else:colData = __colDataFunc(Cold,Hot,hotName='Cold',coldName='Hot')\n",
    "        rmvLst=[];noDups = __noDupsLst(colData.index);colData = colData.loc[noDups]\n",
    "        df = df[noDups];df.insert(0,'Description','na');df = df.rename_axis('Name',axis=0);out=directory+place\n",
    "        if not os.path.exists(out):os.makedirs(out)\n",
    "        if(purity):out = out+'/'+'PostPurity'\n",
    "        else:out = out+'/'+'PrePurity'\n",
    "        if not os.path.exists(out):os.makedirs(out)\n",
    "        df.to_csv(out+'/'+place+name+'.txt',sep='\\t');outDict[place] = (colData)\n",
    "    return outDict\n",
    "def __GSEAPhenLabels(placeLst,outDict,directory='GSEA Input/',purity=True,HvC=True):\n",
    "    for place in placeLst:\n",
    "        colData = outDict[place];length = len(colData.index)\n",
    "        qHot = colData[colData['Group'] == 'Hot'].index;qCold = colData[colData['Group'] == 'Cold'].index\n",
    "        hots = __repeatStr('Hot',len(qHot),'\\t');colds = __repeatStr('Cold',len(qCold),'\\t');out = directory+'/'+place\n",
    "        if not os.path.exists(out):os.makedirs(out)\n",
    "        if(purity):out = out+'/'+'PostPurity'\n",
    "        else:out = out+'/'+'PrePurity'\n",
    "        if not os.path.exists(out):os.makedirs(out)\n",
    "        name = out+'/'+place+'PrePurity'\n",
    "        if(purity):name = out+'/'+place+'PostPurity'\n",
    "        with open(name+'PhenotypeLabels.cls','w') as f:\n",
    "            f.write(str(length)+'\\t2\\t1\\n')\n",
    "            if(HvC):\n",
    "                f.write('#\\tHot\\tCold\\n');f.write(hots+'\\t'+colds)\n",
    "            else:\n",
    "                f.write('#\\tCold\\tHot\\n');f.write(colds+'\\t'+hots)\n",
    "        f.close()\n",
    "    return directory\n",
    "def __repeatStr(string,num,sep):\n",
    "    out=''\n",
    "    for i in range(num-1):\n",
    "        out += string;out += sep\n",
    "    out += string;return out\n",
    "def __getHotCold(df,perList=['25','75'],candLst=['CD8A','GZMA','GZMB','PRF1'],extra=''):\n",
    "    percents={};candLst = __goodGenes(candLst,df.index);length = len(candLst)\n",
    "    for i in candLst:\n",
    "        x = np.quantile(df.loc[i],[0.25,0.75]);percents[i] = x\n",
    "        df2 = df.loc[i];df2 = df2.transpose();df2 = df2[df2 <= percents[i][0]];df2.to_csv(extra+i+' 25Percentile')\n",
    "        df2 = df.loc[i];df2 = df2.transpose();df2 = df2[df2 >= percents[i][1]];df2.to_csv(extra+i+' 75Percentile')\n",
    "    for per in perList:\n",
    "        candSamples=[]\n",
    "        if(length > 0):\n",
    "            g0 = pd.read_csv(extra+candLst[0]+' '+per+'Percentile',index_col=0);g0 = list(g0.index);candSamples = g0\n",
    "        if(length > 1):\n",
    "            g1 = pd.read_csv(extra+candLst[1]+' '+per+'Percentile',index_col=0);g1 = list(g1.index);candSamples = g0+g1\n",
    "        if(length > 2):\n",
    "            g2 = pd.read_csv(extra+candLst[2]+' '+per+'Percentile',index_col=0);g2 = list(g2.index);candSamples = g0+g1+g2\n",
    "        if(length > 3):\n",
    "            g3 = pd.read_csv(extra+candLst[3]+' '+per+'Percentile',index_col=0);g3 = list(g3.index);candSamples = g0+g1+g2+g3\n",
    "        candSamples = __rmvTCGA(candSamples);candSamples = __goodGenes(candSamples,df.columns)\n",
    "        if(per=='75'):dfHot = df[candSamples]\n",
    "        if(per=='25'):dfCold = df[candSamples]\n",
    "    for j in candLst:\n",
    "        os.remove(extra+j+' 25Percentile');os.remove(extra+j+' 75Percentile')\n",
    "    return dfHot,dfCold\n",
    "\n",
    "def __onlyGroup(Dict,group):\n",
    "    outDict={}\n",
    "    for path in Dict:\n",
    "        dict2 = Dict[path];grpDict={}\n",
    "        for grp in dict2:\n",
    "            if(grp == group):\n",
    "                lst = dict2[grp];grpDict[grp] = lst\n",
    "        outDict[path] = grpDict\n",
    "    return outDict\n",
    "def __notHotOrCold(df,hot,cold):\n",
    "    notLst=[]\n",
    "    for col in df.columns:\n",
    "        if(col not in hot.columns and col not in cold.columns):notLst.append(col)\n",
    "    out = df[notLst]\n",
    "    return out\n",
    "\n",
    "def __getDBList(Dict,db):\n",
    "    outDict={}\n",
    "    for path in Dict:\n",
    "        outDictPath={};pathDict=Dict[path];dbLst=pathDict[db];outDictPath[db]=dbLst;outDict[path]=outDictPath\n",
    "    return outDict\n",
    "def __geneSetLst(placeLst,Setname,frst=True):\n",
    "    if(frst):placeLst=[placeLst[0]]\n",
    "    for palce in placeLst:\n",
    "        directory = 'GSEA Input/GeneSets';read = directory+'/'+place+Setname+'.gmt'\n",
    "        df = pd.read_csv(read,index_col=0,sep='\\t', names=list(range(500))).dropna(axis='columns', how='all')\n",
    "    return df\n",
    "def __getBads(geneLst,badLst):\n",
    "    heatLst=[]\n",
    "    for gene in geneLst:\n",
    "        if(gene in badLst):heatLst.append('Hot')\n",
    "        else:heatLst.append('Cold')\n",
    "    df=pd.DataFrame(heatLst,geneLst,columns=['Removed'])\n",
    "    return df\n",
    "\n",
    "def __fixCor(df,path,rowPosition,colPosition=[]):\n",
    "    geneOrder = rowPosition[path];genes = __goodGenes(geneOrder,df.index)\n",
    "    if(colPosition == []):df2 = df.loc[genes][genes]\n",
    "    else:\n",
    "        colOrder =colPosition[path];cols = __goodGenes(colOrder,df.columns);df2 = df.loc[genes][cols]\n",
    "    return df2\n",
    "def __getClusterPosition(df,more=False):\n",
    "    cg = sb.clustermap(df);row = cg.dendrogram_row.reordered_ind;col = cg.dendrogram_col.reordered_ind\n",
    "    if(more):\n",
    "        dfIndx = df.index;geneOrder=[]\n",
    "        for num in row:\n",
    "            gene = dfIndx[num];geneOrder.append(gene)\n",
    "        dfIndx = df.columns;geneOrder2=[]\n",
    "        for num in col:\n",
    "            gene = dfIndx[num];geneOrder2.append(gene)\n",
    "        return geneOrder,geneOrder2\n",
    "    return col, row\n",
    "\n",
    "def __logFoldChange(placeLst,mean=True,ttest=True,correctAll=False):\n",
    "    maxPlace = __maxLenPlace(placeLst,correctAll=correctAll)\n",
    "    if(correctAll):filename = 'Purity/TPM/v4/TCGA_'+maxPlace+'_tpm.tsv'\n",
    "    else:filename = 'Purity/TPM/v1/TCGA_'+maxPlace+'_tpm.tsv'\n",
    "    maxPure = pd.read_csv(filename,index_col=0,sep='\\t')\n",
    "    maxPure.dropna();maxHot,maxCold = __getHotCold(maxPure);colDataMax = __colDataFunc(maxHot.columns,maxCold.columns)\n",
    "    maxPure = maxPure[colDataMax.index];out = pd.DataFrame();out2 = pd.DataFrame();titleLst=[]\n",
    "    for place in tq(placeLst,desc='Fold Change and P-value'):\n",
    "        LFCLst=[];pvalLst=[]\n",
    "        if(correctAll):filename = 'Purity/TPM/v4/TCGA_'+place+'_tpm.tsv'\n",
    "        else:filename = 'Purity/TPM/v1/TCGA_'+place+'_tpm.tsv'\n",
    "        postPure = pd.read_csv(filename,index_col=0,sep='\\t');postPure.dropna();minVal = min(postPure[min(postPure)])\n",
    "        postPure = postPure - minVal;postHot,postCold = __getHotCold(postPure)\n",
    "        colDataPost = __colDataFunc(postHot.columns,postCold.columns);postPure = postPure[colDataPost.index]\n",
    "        if(mean):\n",
    "            title = place+' LFC by Mean';postHotM = postHot.mean(axis=1);postColdM = postCold.mean(axis=1)\n",
    "        else:\n",
    "            title = place+' LFC by Median';postHotM = postHot.median(axis=1);postColdM = postCold.median(axis=1)\n",
    "        titleLst.append(title)\n",
    "        if(ttest):\n",
    "            tTestLst = stats.ttest_ind(postHot.T,postCold.T)[1];title = place+' P-Val by T-test'\n",
    "        else:title = place+' P-Val by RankSum'\n",
    "        titleLst.append(title);num = 0\n",
    "        for gene in maxPure.index:\n",
    "            if(gene in postPure.index):\n",
    "                A = postColdM[gene];B = postHotM[gene];A = A+0.0000001;B = B+0.0000001;LFC = np.log2((A/B));LFCLst.append(LFC)\n",
    "                if(ttest):pval = tTestLst[num]\n",
    "                else:\n",
    "                    pval = stats.ranksums(postHot.loc[gene].values,postCold.loc[gene].values);pval = pval.pvalue\n",
    "                num += 1;pvalLst.append(pval)\n",
    "            else:\n",
    "                LFCLst.append(np.nan);pvalLst.append(np.nan)\n",
    "        out[place] = LFCLst;out2[place] = pvalLst\n",
    "    out.index = maxPure.index;out.index.name = 'Genes';out2.index = maxPure.index;out2.index.name = 'Genes';out = out.dropna()\n",
    "    out2 = out2.dropna();index = __goodGenes(out.index,out2.index);out = out.loc[index];out2 = out2.loc[index]\n",
    "    return out, out2\n",
    "\n",
    "def __getFirst(lst,col):\n",
    "    for i in range(len(lst)):\n",
    "        if(lst[i].columns[0]==col):return i \n",
    "def __mergeCols(fileName,lst,cols,mergeOn,save=True):\n",
    "    dfNum = __getFirst(lst,cols[0]);df = lst[dfNum]\n",
    "    for i in range(dfNum+1,len(lst)):\n",
    "        if(i%100==0 and save):df.to_csv('HotCold Samples/'+fileName)\n",
    "        if within(lst[i].columns[0],cols):df = df.merge(lst[i],on=mergeOn)\n",
    "    if(save):df.to_csv('HotCold Samples/'+fileName)\n",
    "    return df\n",
    "def plotXCell(placeLst,save=False,ratio=True,heat=True,thres=0.02,filt=False):\n",
    "    \"\"\"plotXCell:\n",
    "                Input:\n",
    "                    placeLst, a list of cancer areas for which to create xCell plots\n",
    "                        no default\n",
    "                    save, boolean telling if to save the cancer area xCell data\n",
    "                          in the 'Share Data/' folder\n",
    "                        default = False\n",
    "                    ratio, boolen telling if to get ratios of each types percent in each sample (if Ture)\n",
    "                           or keep raw values (if False)\n",
    "                        default = True\n",
    "                    heat, boolean telling if to plot a heatmap of the xCell data for each cancer area\n",
    "                        default = True\n",
    "                    thres, the threshold a row in the data should be above\n",
    "                           makes the most sense in when ratio = True\n",
    "                        default = 0.02 \n",
    "                    filt, boolean telling if to filter out rows that failed to be > thres\n",
    "                        default = False\n",
    "                Action:\n",
    "                    Plots a heatmap of the xCell data, in either ratio or raw value, \n",
    "                    and maybe filtered bvy thres, for each cancer area in placeLst.\n",
    "                    May also save that data if told to do so.\n",
    "                Output: Upon success, gives back a 1 \n",
    "    \"\"\"\n",
    "    xCell = pd.read_csv('xCell_TCGA_RSEM.txt',index_col=0,sep='\\t')\n",
    "    __renameTPM(xCell)\n",
    "    for place in tq(placeLst,desc='Plot XCell'):\n",
    "        prePure = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "        __renameTPM(prePure)\n",
    "        cols = __goodGenes(xCell.columns,prePure.columns)\n",
    "        xCellCancer = xCell[cols]\n",
    "        title = 'XCell Values, '+place\n",
    "        if(ratio):\n",
    "            title = 'XCell Ratios, '+place\n",
    "            for col in xCellCancer.columns:\n",
    "                ser = xCellCancer[col]\n",
    "                serMin = ser.min()\n",
    "                shiftSer = ser - serMin\n",
    "                shiftMax = shiftSer.max()\n",
    "                percents = shiftSer / shiftMax\n",
    "                xCellCancer[col] = percents\n",
    "            if(filt):\n",
    "                thresName = str(round(thres*100))\n",
    "                title = 'XCell Ratios, Filtered < '+thresName+'%, '+place\n",
    "                xCellCancer = xCellCancer.T\n",
    "                rowLength = len(xCellCancer.index)\n",
    "                xCellCancer = xCellCancer[(xCellCancer.sum() > (thres*rowLength)).replace(False,np.nan).dropna().index]\n",
    "                xCellCancer = xCellCancer.T\n",
    "        if(save):\n",
    "            saveTitle = title.replace(' ','_')\n",
    "            xCellCancer.to_csv('Share Data/'+saveTitle)\n",
    "        if(heat):\n",
    "            cg = sb.heatmap(xCellCancer,cmap=cmapSpecial);plt.title(title);plt.show();print(title)\n",
    "    return 1\n",
    "\n",
    "def getQualifedGenes(placeLst,mean=True,ttest=True,threshold=2,upCold=True,lfc=0,pv=1):\n",
    "    LFC, pval = __logFoldChange(placeLst,mean=mean,ttest=ttest);geneLst=[]\n",
    "    for gene in tq(LFC.index,desc='Qual genes'):\n",
    "        if(upCold):areasL = LFC.loc[gene][LFC.loc[gene] > lfc].index\n",
    "        else:areasL = LFC.loc[gene][LFC.loc[gene] < (-1*lfc)].index\n",
    "        areasP = pval.loc[gene][pval.loc[gene] < pv].index;num = 0\n",
    "        for cancer in areasL:\n",
    "            if cancer in areasP:num += 1\n",
    "        if(num >= threshold):geneLst.append(gene)\n",
    "    return geneLst\n",
    "def partitionLst(Lst,div=4):\n",
    "    \"\"\"partitionLst:\n",
    "                    Input:\n",
    "                        Lst, a list of values\n",
    "                            no default\n",
    "                        div, number of elements each new divded list must contain\n",
    "                            default = 4\n",
    "                    Action:\n",
    "                        Divides the inputed list into similar sized lists each with\n",
    "                        the inputed number of elements\n",
    "                    Example:\n",
    "                        In: partionLst([1,2,3,4,5,6,7],3)\n",
    "                        Out: [[1,2,3],[4,5,6],[7]]\n",
    "                    Output:\n",
    "                        A list of lists, each with the inputed number of elements in them \n",
    "        \"\"\"\n",
    "    outLst=[];start=0;current = div;length = len(Lst);num = int(length/div);last = length%div\n",
    "    while(length > 0):\n",
    "        outLst.append(Lst[start:current]);start += div;current += div;length = length - div\n",
    "    return outLst\n",
    "\n",
    "def __noDupsLst(lst,onlyDups=False):\n",
    "    out = [];outRep=[]\n",
    "    for i in lst:\n",
    "        if(not i in out):\n",
    "            out.append(i)\n",
    "        else:\n",
    "            if(onlyDups):\n",
    "                if(not i in outRep):\n",
    "                    outRep.append(i)\n",
    "    if(onlyDups):\n",
    "        out = outRep\n",
    "    return out\n",
    "\n",
    "def __getNameGSEA(file):\n",
    "    f = file;f = f.split('\\\\')[-1];f = f.split('.')[0];f = f.replace('_',' ')\n",
    "    return f\n",
    "\n",
    "def __getGSEAdfs(date,tpy,placeLst,desktop=True,skipImmune=False,preRank=False):\n",
    "    pathDict = __getPathDict(date=date,tpy=tpy,placeLst=placeLst,desktop=desktop,preRank=preRank)\n",
    "    pathLst = list(pathDict.keys());dfNES = pd.DataFrame();dfFDR = pd.DataFrame()\n",
    "    for gsea in glob.glob('GSEA Output/'+date+'/'+tpy+'/*'):\n",
    "        cancer = __getNameGSEA(gsea)\n",
    "        if(cancer in placeLst):\n",
    "            nesLst=__repeatAppend([],len(pathDict),0);fdrLst=__repeatAppend([],len(pathDict),0)\n",
    "            if(desktop):\n",
    "                fileName=gsea+'/*report*.xls';sep='\\t';nCol='NES';fCol='FDR q-val'\n",
    "            else:\n",
    "                if preRank:fileName =gsea+'/gseapy.prerank.gene_sets.report.csv'\n",
    "                else:fileName =gsea+'/gseapy.gsea.phenotype.report.csv'\n",
    "                sep=',';nCol = 'es';fCol = 'fdr'\n",
    "            for file in glob.glob(fileName):\n",
    "                df = pd.read_csv(file,index_col=0,sep=sep)\n",
    "                for path in df.index:\n",
    "                    Nes = df.loc[path][nCol];fdr = df.loc[path][fCol]\n",
    "                    path = path.upper();nesLst[pathDict[path]] = Nes;fdrLst[pathDict[path]] = fdr\n",
    "            dfNES[cancer] = nesLst;dfFDR[cancer] = fdrLst\n",
    "    dfNES.index = pathLst;dfFDR.index = pathLst\n",
    "    __addKs(dfNES,axis=0,lst=dfNES.index,k=tpy+'_',inplace=True)\n",
    "    __addKs(dfFDR,axis=0,lst=dfFDR.index,k=tpy+'_',inplace=True)\n",
    "    dfNES.index.name = 'Paths';__addKs(dfNES,lst=kobePlaceLst1,inplace=True)\n",
    "    __addKs(dfFDR,lst=kobePlaceLst1,inplace=True);dfNES.columns = getUniqueNames(dfNES.columns)\n",
    "    dfFDR.index.name = 'Paths';dfFDR.columns = getUniqueNames(dfFDR.columns)\n",
    "    dfNES = dfNES.replace(0, np.nan);dfNES.dropna(axis=0,how='all',inplace=True);dfNES.dropna(axis=1,inplace=True)\n",
    "    dfFDR = dfFDR.loc[dfNES.index];dfFDR = dfFDR[dfNES.columns];dfNES = dfNES.replace(np.inf,0);dfFDR = dfFDR.replace(np.inf,0)\n",
    "    if(skipImmune):\n",
    "        dfNES = __skipImmuneDf(dfNES);dfFDR = __skipImmuneDf(dfFDR)\n",
    "    return dfNES,dfFDR\n",
    "\n",
    "def __skipImmuneDf(dfIn,immuneLst=['T-EFFECTOR','IFNG INDUCED','ANTIGEN PROCESSING MACHINERY'],inplace=True):\n",
    "    if(inplace):df = dfIn\n",
    "    else:df = dfIn.copy()\n",
    "    newId=[]\n",
    "    for path in df.index:\n",
    "        if not any(i in path for i in immuneLst):newId.append(path)\n",
    "    df = df.loc[newId]\n",
    "    return df\n",
    "def getUniqueNames(lst,thres=10):\n",
    "    newNum = 1;dups = [''];numLst = __repeatAppend([],len(lst),0)\n",
    "    while True:\n",
    "        nameLst=[]\n",
    "        for idx in range(len(lst)):\n",
    "            name = lst[idx];num = numLst[idx];frst = ' '.join(name.split()[:num])\n",
    "            if(frst in dups):\n",
    "                frst = ' '.join(name.split()[:newNum]);numLst[idx] = newNum\n",
    "            nameLst.append(frst)\n",
    "        dups = __noDupsLst(nameLst,onlyDups=True)\n",
    "        if(dups == []):\n",
    "            newCol=[]\n",
    "            for col in nameLst:\n",
    "                if(col=='Breast'):col = 'Breast HR+'\n",
    "                newCol.append(col)\n",
    "            nameLst = newCol\n",
    "            return nameLst\n",
    "        newNum += 1\n",
    "        if(newNum > thres):\n",
    "            print('getUniqueNames warning: Reached Threshold of '+\n",
    "                  str(thres)+\n",
    "                  ' before getting complete unique names\\nEither threshold is too small or certain names are duplicates')\n",
    "            return nameLst\n",
    "def __setCluster(inputDF,row,col,inplace=False):\n",
    "    if(inplace):df = inputDF\n",
    "    else:df = inputDF.copy()\n",
    "    rowLst=[];colLst=[]\n",
    "    for num in row:\n",
    "        elem = df.index[num];rowLst.append(elem)\n",
    "    for num in col:elem = df.columns[num];colLst.append(elem)\n",
    "    df = df[colLst];df = df.loc[rowLst]\n",
    "    return df\n",
    "\n",
    "def __addKs(dfIn,k='K_',axis=1,inplace=False,lst=[]):\n",
    "    if(inplace):df = dfIn\n",
    "    else:df = dfIn.copy()\n",
    "    if(axis==1):\n",
    "        colLst=[]\n",
    "        for col in df.columns:\n",
    "            if col in lst:\n",
    "                col = k+col\n",
    "            colLst.append(col)\n",
    "        df.columns = colLst\n",
    "    if(axis==0):\n",
    "        rowLst=[]\n",
    "        for row in df.index:\n",
    "            if(row in lst):row = k+row\n",
    "            rowLst.append(row)\n",
    "        df.index = rowLst\n",
    "    return df\n",
    "def plotCorrelation(placeLst,Dict,prePure=False,getPosition=False,position={},meth='spearman',cmap=cmapSpecial,\n",
    "                   size=(15,5),padd=3,name='',save=False):\n",
    "    titleLst=[]\n",
    "    if(getPosition):placeLst = [placeLst[0]];positon={}\n",
    "    for place in tq(placeLst,desc='plot Correlation'):\n",
    "        title=''\n",
    "        if(prePure):\n",
    "            title += 'Pre-Purity, '+place+', '\n",
    "            df = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "            __renameTPM(df);df = np.log2(df+1);df = pd.DataFrame(stats.zscore(df,axis=1),df.index,columns=df.columns)\n",
    "        else:\n",
    "            title += 'Post-Purity, '+place+', ';df = pd.read_csv('Purity/TPM/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        df.dropna(inplace=True);Hot,Cold = __getHotCold(df);Hot.dropna(inplace=True);Cold.dropna(inplace=True)\n",
    "        for path in Dict:\n",
    "            title2 = title+path+', ';pathDict = Dict[path];genes = __runGenes(pathDict);genes = __goodGenes(genes,df.index)\n",
    "            hotPath = Hot.loc[genes];hotPath = hotPath.T;coldPath = Cold.loc[genes]\n",
    "            coldPath = coldPath.T;hotCor = hotPath.corr(method=meth);coldCor = coldPath.corr(method=meth)\n",
    "            if(getPosition):\n",
    "                col, row = __getClusterPosition(hotCor);dfIndx = hotCor.index;geneOrder=[]\n",
    "                for num in col:\n",
    "                    gene = dfIndx[num];geneOrder.append(gene)\n",
    "                position[path] = geneOrder\n",
    "            else:\n",
    "                hotCor = __fixCor(hotCor,path,position);coldCor = __fixCor(coldCor,path,position)\n",
    "                fig, axes = plt.subplots(nrows=1, ncols=2, figsize=size);ax1 = axes[0];ax2 = axes[1];fig.tight_layout(pad=padd)\n",
    "                title2 += 'Hot';sb.heatmap(hotCor,cmap=cmap,ax=ax1,vmin=-1,vmax=1);ax1.set_title(title2)\n",
    "                title2 = title2.replace('Hot','Cold');sb.heatmap(coldCor,cmap=cmap,ax=ax2,vmin=-1,vmax=1)\n",
    "                ax2.set_title(title2);title2 = title2.replace('Cold','Samples Correlation, ');title2 += meth\n",
    "                if(save):\n",
    "                    plt.savefig(title2+'.png',bbox_inches = \"tight\");titleLst.append(title2+'.png')\n",
    "                plt.show();print(title2)\n",
    "    if(getPosition):\n",
    "        return position\n",
    "    if(save):\n",
    "        __mergePDFs(titleLst,name)\n",
    "    return name\n",
    "\n",
    "def __mergePDFs(fileNames,name,erase=False):\n",
    "    if os.path.exists(name):\n",
    "        os.remove(name)\n",
    "    import PyPDF2\n",
    "    from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "    input_streams = [];output_stream = open(name+\".pdf\", 'w+b')\n",
    "    try:\n",
    "        for input_file in fileNames:\n",
    "            input_streams.append(open(input_file, 'rb'))\n",
    "        writer = PdfFileWriter()\n",
    "        for reader in map(PdfFileReader, input_streams):\n",
    "            for n in range(reader.getNumPages()):\n",
    "                writer.addPage(reader.getPage(n))\n",
    "            writer.write(output_stream)\n",
    "    finally:\n",
    "        for f in input_streams:\n",
    "            f.close()\n",
    "        output_stream.close()\n",
    "    if(erase):\n",
    "        for file in fileNames:\n",
    "            os.remove(file)\n",
    "    return name\n",
    "\n",
    "def __maxLenPlace(placeLst,correctAll=False,minn=False):\n",
    "    if(minn):\n",
    "        maxLen = 1000000000\n",
    "    else:\n",
    "        maxLen = 0\n",
    "    maxPlace=placeLst[0]\n",
    "    for place in tq(placeLst,desc='Max Len Place'):\n",
    "        if(correctAll):\n",
    "            filename = 'Purity/TPM/v4/TCGA_'+place+'_tpm.tsv'\n",
    "        else:\n",
    "            filename = 'Purity/TPM/v1/TCGA_'+place+'_tpm.tsv'\n",
    "        postPure = pd.read_csv(filename,index_col=0,sep='\\t');postPure.dropna()\n",
    "        postHot,postCold = __getHotCold(postPure);colDataPost = __colDataFunc(postHot.columns,postCold.columns)\n",
    "        postPure = postPure[colDataPost.index];length = len(postPure.index)\n",
    "        if(minn):\n",
    "            if(length < maxLen):\n",
    "                maxLen = length;maxPlace = place\n",
    "        else:\n",
    "            if(length > maxLen):\n",
    "                maxLen = length;maxPlace = place\n",
    "    return maxPlace\n",
    "\n",
    "def plotLFC(placeLst,Dict,mean=True,ttest=True,getPosition=False,row_position={},col_position={},\n",
    "           size=(12,4),padd=3,correctAll=False):\n",
    "    LFC, pval = __logFoldChange(placeLst,mean=mean,ttest=ttest,correctAll=correctAll)\n",
    "    if(getPosition):\n",
    "            row_position={};col_position={}\n",
    "    for path in tq(Dict,desc='Plotting'):\n",
    "        if not(getPosition):\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2, figsize=size)\n",
    "            ax1 = axes[0];ax2 = axes[1];fig.tight_layout(pad=padd)\n",
    "        pathDict = Dict[path];genes = __runGenes(pathDict)\n",
    "        genes = __goodGenes(genes,LFC.index);LFCgenes = LFC.loc[genes].T;LFCgenes.index.name='Cancer Areas'\n",
    "        if(getPosition):\n",
    "            row_order, col_order = __getClusterPosition(LFCgenes,more=True)\n",
    "            row_position[path] = row_order;col_position[path] = col_order\n",
    "        else:\n",
    "            LFCgenes = __fixCor(LFCgenes,path,row_position,col_position)\n",
    "            LFCgenes = __renameLFC(LFCgenes);sb.heatmap(LFCgenes,cmap=cmapSpecial2,ax=ax1,vmin=-1.5,vmax=1.5)\n",
    "            if(mean):\n",
    "                ax1.set_title(path+' Log2 FC by Mean')\n",
    "            else:\n",
    "                ax1.set_title(path+' Log2 FC by Median')\n",
    "            genes = __runGenes(pathDict);genes = __goodGenes(genes,pval.index);pvalgenes = pval.loc[genes].T\n",
    "            pvalgenes.index.name='Cancer Areas';pvalgenes = __fixCor(pvalgenes,path,row_position,col_position)\n",
    "            pvalgenes = __renameLFC(pvalgenes);sb.heatmap(pvalgenes,cmap=cmapSpecial,vmin=0,vmax=1,ax=ax2)\n",
    "            if(ttest):\n",
    "                ax2.set_title(path+ ' P-Value by T-Test')\n",
    "            else:\n",
    "                ax2.set_title(path+ ' P-Value by RankSums')\n",
    "            plt.show();print(path)\n",
    "    if(getPosition):\n",
    "        return row_position,col_position\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def __numLstsIn(elem,SuperLst=[]):\n",
    "    num = 0\n",
    "    for lst in SuperLst:\n",
    "        if(elem in lst):\n",
    "            num += 1\n",
    "    return num\n",
    "def __enoughLsts(elem,SuperLst=[],threshold=3):\n",
    "    num = __numLstsIn(elem,SuperLst)\n",
    "    return (num >= threshold)\n",
    "\n",
    "def __renameLFC(lfc):\n",
    "    Col = []\n",
    "    for col in lfc.index:\n",
    "        col = col.replace('Carcinoma','');col = col.replace('carcinoma','');col = col.replace('Melanoma','');Col.append(col)\n",
    "    lfc.index = Col\n",
    "    return lfc\n",
    "# Gets the mix N row-col pairings from within a dataframe\n",
    "# \n",
    "def __topN(df,num=1,absVal=True,top=True):\n",
    "    outLst=[];df2 = df.copy()\n",
    "    if(absVal):\n",
    "        df2 = abs(df2)\n",
    "    if top:\n",
    "        for i in range(num):\n",
    "            maxSer = df2.max();maxId = maxSer.argmax();maxCol = maxSer.index[maxId];maxRow = df2[maxCol].idxmax()\n",
    "            df2[maxCol][maxRow] = 0;df2[maxRow][maxCol] = 0\n",
    "            outLst.append((maxCol,maxRow,maxCol+', '+maxRow))\n",
    "    else:\n",
    "        df2 = df2[df2 >= num]\n",
    "        for col in df2:\n",
    "            ser = df2[col];ser = ser.dropna()\n",
    "            for row in ser.index:\n",
    "                df2[col][row]=np.nan;df2[row][col]=np.nan;outLst.append((col,row,col+', '+row))\n",
    "    return outLst\n",
    "\n",
    "__careLst = ['Bladder', 'Breast', 'Colon', 'Liver', 'Lung', 'Melanoma', 'Ovarian', 'Pancreatic', 'Prostate','renal']\n",
    "def kobePlaceLst(careLst=__careLst,thres=1,cares=True):\n",
    "    \"\"\"kobePlaceLst:\n",
    "                    Input:\n",
    "                            careLst, a list of cancer areas that every area in the output list \n",
    "                                     must be a member of one of these areas, \n",
    "                                     and areas outside of careLst will be ignored.\n",
    "                                default = kobe cancers 'Bladder', 'Breast', 'Colon',\n",
    "                                                       'Liver', 'Lung', 'Melanoma', \n",
    "                                                       'Ovarian', 'Pancreatic', 'Prostate',\n",
    "                                                       and 'renal' \n",
    "                            thres, the number of hot/cold samples a place must include to be in the output\n",
    "                                default = 1\n",
    "                            cares, a boolean telling if caresLst should be ignored\n",
    "                                default = True\n",
    "                    Action:\n",
    "                            Looks through all available TPM cancer areas, and creates a list of areas\n",
    "                            with hot/cold samples > the given threshold, and within the careLst \n",
    "                    Output:\n",
    "                            A list of cancer areas.\n",
    "    \"\"\"\n",
    "    pLst = glob.glob('Genes/TPM/*');inputs = tq(pLst)\n",
    "    out = Parallel(n_jobs=num_cores)(delayed(__kobePlaceLstHelp)(p,careLst,thres,cares) for p in inputs)\n",
    "    out = set(out);out.remove('');out = list(out);out.sort()\n",
    "    return out\n",
    "\n",
    "def __kobePlaceLstHelp(p,careLst,thres,cares):\n",
    "    place = p.split('_')[1]\n",
    "    if(cares):\n",
    "        value = any(e in place for e in careLst)\n",
    "    else:\n",
    "        value = True\n",
    "    if(value):\n",
    "        filename = 'Purity/TPM/v1/TCGA_'+place+'_tpm.tsv';postPure = pd.read_csv(filename,index_col=0,sep='\\t')\n",
    "        if(len(postPure.columns)>0):\n",
    "            length = len(postPure.columns)/2\n",
    "            if(length>(thres*2)):\n",
    "                return place\n",
    "    return ''\n",
    "\n",
    "def getBiggestXCancers(num=1,thres=30):\n",
    "    pLst = glob.glob('Genes/TPM/*')\n",
    "    inputs = pLst;out = Parallel(n_jobs=num_cores)(delayed(__getBiggestXCancersHelp)(p) for p in inputs);outLst=[]\n",
    "    if(num>len(pLst)):\n",
    "        num = len(pLst)\n",
    "    for i in range(num):\n",
    "        argMax = out.index(max(out))\n",
    "        place = out[argMax][1];num = out[argMax][0];outLst.append((place,num));out[argMax] = (0,place)\n",
    "    return outLst\n",
    "def __getBiggestXCancersHelp(p): \n",
    "    place = p.split('_')[1]\n",
    "    filename = 'Purity/TPM/v1/TCGA_'+place+'_tpm.tsv';postPure = pd.read_csv(filename,index_col=0,sep='\\t')\n",
    "    return  len(postPure.columns),place\n",
    "\n",
    "def __getPathDict(date,tpy,placeLst,desktop=False,preRank=False):\n",
    "    pathLst=[]\n",
    "    for gsea in glob.glob('GSEA Output/'+date+'/'+tpy+'/*'):\n",
    "        cancer = __getNameGSEA(gsea)\n",
    "        if(cancer in placeLst):\n",
    "            if(desktop):\n",
    "                fileName=gsea+'/*report*.xls';sep='\\t';nCol='NES';fCol='FDR q-val'\n",
    "            else:\n",
    "                if preRank:\n",
    "                    fileName =gsea+'/gseapy.prerank.gene_sets.report.csv'\n",
    "                else:\n",
    "                    fileName =gsea+'/gseapy.gsea.phenotype.report.csv'\n",
    "                sep=',';nCol = 'es';fCol = 'fdr'\n",
    "            for file in glob.glob(fileName):\n",
    "                df = pd.read_csv(file,index_col=0,sep=sep)\n",
    "                for path in df.index:\n",
    "                    pathLst.append(path)\n",
    "    pathLst = list(set(pathLst));num=0;pathDict={}\n",
    "    for path in pathLst:\n",
    "        pathDict[path]=num;num+=1\n",
    "    return pathDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masterPlotGSEA(dateIn,placeLst,databaseLst='All',title='GSEA',desktop=False,save=False,preRank=False,\n",
    "                   metric='cosine',fixPos=False,Position={},fontSize=12,rot=45,skipImmune=False,coldNum=0,figSize=(30,20),\n",
    "                   skipKobePaths=False,numParts=20,reverseOrder=False,dbName='',fdrVal=0.25,\n",
    "                   noParts=False,removeBad=False,containsColdCluster=(False,False,0)):\n",
    "    \"\"\"masterPlotGSEA:\n",
    "                        Input:\n",
    "                            dateLst, list of all days in which the GSEA anyalysis you want plotted were done\n",
    "                                  typically first three letters of the month then the number of the day\n",
    "                                  ex: jul13, nov5\n",
    "                                no default\n",
    "                            placeLst, list of cancer areas to include in the plot\n",
    "                                no default\n",
    "                            databaseLst, list of the database to plot,\n",
    "                                         for all available databases enter 'All'\n",
    "                                         ex: ['KOBE','KEGG']\n",
    "                                default = 'All'\n",
    "                            title, the title of the heatmaps created\n",
    "                                default = 'GSEA'\n",
    "                            desktop, boolean telling if output if from GSEA desktop/command line version (True)\n",
    "                                     or the python wrapper version (False)\n",
    "                                default = False\n",
    "                            save, boolean telling if to save the clustermaps (will be in 'Saved Images/ Folder')\n",
    "                            preRank, boolean telling if GSEA-Prerank was run, or normal GSEA\n",
    "                            metric, str metric used for clustering\n",
    "                                default = 'cosine'\n",
    "                            fixPos, boolean telling if to use Position to order the plots, or use clustering\n",
    "                            Position, dictionary to be used for positioning clustermap if fixPos == True\n",
    "                            rot, \n",
    "                            \n",
    "                        Actions:\n",
    "                            Plots a clustermap of the NES and FDR \n",
    "                            (with FDR's positions based on NES's clustering)\n",
    "                            from all the available GSEA data from the date given\n",
    "                        Output:\n",
    "                            On success, it returns the position dictionary to be used by reruns of this function to have\n",
    "                            different plots with the same positioning\n",
    "    \"\"\"\n",
    "    if(isinstance(dateIn,list)):\n",
    "        dateLst = dateIn.copy()\n",
    "    else:\n",
    "        dateLst = [dateIn]\n",
    "    if(databaseLst=='All'):\n",
    "        dbLst=[]\n",
    "        for gsea in glob.glob('GSEA Output/'+dateLst[0]+'/*'):\n",
    "            dbLst.append(gsea.split('\\\\')[-1])\n",
    "    else:\n",
    "        dbLst=databaseLst.copy()\n",
    "    if(skipKobePaths):\n",
    "        dbLst.remove('KOBE')\n",
    "    dateNum=1\n",
    "    for date in dateLst:\n",
    "        datePos={}\n",
    "        superDfNes,superDfFdr = __superDfGSEA(date,dbLst=dbLst,placeLst=placeLst,\n",
    "                                              desktop=desktop,skipImmune=skipImmune,\n",
    "                                              preRank=preRank,coldNum=coldNum,fdrVal=fdrVal,\n",
    "                                              containsColdCluster=containsColdCluster)\n",
    "        superDfNes,superDfFdr,pathLst,catLst = __getPathLst(superDfNes,superDfFdr,removeBad)\n",
    "        superDfNes.index = pathLst;superDfFdr.index = pathLst\n",
    "        if coldNum > 0:\n",
    "            if not containsColdCluster[0]:\n",
    "                title2 = title+' At least '+str(coldNum)+' Up in Cold Pathways, FDR '+str(fdrVal)\n",
    "            else:\n",
    "                title2 = title+' FDR '+str(fdrVal)\n",
    "        else:\n",
    "            title2 = title+' All Pathways'\n",
    "        print('plotting')\n",
    "        if len(superDfNes.index) > 1:\n",
    "            if dbName=='c2.all':\n",
    "                df3,df4 = __C2SplitGSEA(superDfNes,superDfFdr,useLst=True,lst=catLst)\n",
    "                superDfNes3,superDfFdr3,catLst3=df3;superDfNes4,superDfFdr4,catLst4=df4;dbName=dbName+' '+msigNameDict[dbName]\n",
    "                if len(superDfNes3.index) > 1:\n",
    "                    row,col = __helpPlotGSEA(superDfNes3,superDfFdr3,title=title2,db=dbName+' Canonical, ',metric=metric,\n",
    "                                             save=save,numParts=numParts,reverseOrder=reverseOrder,noParts=noParts,\n",
    "                                             catLst=catLst3,\n",
    "                                             figSize=figSize,fixPos=fixPos,pos=Position,fontSize=fontSize,rot=rot)\n",
    "                if len(superDfNes4.index) > 1:\n",
    "                    row,col = __helpPlotGSEA(superDfNes4,superDfFdr4,title=title2,\n",
    "                                             db=dbName+' Chemical and Genetic Perturbations, ',metric=metric,\n",
    "                                             catLst=catLst4,\n",
    "                                             save=save,numParts=numParts,reverseOrder=reverseOrder,noParts=noParts,\n",
    "                                             figSize=figSize,fixPos=fixPos,pos=Position,fontSize=fontSize,rot=rot)\n",
    "            else:\n",
    "                if dbName=='c5.all':\n",
    "                    df3,df4 = __C2SplitGSEA(superDfNes,superDfFdr,useLst=True,lst=catLst,keep=['GO'])\n",
    "                    superDfNes3,superDfFdr3,catLst3 = df3\n",
    "                    dbName = dbName+' '+msigNameDict[dbName]+' GO Biological Process, '\n",
    "                    if len(superDfNes3.index) > 1:\n",
    "                        row,col = __helpPlotGSEA(superDfNes3,superDfFdr3,title=title2,db=dbName,metric=metric,\n",
    "                                                 save=save,numParts=numParts,reverseOrder=reverseOrder,\n",
    "                                                 catLst=catLst3,figSize=figSize,fixPos=fixPos,pos=Position,\n",
    "                                                 fontSize=fontSize,rot=rot,noParts=noParts)\n",
    "                else:\n",
    "                    dbName = dbName+' '+msigNameDict[dbName]+', '\n",
    "                    row,col = __helpPlotGSEA(superDfNes,superDfFdr,title=title2,db=dbName,metric=metric,save=save,\n",
    "                                             numParts=numParts,reverseOrder=reverseOrder,noParts=noParts,catLst=catLst,\n",
    "                                             figSize=figSize,fixPos=fixPos,pos=Position,fontSize=fontSize,rot=rot)\n",
    "            datePos['All']= (row,col)\n",
    "    gc.collect()\n",
    "    return datePos\n",
    "def __superDfGSEA(date,dbLst,placeLst,desktop,skipImmune,preRank,coldNum,fdrVal,containsColdCluster=(False,False,0)):\n",
    "    if(len(dbLst)<=0):\n",
    "        print('Date inputed has no GSEA output')\n",
    "        raise \n",
    "    frstDB=True\n",
    "    for db in tq(dbLst,desc='superDfGSEA'):\n",
    "        dfNes, dfFdr = __getGSEAdfs(date,db,placeLst,desktop,skipImmune,preRank=preRank)\n",
    "        dfNes, dfFdr =__getUpinCold(dfNes,dfFdr,coldNum,coldNum,fdrVal)\n",
    "        if(frstDB):\n",
    "            superDfNes = dfNes.copy();superDfFdr = dfFdr.copy();frstDB=False\n",
    "        else:\n",
    "            superDfNes = pd.concat([superDfNes,dfNes]);superDfFdr = pd.concat([superDfFdr,dfFdr])\n",
    "        gc.collect()\n",
    "    if containsColdCluster[0]:\n",
    "        coldCancerLst=['Adrenocortical','Breast HR+','K_Lung adenocarcinoma','K_Lung squamous','Thyroid','K_Skin']\n",
    "        if containsColdCluster[1]:\n",
    "            lst2=[]\n",
    "            for place in superDfNes.columns:\n",
    "                if not place in coldCancerLst:\n",
    "                    lst2.append(place)\n",
    "            coldCancerLst = lst2\n",
    "        df2=superDfNes[coldCancerLst];df2=df2[df2<0]\n",
    "        df2=countNotNaNs(df2,rev=True);df2=df2[df2>=containsColdCluster[2]];clusterPathways = list(df2.index)\n",
    "        superDfNes = superDfNes.loc[clusterPathways];superDfFdr = superDfFdr.loc[clusterPathways]\n",
    "    superDfNes = superDfNes.dropna(how='all').fillna(0);superDfFdr = superDfFdr.dropna(how='all').fillna(1)\n",
    "    if 'Uterine' in superDfNes.columns and len(placeLst)>20:\n",
    "        superDfNes = superDfNes.drop(columns=['Uterine']);superDfFdr = superDfFdr.drop(columns=['Uterine'])\n",
    "    gc.collect()\n",
    "    return superDfNes, superDfFdr\n",
    "def __helpPlotGSEA(dfNes,dfFdr,title,db,metric='cosine',fixPos=False,pos={},fontSize=12,rot=45,save=False,catLst=[],\n",
    "                   figSize=(20,20),noParts=False,rowColors=(None,{}),\n",
    "                   numParts=20,reverseOrder=False,suptitleName=''):\n",
    "    gc.collect();parts = math.ceil(len(dfNes.index)/numParts)\n",
    "    maxx = max(dfNes.max().max(),1);minn = min(dfNes.min().min(),-1);cClus=not(fixPos);rClus=not(fixPos)\n",
    "    if(fixPos):\n",
    "        row, col = pos[db];dfNes = __setCluster(dfNes,row,col)\n",
    "    cg = sb.clustermap(dfNes,cmap=cmapSpecial,col_cluster=cClus,figsize=figSize,vmax=maxx,vmin=minn,\n",
    "                       row_cluster=rClus,metric=metric,yticklabels=0,xticklabels=1,row_colors=rowColors[0])\n",
    "    if(fixPos):\n",
    "        row, col = pos[db]\n",
    "    else:\n",
    "        row = cg.dendrogram_row.reordered_ind;col = cg.dendrogram_col.reordered_ind\n",
    "    if noParts: \n",
    "        saveLst=[]\n",
    "        for x,y in zip(cat2,colorLst):\n",
    "            cg.ax_heatmap.plot(0, 0, color=y, label=x, linewidth=10, solid_capstyle=\"butt\")\n",
    "        cg.ax_heatmap.legend(loc=(-0.05,1), title=\"MSig Category\",prop={'size': 40})\n",
    "        cg.ax_heatmap.set_xlabel('Cancers',size=40);cg.ax_heatmap.set_ylabel('Paths',size=40)\n",
    "        plt.setp(cg.ax_heatmap.get_xticklabels(),rotation=rot,ha='right',size=30);title2 = db+title+', Metric '+metric+', NES'\n",
    "        cg.fig.suptitle(title2,size=50);plt.title('NES Values',size=40)\n",
    "        if save:\n",
    "            plt.savefig('Saved Images/'+title2+'.pdf',dpi=200,bbox_inches = \"tight\")\n",
    "            plt.close();saveLst.append('Saved Images/'+title2+'.pdf')\n",
    "        else:\n",
    "            plt.show();print(title2)\n",
    "        dfFdr = __setCluster(dfFdr,row,col)\n",
    "        cg = sb.clustermap(dfFdr,cmap=cmapSpecial,col_cluster=False,figsize=figSize,vmax=1,vmin=0,\n",
    "                           row_cluster=False,metric=metric,yticklabels=0,xticklabels=1)\n",
    "        cg.ax_heatmap.set_xlabel('Cancers',size=40);cg.ax_heatmap.set_ylabel('Paths',size=40)\n",
    "        plt.setp(cg.ax_heatmap.get_xticklabels(),rotation=rot,ha='right',size=30)\n",
    "        title2 = db+title+', Metric '+metric+', FDR';cg.fig.suptitle(title2,size=50);plt.title('FDR Values',size=40)\n",
    "        if save:\n",
    "            plt.savefig('Saved Images/'+title2+'.pdf',dpi=200,bbox_inches = \"tight\");plt.close()\n",
    "            saveLst.append('Saved Images/'+title2+'.pdf')\n",
    "        else:\n",
    "            plt.show();print(title2)\n",
    "    else:\n",
    "        plt.close();dfNes = __setCluster(dfNes,row,col);dfFdr = __setCluster(dfFdr,row,col);rowColors2=[]\n",
    "        for rowCol in rowColors[0]:\n",
    "            rowLst=[]\n",
    "            for num in row:\n",
    "                elem = rowCol[num];rowLst.append(elem)\n",
    "            rowColors2.append(rowLst)\n",
    "        if reverseOrder:\n",
    "            dfNes = dfNes.iloc[::-1];dfFdr = dfFdr.iloc[::-1]\n",
    "        saveLst=[]\n",
    "        for n in range(parts):\n",
    "            partName = str(n+1)\n",
    "            rows = list(dfNes.index)[n*numParts:(n+1)*numParts];dfNes2 = dfNes.loc[rows];dfFdr2 = dfFdr.loc[rows]\n",
    "            if rowColors:\n",
    "                rowColorPart = []\n",
    "                for rowCol in rowColors2:\n",
    "                    rowColorPart.append(rowCol[n*numParts:(n+1)*numParts])\n",
    "            else:\n",
    "                rowColorPart=None\n",
    "            if len(dfNes2.index)>0:\n",
    "                cg = sb.clustermap(dfNes2,cmap=cmapSpecial,col_cluster=False,figsize=figSize,vmax=maxx,vmin=minn,annot=dfFdr2,\n",
    "                                   row_cluster=False,metric=metric,yticklabels=1,xticklabels=1,annot_kws={\"size\": 30},\n",
    "                                   row_colors=rowColorPart)\n",
    "                for x,y in rowColors[1]:\n",
    "                    cg.ax_heatmap.plot(0, 0, color=y, label=x, linewidth=10, solid_capstyle=\"butt\")\n",
    "                if n == 0:\n",
    "                    cg.ax_heatmap.legend(loc=(-0.05,1), title=\"C Groups\",prop={'size':40})\n",
    "                cg.ax_heatmap.set_xlabel('Cancers',size=50);cg.ax_heatmap.set_ylabel('Paths',size=50)\n",
    "                plt.setp(cg.ax_heatmap.get_xticklabels(),rotation=rot,ha='right',size=35)\n",
    "                plt.setp(cg.ax_heatmap.get_yticklabels(),rotation=rot,va='bottom',size=35)\n",
    "                cg.ax_heatmap.set_title(suptitleName+'\\nOverlaid text indicates FDR, color indicateas NES',size=50)\n",
    "                title2 = db+title+', Metric '+metric+', NES and FDR, Part '+partName\n",
    "                if parts==1:\n",
    "                    title2 = db+title+', Metric '+metric+', NES and FDR'\n",
    "                cg.fig.suptitle(title2,size=50);plt.title('NES Values',size=40)\n",
    "                if save:\n",
    "                    plt.savefig('Saved Images/'+title2+'.pdf',dpi=200,bbox_inches = \"tight\")\n",
    "                    plt.close();saveLst.append('Saved Images/'+title2+'.pdf')\n",
    "                else:\n",
    "                    plt.show();print(title2)\n",
    "    if save:\n",
    "        gc.collect();__mergePDFs(saveLst,name='Saved Images/'+db+title+', '+metric,erase=True)\n",
    "    return row, col\n",
    "def __getPathLst(superDfNesIn,superDfFdrIn,removeBad):\n",
    "    superDfNes = superDfNesIn.copy();superDfFdr = superDfFdrIn.copy();path2Lst=[];catLst=[]\n",
    "    for path in superDfNes.index:\n",
    "        splt = path.split('_');cat = splt[0].replace('MSigDB','')\n",
    "        cat = cat.split('.all')[0]+'.all';catLst.append(cat);splt=splt[2:];pathName = '_'.join(splt);path2Lst.append(pathName)  \n",
    "    superDfNes.index = path2Lst;superDfFdr.index = path2Lst;keepLst=superDfNes.index\n",
    "    if removeBad:\n",
    "        df = pd.read_csv('MsigDB/c2.cp.v7.2.symbols.gmt.tsv',sep='\\t',index_col=0)\n",
    "        c2can = list(df.columns);c2can = __goodGenes(c2can,superDfNes.index)\n",
    "        df = pd.read_csv('MsigDB/c5.go.bp.v7.2.symbols.gmt.tsv',sep='\\t',index_col=0)\n",
    "        c5bp = list(df.columns);c5bp = __goodGenes(c5bp,superDfNes.index)\n",
    "        df = pd.read_csv('MsigDB/h.all.v7.2.symbols.gmt.tsv',sep='\\t',index_col=0)\n",
    "        hall = list(df.columns);hall = __goodGenes(hall,superDfNes.index);keepLst=c2can+c5bp+hall\n",
    "    superDfNes = superDfNes.loc[keepLst];superDfFdr = superDfFdr.loc[keepLst]\n",
    "    return superDfNes, superDfFdr, catLst\n",
    "def __fixOutliers(dfIn,scale=0.1,title='',thres=3,onlyDic=False,dicIn={}):\n",
    "    prePure = dfIn.copy();totalSize=0;geneLst=[];runGenes = prePure.index\n",
    "    if(onlyDic):\n",
    "        runGenes = __totalRunGenes(dicIn);runGenes = __goodGenes(runGenes,prePure.index)\n",
    "    for gene in runGenes:\n",
    "        scale2=scale;fixLst=[];thresNum=0\n",
    "        while(True):\n",
    "            if(thresNum > thres):\n",
    "                scale2 = scale2/2\n",
    "            df = prePure.loc[gene];std35 = (df.mean()+3.5*df.std(),df.mean()-3.5*df.std())\n",
    "            dfUp = df.loc[df>std35[0]];dfDown = df.loc[df<std35[1]];outSize = len(dfUp)+len(dfDown)\n",
    "            if(outSize==0):\n",
    "                break\n",
    "            for elem in dfUp.index:\n",
    "                curVal = prePure.loc[gene][elem]\n",
    "                if(df.std()>1):\n",
    "                    newVal=df.mean()+3*df.std()+(curVal*scale2)\n",
    "                else:\n",
    "                    newVal=df.mean()+3*df.std()+(curVal*scale2*df.std())\n",
    "                prePure.loc[gene][elem]=newVal;fixLst.append(elem)\n",
    "            for elem in dfDown.index:\n",
    "                curVal = prePure.loc[gene][elem]\n",
    "                if(df.std()>1):\n",
    "                    newVal = df.mean() - 3*df.std() - (curVal*scale2)\n",
    "                else:\n",
    "                    newVal = df.mean() - 3*df.std() - (curVal*scale2*df.std())\n",
    "                prePure.loc[gene][elem] = newVal;fixLst.append(elem)\n",
    "            thresNum += 1\n",
    "        fixLst = __noDupsLst(fixLst);geneLst.append((gene,len(fixLst)))\n",
    "    return prePure, geneLst\n",
    "def plotPureCorrConsis(placeLst,meth='spearman'):\n",
    "    meth='spearman';dfLst=[];frst=True\n",
    "    for place in tq(placeLst,desc='dfLst'):\n",
    "        prePure = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "        if(frst):\n",
    "            genes = prePure.index;frst=False\n",
    "        else:\n",
    "            genes = __goodGenes(genes,prePure.index)\n",
    "        prePure = __pureDf(prePure);dfLst.append((place,prePure))\n",
    "    genes.insert(0,'Purity Scores')\n",
    "    for path in tq(overAllDict,desc='Plotting'):\n",
    "        out = pd.DataFrame();dic = overAllDict[path];genesPath = __runGenes(dic)\n",
    "        genesPath.insert(0,'Purity Scores');genesPath = __goodGenes(genesPath,genes)\n",
    "        for dfTup in dfLst:\n",
    "            name = dfTup[0];df = dfTup[1];df2 = df.loc[genesPath]\n",
    "            cor = df2.T.corr(method=meth)['Purity Scores'] ;out[name] = list(cor)\n",
    "        out.index = genesPath;out.columns = getUniqueNames(out.columns)\n",
    "        out = out.drop('Purity Scores');out.dropna(inplace=True);out = out.T\n",
    "        sb.clustermap(out,cmap=cmapSpecial,metric='cosine',yticklabels=1,xticklabels=1)\n",
    "        plt.title(path+' Correlation to Purity, '+meth);plt.show()\n",
    "        print(path+' Correlation to Purity, '+meth)\n",
    "    return 1\n",
    "def __C2SplitGSEA(superDfNes2,superDfFdr2,useLst=False,lst=[],\n",
    "                  keep=['KEGG','BIOCARTA','PID','REACTOME','ST','WP','SIG','SA']):\n",
    "    keepLst=[];keepLst2=[];spltLst=[];lst1=[];lst2=[];i=0\n",
    "    for row in superDfNes2.index:\n",
    "        splt = row.split('_')[0]\n",
    "        if splt in keep:\n",
    "            keepLst.append(row)\n",
    "            if useLst:\n",
    "                lst1.append(lst[i])\n",
    "        else:\n",
    "            keepLst2.append(row)\n",
    "            if useLst:\n",
    "                lst2.append(lst[i])\n",
    "        i+=1\n",
    "    superDfNes3 = superDfNes2.loc[keepLst];superDfNes4 = superDfNes2.loc[keepLst2]\n",
    "    superDfFdr3 = superDfFdr2.loc[keepLst];superDfFdr4 = superDfFdr2.loc[keepLst2]\n",
    "    return (superDfNes3,superDfFdr3,lst1),(superDfNes4,superDfFdr4,lst2)\n",
    "msigNameDict={};msigNameDict['h.all']='HallMark Gene Sets';msigNameDict['c2.all']='Curated Gene Sets'\n",
    "msigNameDict['c3.all']='Regulatory target Gene Sets';msigNameDict['c4.all']='Computational Gene Sets'\n",
    "msigNameDict['c5.all']='Ontology Gene Sets';msigNameDict['c6.all']='Oncogenic Signature Gene Sets'\n",
    "msigNameDict['c8.all']='Cell Type Signature Gene Sets';msigNameDict['All']=' Wanted Gene Sets'\n",
    "def __getOutliers(placeLst,fraction=False):\n",
    "    frst=True\n",
    "    for place in placeLst:\n",
    "        if(fraction):\n",
    "            prePure = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "            fract = len(prePure.columns)\n",
    "        with open(place+' Outliers.txt') as f:\n",
    "            out=[]\n",
    "            geneLst=[]\n",
    "            numLst=[]\n",
    "            for line in f:\n",
    "                line = line.replace('(','')\n",
    "                line = line.replace(')','')\n",
    "                line = line.replace('\\n','')\n",
    "                lines = line.split(',')\n",
    "                gene = lines[0]\n",
    "                gene = gene.replace(\"'\",'')\n",
    "                num = int(lines[1])\n",
    "                geneLst.append(gene)\n",
    "                numLst.append(num)\n",
    "        if(fraction):\n",
    "            numLst = [number / fract for number in numLst]\n",
    "        out = pd.DataFrame(numLst,geneLst,columns=[place])\n",
    "        if(frst):\n",
    "            df = out.copy()\n",
    "            frst=False\n",
    "        else:\n",
    "            df = df.join(out)\n",
    "    return df\n",
    "def plotOutliers(placeLst,fraction=False):\n",
    "    \"\"\"plotOutliers:\n",
    "                    Input:\n",
    "                        placeLst, a list of cancer area which you want included in the heatmaps\n",
    "                            no default\n",
    "                        fraction, boolean telling if to plot percent of outliers in each cancer (True),\n",
    "                                  or raw total number of outliers in each cancer (False)\n",
    "                    Actions:\n",
    "                        plots a heatmap for each superLst pathway of the number of outlier samples \n",
    "                        that were moved in each gene in that pathway \n",
    "                        (if the same sample was mvoed more than once, it is only counted as 1)\n",
    "                    Returns:\n",
    "                        On success return 1.\n",
    "    \"\"\"\n",
    "    df = __getOutliers(placeLst,fraction)\n",
    "    df.columns = getUniqueNames(df.columns)\n",
    "    for path in tq(overAllDict,desc='Paths'):\n",
    "        lst = overAllDict[path]\n",
    "        genes = __runGenes(lst)\n",
    "        genes = __goodGenes(genes,df.index)\n",
    "        df2 = df.loc[genes]\n",
    "        df2 = np.log2(df2+1)\n",
    "        df2 = df2.T\n",
    "        sb.clustermap(df2,cmap=cmapSpecial,row_cluster=False,yticklabels=1,xticklabels=1)\n",
    "        if(fraction):\n",
    "            title=path+', percent of Samples Outlier-Shifted for each Gene'\n",
    "        else:\n",
    "            title=path+', Log2 of Samples Outlier-Shifted for each Gene'\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        print(title)\n",
    "    return 1\n",
    "def __getCorrectionVersion(*args,place,fixOutliers=True):\n",
    "    dfLst=[];nameLst=[]\n",
    "    for num in args:\n",
    "        if(num==0):\n",
    "            if(fixOutliers):\n",
    "                df = pd.read_csv('Purity/TPM/Outliers Fixed/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "            else:\n",
    "                df = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t');__renameTPM(df)\n",
    "                df = np.log2(df+1);df = pd.DataFrame(stats.zscore(df,axis=1),df.index,columns=df.columns)\n",
    "                pDf = __pureDf(df);df = df[pDf.columns]\n",
    "            df.dropna(inplace=True)\n",
    "        else:\n",
    "            direct = 'Purity/TPM/v'+str(num)+'/'\n",
    "            df = pd.read_csv(direct+'TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t');pDf = __pureDf(df);df = df[pDf.columns]\n",
    "        if(num==0):name = 'Per-Purity'\n",
    "        else:name = 'Version '+str(num)\n",
    "        dfLst.append(df);nameLst.append(name)\n",
    "    return dfLst,nameLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __heatDF(dfIn,insert=0,zscore=False):\n",
    "    df = dfIn.copy();__renameTPM(df)\n",
    "    hot, cold = __getHotCold(dfIn);candLst=['CD8A','GZMA','GZMB','PRF1']\n",
    "    df2 = dfIn.loc[candLst];mean = df2.mean()\n",
    "    if(zscore):mean = pd.Series(stats.zscore(mean),index=mean.index)\n",
    "    df = df.T;df.insert(insert,'Heat Scores',mean);df = df.T\n",
    "    return df, hot, cold \n",
    "def shareData(palceLst,dicIn,directory,outName=''):\n",
    "    lst=[]\n",
    "    for path in dicIn:\n",
    "        dic = dicIn[path];genes = __runGenes(dic);lst.extend(genes)\n",
    "    for place in tq(palceLst,desc='Share Data'):\n",
    "        df = pd.read_csv('Purity/TPM/'+directory+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        genes = __goodGenes(lst,df.index);df = df.loc[genes];df, hot, cold = __heatDF(df,place,len(df.index));hcDeg=[]\n",
    "        for col in df:\n",
    "            if(col in hot.columns):hcDeg.append(1)\n",
    "            else:\n",
    "                if(col in cold.columns):hcDeg.append(2)\n",
    "                else:hcDeg.append(0)\n",
    "        df = df.T;df['HC Designation, 1-Hot, 2-Cold, Neither-0'] = hcDeg\n",
    "        df = df.T;df.to_csv('Share Data/'+place+outName+'_HeatScoreAndDesignation.csv')\n",
    "    return 1\n",
    "def masterPlotPurity(placeLst,*args,dic,allPath=False,onlySkinny=False,noSkinnys=False,\n",
    "                     size=(30,10),font=1.5,meth='spearman',corrNum=0,regLine=False,regLine2=False,\n",
    "                     regLineNum=0,regLineNum2=1,corThres=0.1,corLimit=False,fixOutliers=True,skip=[],save=False):\n",
    "    start=time.time()\n",
    "    if(save):\n",
    "        for img in glob.glob('Saved Images/*'):os.remove(img)\n",
    "    for place in placeLst:\n",
    "        __masterPlotPurityHelp(place,*args,dic=dic,allPath=allPath,onlySkinny=onlySkinny,noSkinnys=noSkinnys,\n",
    "                               size=size,font=font,meth=meth,corrNum=corrNum,regLine=regLine,regLine2=regLine2,\n",
    "                               regLineNum=regLineNum,regLineNum2=regLineNum2,corThres=corThres,\n",
    "                               corLimit=corLimit,fixOutliers=fixOutliers,skip=skip,save=save)\n",
    "    end=time.time();total = (end-start)/60\n",
    "    return total\n",
    "def __masterPlotPurityHelp(place,*args,dic,allPath=False,onlySkinny=False,noSkinnys=False,\n",
    "                           size=(30,10),font=1.5,meth='spearman',corrNum=0,regLine=False,\n",
    "                           regLine2=False,regLineNum=0,regLineNum2=1,corThres=0.1,corLimit=False,\n",
    "                           fixOutliers=True,skip=[],save=False):\n",
    "    if not place in skip:\n",
    "        dfLst, nameLst = __getCorrectionVersion(*args,place=place,fixOutliers=fixOutliers);nameLst2=[]\n",
    "        for name in nameLst:\n",
    "            name=name.split('.2')[0]+', Skinny Corrected';nameLst2.append(name)\n",
    "        __plotPurityCorrection2(dfLst,nameLst2,dicIn=dic,allPath=allPath,onlySkinny=onlySkinny,\n",
    "                                size=size,font=font,place=place,meth=meth,noSkinnys=noSkinnys,corrNum=corrNum,\n",
    "                                regLine=regLine,regLine2=regLine2,corThres=corThres,corLimit=corLimit,save=save,\n",
    "                                regLineNum=regLineNum,regLineNum2=regLineNum2)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __plotPurityCorrection2(dfLst,nameLst,dicIn,allPath=False,onlySkinny=False,noSkinnys=False,\n",
    "                            size=(15,5),font=1.5,place='',meth='spearman',corrNum=0,diffCorr=False,\n",
    "                            corrDict={},regLine=True,regLineNum=0,regLine2=False,regLineNum2=1,\n",
    "                            corThres=0.1,corLimit=False,save=False):\n",
    "    dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "    dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t')\n",
    "    __renameTPM(dfHeat)\n",
    "    hot,cold = __getHotCold(dfHeat)\n",
    "    notHotCold = __notHotOrCold(dfHeat,hot,cold)\n",
    "    inputs = dicIn\n",
    "    out = Parallel(n_jobs=3)(delayed(__plotPurityCorrection2Help)\n",
    "                                     (path,hot,cold,notHotCold,dicIn,dfLst,nameLst,allPath,onlySkinny,noSkinnys,size,font,place,\n",
    "                                      meth,corrNum,diffCorr,corrDict,regLine,regLineNum,\n",
    "                                      regLine2,regLineNum2,corThres,corLimit,save) for path in inputs)\n",
    "    return out\n",
    "def __plotPurityCorrection2Help(path,hot,cold,notHotCold,dicIn,dfLst,nameLst,allPath,onlySkinny,noSkinnys=False,\n",
    "                                size=(15,5),font=1.5,place='',meth='spearman',corrNum=0,diffCorr=False,\n",
    "                                corrDict={},regLine=True,regLineNum=0,regLine2=False,regLineNum2=1,\n",
    "                                corThres=0.1,corLimit=False,save=False):\n",
    "    sb.set(font_scale=font)\n",
    "    title=''\n",
    "    colors = ['white','gray','orange','purple','aqua','yellow','brown','pink','navy','maroon']\n",
    "    if(allPath):\n",
    "        fig, axes = plt.subplots(nrows=round(len(dfLst)/2), ncols=2, figsize=size)\n",
    "        ax1 = axes[0]\n",
    "        ax2 = axes[1]\n",
    "        fig.tight_layout(pad=3)\n",
    "    df2Lst=[]\n",
    "    dic = dicIn[path]\n",
    "    genes = __runGenes(dic)\n",
    "    for df in dfLst:\n",
    "        genes = __goodGenes(genes,df.index)\n",
    "        dfPath = df.loc[genes]\n",
    "        colorNum=0\n",
    "        movedColor=False\n",
    "        colorsLen = len(colors)\n",
    "        pDf = __pureDf(dfPath)\n",
    "        goodHotCols = __goodGenes(hot.columns,pDf.columns)\n",
    "        goodColdCols = __goodGenes(cold.columns,pDf.columns)\n",
    "        goodNCols = __goodGenes(notHotCold.columns,pDf.columns)\n",
    "        cold = df[goodColdCols]\n",
    "        hot = df[goodHotCols]\n",
    "        notHotCold = df[goodNCols]\n",
    "        hotX = pDf[goodHotCols].loc['Purity Scores']\n",
    "        hotXInd = __noDupsLst(hotX.index)\n",
    "        hotX = hotX[hotXInd]\n",
    "        coldX = pDf[goodColdCols].loc['Purity Scores']\n",
    "        coldXInd = __noDupsLst(coldX.index)\n",
    "        coldX = coldX[coldXInd]\n",
    "        notX = pDf[goodNCols].loc['Purity Scores']\n",
    "        notXInd = __noDupsLst(notX.index)\n",
    "        notX = notX[notXInd]\n",
    "        df1Cor = pDf.T.corr(method=meth)['Purity Scores']\n",
    "        df2Lst.append((df,pDf,df1Cor,hot,cold,notHotCold,hotX,coldX,notX))\n",
    "    for gene in genes:\n",
    "        printName=False\n",
    "        if not(gene=='Purity Scores'):\n",
    "            dfNum=0\n",
    "            for dfTup in df2Lst:\n",
    "                df = dfTup[0]\n",
    "                pDf = dfTup[1]\n",
    "                df1Cor = dfTup[2]\n",
    "                hot=dfTup[3]\n",
    "                cold=dfTup[4]\n",
    "                notHotCold=dfTup[5]\n",
    "                hotX = dfTup[6]\n",
    "                coldX = dfTup[7]\n",
    "                notX = dfTup[8]\n",
    "                x = pDf.loc['Purity Scores']    \n",
    "                y = pDf.loc[gene]\n",
    "                geneCor = df1Cor.loc[gene]\n",
    "                residual=True\n",
    "                if(len(y.index)==0 or len(y.values)==0):\n",
    "                    residual = False\n",
    "                    break\n",
    "                if(onlySkinny and not __skinyGene(y) and dfNum==0):\n",
    "                    residual = False\n",
    "                    break\n",
    "                if(noSkinnys and __skinyGene(y) and dfNum==0):\n",
    "                    residual = False\n",
    "                    break\n",
    "                if(corLimit and abs(geneCor)<(corThres) and dfNum==0):\n",
    "                    residual = False\n",
    "                    break\n",
    "                if(dfNum==0):\n",
    "                    fig, axes = plt.subplots(nrows=round(len(dfLst)/2), ncols=2, figsize=size)\n",
    "                    fig.tight_layout(pad=3)\n",
    "                    printName=True\n",
    "                if(allPath):\n",
    "                    if(residual):\n",
    "                        if(max(y)>5 or min(y)<-5):\n",
    "                            colorVal = colorNum % colorsLen;colorNum += 1\n",
    "                            movedColor=True;color = colors[colorVal];ax1.plot(x,y,'o',label=gene,color=color)\n",
    "                        else:\n",
    "                            hotY = hot.loc[gene];coldY = cold.loc[gene];notY = notHotCold.loc[gene]\n",
    "                            ax1.plot(hotX,hotY,'o',color='red',label='')\n",
    "                            ax1.plot(coldX,coldY,'o',color='blue',label='');ax1.plot(notX,notY,'o',color='black',label='')\n",
    "                        if(max(residual)>5 or min(residual)<-5):\n",
    "                            if not(movedColor):\n",
    "                                colorVal = colorNum % colorsLen;colorNum += 1;color = colors[colorVal]\n",
    "                            movedColor=False;ax2.plot(x,residual,'o',label=gene,color=color)\n",
    "                        else:\n",
    "                            hotRes = residual.loc[goodHotCols];coldRes = residual.loc[goodColdCols]\n",
    "                            notRes = residual.loc[goodNCols];ax2.plot(hotX,hotRes,'o',color='red',label='')\n",
    "                            ax2.plot(coldX,coldRes,'o',color='blue',label='');ax2.plot(notX,notRes,'o',color='black',label='')\n",
    "            \n",
    "                else:\n",
    "                    if(residual):\n",
    "                        geneCor = df1Cor.loc[gene];col = int(dfNum/2);row = dfNum%2\n",
    "                        if((len(dfLst)/2)<=1):ax = axes[row]\n",
    "                        else:ax = axes[col][row]\n",
    "                        ax.set_facecolor('white');ax.spines[\"top\"].set_color('black');ax.spines[\"bottom\"].set_color('black')\n",
    "                        ax.spines[\"right\"].set_color('black');ax.spines[\"left\"].set_color('black')\n",
    "                        ax.spines[\"top\"].set_lw(4);ax.spines[\"bottom\"].set_lw(4);ax.spines[\"right\"].set_lw(4)\n",
    "                        ax.spines[\"left\"].set_lw(4);hotY = hot.loc[gene];hotYInd = __noDupsLst(hotY.index)\n",
    "                        hotY = hotY[hotYInd];coldY = cold.loc[gene];coldYInd = __noDupsLst(coldY.index)\n",
    "                        coldY = coldY[coldYInd];notY = notHotCold.loc[gene];notYInd = __noDupsLst(notY.index)\n",
    "                        notY = notY[notYInd];ax.plot(hotX,hotY,'o',label='Hot',color='red')\n",
    "                        ax.plot(coldX,coldY,'o',label='Cold',color='blue');\n",
    "                        ax.plot(notX,notY,'o',label='Neither',color='black')\n",
    "                        if(regLine and regLineNum==dfNum):\n",
    "                            try:m, b = np.polyfit(x, y, 1)\n",
    "                            except:m, b = np.polyfit(x, y, 1)\n",
    "                            reggressionLine = m*x + b;ax.plot(x,reggressionLine,label='Reg Line',color='black')\n",
    "                        if(regLine2 and regLineNum2==dfNum):\n",
    "                            minArea = y.min() + 0.4;y2 = y[y > minArea];y2Ind = __noDupsLst(y2.index)\n",
    "                            y2Ind = __goodGenes(y2Ind,x.index);y2 = y2[y2Ind];y2.dropna(inplace=True);x2 = x.loc[y2.index]\n",
    "                            try:m, b = np.polyfit(x2, y2, 1)\n",
    "                            except:m, b = np.polyfit(x2, y2, 1)\n",
    "                            reggressionLine = m*x + b;ax.plot(x,reggressionLine,label='Reg Line',color='black')\n",
    "                        ax.set_xlim([min(min(hotX),min(coldX),min(notX))-0.025,1.025]);ax.set_ylim(-2.5,4)\n",
    "                        ax.set_xlabel('Purity Score');ax.set_ylabel('ZScore')\n",
    "                        if(dfNum==0):\n",
    "                            ax.legend(loc=(1,1.1));title = place+', '+path+', '+gene+', '+nameLst[dfNum]\n",
    "                        else:title = nameLst[dfNum]\n",
    "                        if __skinyGene(y) and dfNum==0:title = title+', Is Skinny'\n",
    "                        if(regLine and dfNum == regLineNum):title = title+', Reg Line for v8'\n",
    "                        if(regLine2 and dfNum == regLineNum2):title = title+', Reg Line for v7'\n",
    "                        title2 = title\n",
    "                        if(diffCorr):\n",
    "                            if(dfNum>1):title2 = title+', Corr to other Version = '+str(round(corrDict[gene],3))\n",
    "                        ax.set_title(title2)\n",
    "                dfNum =dfNum+1\n",
    "            if(printName):\n",
    "                title = place+', '+path+', '+gene+', '+meth\n",
    "                if(onlySkinny):\n",
    "                    title = title+', Only Skinny'\n",
    "                if(noSkinnys):\n",
    "                    title = title+', No Skinnys'\n",
    "                if(save):\n",
    "                    plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "                plt.show();print(title)\n",
    "    if(allPath):\n",
    "        ax1.set_xlabel('Purity Score');ax1.set_ylabel('ZScore');ax1.set_title(place+', '+path+', Pre-Purity')\n",
    "        ax2.legend(ncol=6,loc=(-1,-0.6));ax2.set_xlabel('Purity Score')\n",
    "        ax2.set_ylabel('ZScore');ax2.set_title(place+', '+path+', Post-Purity');title = place+', '+path+', All Genes'\n",
    "        if(save):\n",
    "            plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "        plt.show();print(title)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __removeBadPlace(df,thres=0.9):\n",
    "    out=[]\n",
    "    for gene in df.index:\n",
    "        df2 = df.loc[gene];zeros = list(df2).count(0);total = len(list(df2));percent = zeros/total\n",
    "        if(percent <= thres):out.append(gene)\n",
    "    dfOut = df.loc[out]\n",
    "    return dfOut\n",
    "\n",
    "def plotHeatCorr(placeLst,directory='All But Skinny Corrected, Shift Zeros',meth='spearman',geneSets=True\n",
    "                ,badCorr=False,negCorr=False,Dict={}):\n",
    "    \"\"\"\n",
    "    plotHeatCorr:\n",
    "                Inputs:\n",
    "                        placeLst, list of cancer areas you want plotted\n",
    "                            no default\n",
    "                        directory, directory where the purity correction version you want plotted is\n",
    "                            default = 'All But Skinny Corrected, Shift Zeros'\n",
    "                        meth, the method for correlation to heat\n",
    "                            default = 'spearman'\n",
    "                        geneSets, badCorr and negCorr, 3 booleans telling what to highlight on top of the plot\n",
    "                                                       which genesets the gene came from (geneSets=True)\n",
    "                                                       if it was skinny (badCorr=True)\n",
    "                                                       or if it wad negativley correlated with purity (negCorr=True)\n",
    "                            default = geneSets(True), badCorr(False), negCorr(False)\n",
    "                        Dict, the dictionary for the genes in the superLst\n",
    "                            default is overAllDict\n",
    "    \"\"\"\n",
    "    dfLst =[]\n",
    "    num=0\n",
    "    colorLst = sb.color_palette(\"Set1\",n_colors=len(placeLst))\n",
    "    for place in tq(placeLst,desc='dfLst'):\n",
    "        color = colorLst[num]\n",
    "        num += 1\n",
    "        filename = 'Purity/TPM/'+directory+'/TCGA_'+place+'_tpm.tsv'\n",
    "        prePure = pd.read_csv(filename,index_col=0,sep='\\t')\n",
    "        prePureReal = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "        __renameTPM(prePureReal)\n",
    "        __renameTPM(prePure)\n",
    "        df, hot, cold = __heatDF(prePure,place)\n",
    "        prePure = prePure[df.columns]\n",
    "        prePureReal = prePureReal[df.columns]\n",
    "        df = df.loc['Heat Scores']\n",
    "        dfLst.append((df,prePure,color,prePureReal))\n",
    "        \n",
    "    for path in tq(Dict,desc='Plot'):\n",
    "        colColrs=[]\n",
    "        badNumLst=[]\n",
    "        pathDict = Dict[path]\n",
    "        genes = __runGenes(pathDict)\n",
    "        for dfTup in dfLst:\n",
    "            prePure = dfTup[1]\n",
    "            prePureReal = dfTup[3]\n",
    "            goodPathGSEA = __goodGenes(genes,prePure.index)\n",
    "            cor = prePure.loc[goodPathGSEA].T.corr(method=meth)\n",
    "            color = dfTup[2]\n",
    "            badLst=[]\n",
    "            if(badCorr):\n",
    "                badLst = __getPurityLst(cor,0.5,'Down',0,percent=True)\n",
    "            if(negCorr):\n",
    "                badLst=[]\n",
    "                pathGenes = __goodGenes(genes,prePureReal.index)\n",
    "                prePure = prePureReal.loc[pathGenes]\n",
    "                pDf = __pureDf(prePure)\n",
    "                x = pDf.loc['Purity Scores']\n",
    "                for gene in pDf.index:\n",
    "                    if not(gene=='Purity Scores'):\n",
    "                        y = pDf.loc[gene]\n",
    "                        m, b = np.polyfit(x, y, 1)\n",
    "                        if(m<=lessThan):\n",
    "                            badLst.append(gene)\n",
    "            badLst = __goodGenes(badLst,genes)\n",
    "            badDf = __getBads(genes,badLst)\n",
    "            badNum = len(badLst)\n",
    "            badNumLst.append(badNum)\n",
    "            badColor = __getRowColors(badDf,color,'Removed')\n",
    "            colColrs.append(badColor)\n",
    "        if(geneSets):\n",
    "            colColrs=[]\n",
    "            num=0\n",
    "            badNumLst=[]\n",
    "            for db in pathDict:\n",
    "                color = colorLst[num]\n",
    "                num +=1\n",
    "                badLst=[]\n",
    "                badLst = pathDict[db]\n",
    "                badDf = __getBads(genes,badLst)\n",
    "                badNumLst.append(len(badLst))\n",
    "                badColor = __getRowColors(badDf,color,'Removed')\n",
    "                colColrs.append(badColor)\n",
    "        out = pd.DataFrame()\n",
    "        \n",
    "        for gene in genes:\n",
    "            corLst=[]\n",
    "            if not(gene=='Heat Score'):\n",
    "                for dfTup in dfLst:\n",
    "                    df = dfTup[0]\n",
    "                    df2 = dfTup[1]\n",
    "                    cor = np.nan\n",
    "                    if (gene in df2.index):\n",
    "                        y = df\n",
    "                        x = df2.loc[gene]\n",
    "                        if(meth=='spearman'):\n",
    "                            cor = stats.spearmanr(x, y)[0]\n",
    "                        if(meth=='pearson'):\n",
    "                            cor = stats.pearsonr(x, y)[0]\n",
    "                    corLst.append(cor)\n",
    "                    \n",
    "            out[gene] = corLst\n",
    "        out.index = placeLst\n",
    "        out.index.name = path\n",
    "        out = out.T.dropna().T\n",
    "        cg = sb.clustermap(out,cmap=cmapSpecial,vmin=-1,vmax=1,col_colors=colColrs,\n",
    "                           yticklabels=1,xticklabels=1)\n",
    "        if (geneSets):\n",
    "            placeLst1=[]\n",
    "            for num in range(len(list(pathDict.keys()))):\n",
    "                key = list(pathDict.keys())[num]\n",
    "                badLen = badNumLst[num]\n",
    "                placeLst1.append(key+' total genes in db: '+str(badLen))\n",
    "        else:\n",
    "            placeLst1=[]\n",
    "            for num in range(len(placeLst)):\n",
    "                p = placeLst[num]\n",
    "                l = badNumLst[num]\n",
    "                p1 = p+' '+str(l)\n",
    "                placeLst1.append(p1)\n",
    "        for x,y in zip(placeLst1, colorLst):\n",
    "            cg.ax_heatmap.plot(0, 0, color=y, label=x, solid_capstyle=\"butt\")\n",
    "    \n",
    "        cg.ax_heatmap.set_xlabel(directory)\n",
    "        cg.ax_heatmap.legend(loc=(1,1.1), title=directory)\n",
    "        title = \"Correlation to Heat, \"+path+', '+meth+', Number of genes = '+str(len(out.columns))+', '+directory\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        print(title)   \n",
    "    return 1\n",
    "\n",
    "def __getGSEALst(cls):\n",
    "    f = open(cls)\n",
    "    n=1\n",
    "    for line in f:\n",
    "        if(n==3):\n",
    "            lst = line.split('\\t')\n",
    "        n += 1\n",
    "    return lst\n",
    "\n",
    "def runGSEA(placeLst,useEveryDict=True,outDir='GSEA Output',inDir='GSEA Input',dbLstIn=[],preRank=False,permNum=1000,\n",
    "            minSize=1,permType='phenotype',method='signal_to_noise',no_plot=True,title='',processes=4,overRide=False,\n",
    "            version='v7'):\n",
    "    \"\"\"runGsea\n",
    "                Input:\n",
    "                    palceLst: list of cancer areas you want to run gsea on \n",
    "                             ,each place needs to have expression and phenotype files (as per GSEA requirments)\n",
    "                    outDir: main directory in which to save the results \n",
    "                            (program will also create directories for date/db/place in order to save all results seperatly)\n",
    "                        default = GSEA Output\n",
    "                    inDir: main directroy where the input files are located (expression/phenotype/gene sets)\n",
    "                        default = 'GSEA Input/'\n",
    "                    title: name given to the outputed directory (other than the current date)\n",
    "    \"\"\"\n",
    "    from datetime import date as dateToday\n",
    "    date = str(dateToday.today())\n",
    "    outdir1=outDir+'/'+date+title\n",
    "    if not os.path.exists(outdir1):\n",
    "        os.makedirs(outdir1)\n",
    "    if useEveryDict:\n",
    "        dbLst = list(everyDict['T-effector'].keys())\n",
    "    else:\n",
    "        dbLst = dbLstIn.copy()\n",
    "    for db in tq(dbLst,desc='Running GSEA'):\n",
    "        outdir2=outdir1+'/'+db\n",
    "        if not os.path.exists(outdir2):\n",
    "            os.makedirs(outdir2)\n",
    "        inputs = placeLst\n",
    "        out = Parallel(n_jobs=5)(delayed(__helpRunGSEA)(db,inDir,outdir2,place,preRank,processes,minSize,no_plot,\n",
    "                                                        permNum,permType,method,overRide,version) for place in inputs)\n",
    "    return 1\n",
    "def __helpRunGSEA(db,inDir,outdir2,place,preRank,processes,minSize,no_plot,permNum,permType,method,overRide,version='v7'):\n",
    "    gene_sets=inDir+'/'+'GeneSets/'+db+'_GeneSet.gmt'\n",
    "    outdir3=outdir2+'/'+place\n",
    "    if not os.path.exists(outdir3):\n",
    "        os.makedirs(outdir3)\n",
    "        new=True\n",
    "    else:\n",
    "        new=False\n",
    "    if new or overRide:\n",
    "        data=inDir+'/'+place+'/PostPurity/'+place+'GeneExpressionPostPurity.txt'\n",
    "        cls=inDir+'/'+place+'/PostPurity/'+place+'PostPurityPhenotypeLabels.cls'\n",
    "        lst = __getGSEALst(cls)\n",
    "        rnkFile = inDir+'/Ranks/'+place+'/'+version+'.rnk'\n",
    "        if preRank:\n",
    "            GSEA.prerank(rnk=rnkFile,gene_sets=gene_sets,outdir=outdir3,processes=processes,\n",
    "                         min_size=minSize,no_plot=no_plot,permutation_num=permNum)\n",
    "        else:\n",
    "            out = GSEA.gsea(data=data,gene_sets=gene_sets,cls=lst,outdir=outdir3,processes=processes,\n",
    "                            permutation_num=permNum,min_size=minSize,permutation_type=permType,\n",
    "                            method=method,no_plot=no_plot)\n",
    "    return 1\n",
    "def plotRegDiffGSEA(date1,date2,placeLst,desktop=False,skipImmune=False,allPath=False,onlySkinny=False,\n",
    "                onlyOutliers=False,size=(30,10),font=1.5,meth='spearman',preRank=False,\n",
    "                noSkinnys=False,corrNum=0,regLine=True,regLineNum=0,regLine2=False,regLineNum2=1,corThres=0.1,save=False):\n",
    "    dbLst=[]\n",
    "    for gsea in glob.glob('GSEA Output/'+date1+'/*'):\n",
    "        dbLst.append(gsea.split('\\\\')[-1])\n",
    "    superDfNes1,superDfFdr1 = __superDfGSEA(date1,dbLst,placeLst,desktop=desktop,skipImmune=skipImmune,preRank=preRank)\n",
    "    superDfNes2,superDfFdr2 = __superDfGSEA(date2,dbLst,placeLst,desktop=desktop,skipImmune=skipImmune,preRank=preRank)\n",
    "    totalSize = len(superDfNes1.index)*len(superDfNes1.columns)\n",
    "    print('Total # of Comparisons = '+str(totalSize))\n",
    "    diffLst=[]\n",
    "    bigDiffLst=[]\n",
    "    for idx in superDfNes1.index:\n",
    "        for col in superDfNes1.columns:\n",
    "            elem = superDfNes1.loc[idx][col]\n",
    "            elem2 = superDfNes2.loc[idx][col]\n",
    "            if(np.sign(elem) != np.sign(elem2)):\n",
    "                diffLst.append((col.replace('K_',''),idx))\n",
    "                if(abs(elem-elem2)>=0.3):\n",
    "                    bigDiffLst.append((col.replace('K_',''),idx))\n",
    "    pLst=[]\n",
    "    for test in bigDiffLst:\n",
    "        place = test[0]\n",
    "        if not(place in pLst):\n",
    "            pLst.append(place)\n",
    "    fullLst={}\n",
    "    for p in placeLst:\n",
    "        for i in pLst:\n",
    "            if(i in p):\n",
    "                fullLst[i] = p\n",
    "    dictIn = everyDict.copy()\n",
    "    numDiffPlaceLst=[]\n",
    "    numDiffPathLst=[]\n",
    "    for test in tq(bigDiffLst,desc='plot'):\n",
    "        place = test[0]\n",
    "        path = test[1]\n",
    "        place = fullLst[place]\n",
    "        path1 = path.split('_')\n",
    "        pathDict={}\n",
    "        for path2 in everyDict:\n",
    "            if(path2 == path1[1]):\n",
    "                dic2 = dictIn[path2]\n",
    "                inDict={} \n",
    "                for d in dic2:\n",
    "                    if(d==path1[0]):\n",
    "                        inDict[d]=dic2[d].copy()\n",
    "                        pathDict[path] = inDict\n",
    "        path = test[1]\n",
    "        numDiffPlaceLst.append(place)\n",
    "        numDiffPathLst.append(path)\n",
    "        num1 = date1.split()[1].split('v')[1]\n",
    "        num2 = date2.split()[1].split('v')[1]\n",
    "        dfLst, nameLst = __getCorrectionVersion(0,0,num1,num2,place=place,fixOutliers=True)\n",
    "        __plotPurityCorrection2(dfLst,nameLst,[],pathDict,allPath=allPath,\n",
    "                                onlySkinny=onlySkinny,onlyOutliers=onlyOutliers,\n",
    "                                size=size,font=font,place=place,meth=meth,noSkinnys=noSkinnys,corrNum=corrNum,\n",
    "                                regLine=regLine,regLineNum=regLineNum,regLine2=regLine2,\n",
    "                                regLineNum2=regLineNum2,corThres=corThres,save=save)\n",
    "        \n",
    "    DiffPlace={}\n",
    "    for place in numDiffPlaceLst:\n",
    "        num = numDiffPlaceLst.count(place)\n",
    "        DiffPlace[place] = num\n",
    "    DiffPath={}   \n",
    "    for path in numDiffPathLst:\n",
    "        num = numDiffPathLst.count(path)\n",
    "        DiffPath[path] = num\n",
    "    return DiffPlace, DiffPath\n",
    "def __getSuperLst(dic):\n",
    "    superLst=[]\n",
    "    for path in dic:\n",
    "        lst = __runGenes(dic[path])\n",
    "        for elem in lst:\n",
    "            if not elem in superLst:\n",
    "                superLst.append(elem)\n",
    "    return superLst\n",
    "def plotGeneCorr(placeLst,dicIn,version=7,meth='spearman',metric='cosine',fixPos=False,pos={},\n",
    "               hots=False,colds=False,diff=False):\n",
    "    outDic={}\n",
    "    dfLst=[]\n",
    "    for place in tq(placeLst,desc='dfLst'):\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        if(hots or colds or diff):\n",
    "            dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "            dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t')\n",
    "            __renameTPM(dfHeat)\n",
    "            hot,cold = __getHotCold(dfHeat)\n",
    "            hotCols = __goodGenes(hot.columns,df.columns)\n",
    "            coldCols = __goodGenes(cold.columns,df.columns)\n",
    "            dfLst.append((df,place,hotCols,coldCols))\n",
    "        else:\n",
    "            dfLst.append((df,place))\n",
    "    for path in tq(dicIn,desc='Gene-Gene Corr'):\n",
    "        for dfTup in dfLst:\n",
    "            df = dfTup[0]\n",
    "            place = dfTup[1]\n",
    "            if(hots or colds or diff):\n",
    "                hotCols = dfTup[2]\n",
    "                coldCols = dfTup[3]\n",
    "            \n",
    "            dic2 = dicIn[path]\n",
    "            genes = __runGenes(dic2)\n",
    "            genes = __goodGenes(genes,df.index)\n",
    "            dfPath1 = df.loc[genes]\n",
    "            dfPath2 = dfPath1.copy()\n",
    "            if(hots):\n",
    "                dfPath2 = dfPath2[hotCols]\n",
    "            if(colds):\n",
    "                dfPath2 = dfPath2[coldCols]\n",
    "            corr = dfPath2.T.corr(method=meth)\n",
    "            if(diff):\n",
    "                dfPathH = dfPath1[hotCols]\n",
    "                dfPathC = dfPath1[coldCols]\n",
    "                corrH = dfPathH.T.corr(method=meth)\n",
    "                corrC = dfPathC.T.corr(method=meth)\n",
    "                corr = corrH - corrC\n",
    "            cClus=not(fixPos)\n",
    "            rClus=not(fixPos)\n",
    "            if(fixPos):\n",
    "                tup = pos[place+'_'+path]\n",
    "                row = tup[0]\n",
    "                col = tup[1]\n",
    "                corr = __setCluster(corr,row,col)\n",
    "            cg = sb.clustermap(corr,metric=metric,cmap=cmapSpecial,vmin=-1,vmax=1,yticklabels=0,xticklabels=0,\n",
    "                              col_cluster=cClus,row_cluster=rClus)\n",
    "            if not(fixPos):\n",
    "                row = cg.dendrogram_row.reordered_ind\n",
    "                col = cg.dendrogram_col.reordered_ind\n",
    "            title ='Gen to gene Corr, '\n",
    "            if(hots):\n",
    "                title += 'Only Hots, '\n",
    "            if(colds):\n",
    "                title += 'Only Colds, '\n",
    "            if(diff):\n",
    "                title += 'Diff of Hot and Cold, '\n",
    "            plt.title(title+place+', '+path+', '+meth+', '+metric+', version '+str(version))\n",
    "            plt.show()\n",
    "            print(title+place+', '+path+', '+meth+', '+metric+', version '+str(version))\n",
    "            outDic[place+'_'+path] = (row,col)\n",
    "    return outDic\n",
    "\n",
    "def plotPairsCorr(placeLst,dicIn,version=7,meth='spearman',Num=10,fontSize=10,save=True):\n",
    "    dfLst=[]\n",
    "    for place in placeLst:\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        dfLst.append((df,place))\n",
    "\n",
    "    for path in tq(dicIn,desc='Pairs Corr'):\n",
    "        dic2 = dicIn[path]\n",
    "        genes = __runGenes(dic2)\n",
    "        for dfTup in dfLst:\n",
    "            df = dfTup[0]\n",
    "            placeName = dfTup[1]\n",
    "        \n",
    "            genesP = __goodGenes(genes,df.index)\n",
    "            dfPath = df.loc[genesP]\n",
    "            corr = dfPath.T.corr(method=meth)\n",
    "            for i in range(len(corr.index)):\n",
    "                corr.iloc[i][i] = 0\n",
    "            topPairs = __topN(corr,Num)\n",
    "        \n",
    "            corPLst=[]\n",
    "            for dfTup2 in dfLst:\n",
    "                df2 = dfTup2[0]\n",
    "                genesP = __goodGenes(genes,df2.index)\n",
    "                dfPath = df2.loc[genesP]\n",
    "                corr = dfPath.T.corr(method=meth)\n",
    "                corLst=[]\n",
    "                nameLst=[]\n",
    "                for tup in topPairs:\n",
    "                    g1 = tup[0]\n",
    "                    g2 = tup[1]\n",
    "                    Name = tup[2]\n",
    "                    corV = corr.loc[g1][g2]\n",
    "                    corLst.append(corV)\n",
    "                    nameLst.append(Name)\n",
    "                corPLst.append(corLst)\n",
    "        \n",
    "            out = pd.DataFrame(corPLst,placeLst,columns=nameLst)\n",
    "            cg = sb.heatmap(out,cmap=cmapSpecial,yticklabels=1,xticklabels=1)\n",
    "            plt.setp(cg.get_xticklabels(),rotation=45,ha='right',size=fontSize)\n",
    "            plt.title('Top '+str(Num)+' Correlated Gene Pairs, for '+placeName+', '+path+', '+meth+' version '+str(version))\n",
    "            plt.show()\n",
    "            print('Top '+str(Num)+' Correlated Gene Pairs, for '+placeName+', '+path+', '+meth+' version '+str(version))\n",
    "    return 1\n",
    "\n",
    "def plotKobeGGCorr(placeLst,Dict,version=7,meth='spearman',metric='cosine',save=True,onlyKobe=False,\n",
    "                 fontSize=12,thres=10,hots=False,colds=False,diff=False,fixPos=False,pos={},Path2Path=True):\n",
    "    if(save):\n",
    "        for img in glob.glob('Saved Images/*'):\n",
    "            os.remove(img)\n",
    "    frstDic = list(Dict.keys())[0]\n",
    "    dbLst=[]\n",
    "    if(onlyKobe):\n",
    "        for db in Dict[frstDic]:\n",
    "            dbLst.append(db)\n",
    "        kobeDict = __getDBList(Dict,'KOBE')\n",
    "    else:\n",
    "        kobeDict = Dict.copy()\n",
    "\n",
    "    dfLst=[]\n",
    "    for place in tq(placeLst,desc='dfLst'):\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        \n",
    "        if(hots or colds or diff):\n",
    "            dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "            dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t')\n",
    "            __renameTPM(dfHeat)\n",
    "            hot,cold = __getHotCold(dfHeat)\n",
    "            hotCols = __goodGenes(hot.columns,df.columns)\n",
    "            coldCols = __goodGenes(cold.columns,df.columns)\n",
    "            dfLst.append((df,place,hotCols,coldCols))\n",
    "        else:\n",
    "            dfLst.append((df,place))\n",
    "    \n",
    "    kobeLst={}\n",
    "    for path in kobeDict:\n",
    "        dic2 = kobeDict[path]\n",
    "        lst = __runGenes(dic2)\n",
    "        kobeLst[path]=lst\n",
    "    if(Path2Path):\n",
    "        outDic = __plotKobeGGCorr1(kobeLst,dfLst,placeLst,hots,colds,\n",
    "                                   diff,version,metric,meth,fixPos,pos,thres,fontSize,save,onlyKobe)\n",
    "    else:\n",
    "        outDic = __plotKobeGGCorr2(kobeLst,dfLst,placeLst,hots,colds,\n",
    "                                   diff,version,metric,meth,fixPos,pos,thres,fontSize,save,onlyKobe)\n",
    "    return outDic\n",
    "\n",
    "def __plotKobeGGCorr1(kobeLst,dfLst,placeLst,hots,colds,diff,version,metric,meth,fixPos,pos,thres,fontSize,save,onlyKobe):\n",
    "    outDic={}\n",
    "    runLst = list(kobeLst.keys())\n",
    "    for pathNum in tq(range(len(runLst)),desc='Gene Pair Corr'):\n",
    "        path1 = runLst[pathNum]\n",
    "        for path2Num in range(pathNum,len(runLst)):\n",
    "            path2 = runLst[path2Num]\n",
    "            if path2 != path1:\n",
    "                lst1 = kobeLst[path1]\n",
    "                lst2 = kobeLst[path2]\n",
    "                for dfTup in dfLst:\n",
    "                    df = dfTup[0]\n",
    "                    lst1 = __goodGenes(lst1,df.index)\n",
    "                    lst2 = __goodGenes(lst2,df.index)\n",
    "                corPLst=[]\n",
    "                for dfTup in dfLst:\n",
    "                    df = dfTup[0]\n",
    "                    if(hots or colds or diff):\n",
    "                        hotCols = dfTup[2]\n",
    "                        coldCols = dfTup[3]\n",
    "                    corrLst=[]\n",
    "                    nameLst=[]\n",
    "                    for elem1 in lst1:\n",
    "                        for elem2 in lst2:\n",
    "                            ser1 = df.loc[elem1]\n",
    "                            ser2 = df.loc[elem2]\n",
    "                            corr = ser1.corr(ser2,method=meth)\n",
    "                            if(hots):\n",
    "                                serH1 = ser1[hotCols]\n",
    "                                serH2 = ser2[hotCols]\n",
    "                                corrH = serH1.corr(serH2,method=meth)\n",
    "                                corr = corrH\n",
    "                            if(colds):\n",
    "                                serC1 = ser1[coldCols]\n",
    "                                serC2 = ser2[coldCols]\n",
    "                                corrC = serC1.corr(serC2,method=meth)\n",
    "                                corr = corrC\n",
    "                            corrLst.append(corr)\n",
    "                            nameLst.append(elem1+', '+elem2)\n",
    "                    corPLst.append(corrLst)\n",
    "                out = pd.DataFrame(corPLst,placeLst,columns=nameLst)\n",
    "                out.index.name = 'Cancer Areas'\n",
    "                __addKs(out,axis=0,lst=kobePlaceLst1,inplace=True)\n",
    "                out.index = getUniqueNames(out.index)\n",
    "                out = out.T\n",
    "                out.index.name = 'Gene Pairings'\n",
    "                \n",
    "                cClus=not(fixPos)\n",
    "                rClus=not(fixPos)\n",
    "                if(fixPos):\n",
    "                    tup = pos[path1+'_'+path2]\n",
    "                    row = tup[0]\n",
    "                    col = tup[1]\n",
    "                    out = __setCluster(out,row,col)\n",
    "                cg = sb.clustermap(out,cmap=cmapSpecial,xticklabels=1,yticklabels=1,metric=metric,\n",
    "                                  col_cluster=cClus,row_cluster=rClus)\n",
    "                if not(fixPos):\n",
    "                    row = cg.dendrogram_row.reordered_ind\n",
    "                    col = cg.dendrogram_col.reordered_ind\n",
    "                \n",
    "                addOn = len(cg.ax_heatmap.get_yticklabels()) / thres\n",
    "                newFont = fontSize - addOn\n",
    "                plt.setp(cg.ax_heatmap.get_yticklabels(),rotation=45,va='bottom',size=newFont)\n",
    "                title = path1+' to '+path2+', '\n",
    "                if(onlyKobe):\n",
    "                    title += 'Kobe Database Gene Correlation, '\n",
    "                else:\n",
    "                    title += 'Pathway Gene Gene Correlation'\n",
    "                if(hots):\n",
    "                    title += 'Only Hot Samples, '\n",
    "                if(colds):\n",
    "                    title += 'Only Cold Samples, '\n",
    "                if(diff):\n",
    "                    title += 'Diff of Hot Corr and Cold Corr, '\n",
    "                title = title+meth+', '+metric+', version '+str(version)\n",
    "                plt.title(title)\n",
    "                #plt.tight_layout()\n",
    "                if(save):\n",
    "                    plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "                plt.show()    \n",
    "                print(title)\n",
    "                outDic[path1+'_'+path2] = (row,col)\n",
    "    return outDic\n",
    "\n",
    "def __plotKobeGGCorr2(kobeLst,dfLst,placeLst,hots,colds,diff,version,metric,meth,fixPos,pos,thres,fontSize,save,onlyKobe):\n",
    "    outDic={};runLst = list(kobeLst.keys())\n",
    "    for pathNum in tq(range(len(runLst)),desc='Gene Pair Corr'):\n",
    "        path1 = runLst[pathNum];lst1 = kobeLst[path1]\n",
    "        for dfTup in dfLst:\n",
    "            df = dfTup[0];lst1 = __goodGenes(lst1,df.index)\n",
    "        corPLst=[]\n",
    "        for dfTup in tq(dfLst,desc='places for '+path1):\n",
    "            df = dfTup[0]\n",
    "            if(hots or colds or diff):\n",
    "                hotCols = dfTup[2];coldCols = dfTup[3]\n",
    "            corrLst=[];nameLst=[]\n",
    "            for num1 in range(len(lst1)):\n",
    "                elem1 = lst1[num1]\n",
    "                for num2 in range(num1,len(lst1)):\n",
    "                    elem2 = lst1[num2]\n",
    "                    if not elem1 == elem2:\n",
    "                        ser1 = df.loc[elem1];ser2 = df.loc[elem2];corr = ser1.corr(ser2,method=meth)\n",
    "                        if(hots):\n",
    "                            serH1 = ser1[hotCols];serH2 = ser2[hotCols]\n",
    "                            corrH = serH1.corr(serH2,method=meth);corr = corrH\n",
    "                        if(colds):\n",
    "                            serC1 = ser1[coldCols];serC2 = ser2[coldCols]\n",
    "                            corrC = serC1.corr(serC2,method=meth);corr = corrC\n",
    "                        corrLst.append(corr);nameLst.append(elem1+', '+elem2)\n",
    "            corPLst.append(corrLst)\n",
    "        out = pd.DataFrame(corPLst,placeLst,columns=nameLst)\n",
    "        out.index.name = 'Cancer Areas';__addKs(out,axis=0,lst=kobePlaceLst1,inplace=True)\n",
    "        out.index = getUniqueNames(out.index);out = out.T;out.index.name = 'Gene Pairings';cClus=not(fixPos);rClus=not(fixPos)\n",
    "        if(fixPos):\n",
    "            tup = pos[path1+'_'+path2];row = tup[0];col = tup[1];out = __setCluster(out,row,col)\n",
    "        cg = sb.clustermap(out,cmap=cmapSpecial,xticklabels=1,yticklabels=1,metric=metric,\n",
    "                          col_cluster=cClus,row_cluster=rClus)\n",
    "        if not(fixPos):\n",
    "            row = cg.dendrogram_row.reordered_ind;col = cg.dendrogram_col.reordered_ind\n",
    "        addOn = len(cg.ax_heatmap.get_yticklabels())/thres;newFont = fontSize - addOn\n",
    "        plt.setp(cg.ax_heatmap.get_yticklabels(),rotation=45,va='bottom',size=newFont);title = path1+', '\n",
    "        if(onlyKobe):title += 'Kobe Database Gene Correlation, '\n",
    "        else:title += 'Pathway Gene Gene Correlation'\n",
    "        if(hots):title += 'Only Hot Samples, '\n",
    "        if(colds):title += 'Only Cold Samples, '\n",
    "        if(diff):title += 'Diff of Hot Corr and Cold Corr, '\n",
    "        title = title+meth+', '+metric+', version '+str(version);plt.title(title)\n",
    "        if(save):plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "        plt.show();print(title);outDic[path1] = (row,col)\n",
    "    return outDic\n",
    "\n",
    "def plotKobePPCorr(placeLst,Dict,meth='spearman',metric='cosine',ver=7,fixPos=False,pos=(),\n",
    "                  hots=False,colds=False,diff=False,save=False,repeat=True):\n",
    "    frstDic = list(Dict.keys())[0]\n",
    "    dbLst=[]\n",
    "    for db in Dict[frstDic]:\n",
    "        dbLst.append(db)\n",
    "    kobeDict = __getDBList(Dict,'KOBE')\n",
    "\n",
    "    dfLst=[]\n",
    "    for place in placeLst:\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(ver)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        \n",
    "        if((hots or colds or diff) and not repeat):\n",
    "            dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "            dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t')\n",
    "            __renameTPM(dfHeat)\n",
    "            hot,cold = __getHotCold(dfHeat)\n",
    "            hotCols = __goodGenes(hot.columns,df.columns)\n",
    "            coldCols = __goodGenes(cold.columns,df.columns)\n",
    "            dfLst.append((df,place,hotCols,coldCols))\n",
    "        else:\n",
    "            dfLst.append((df,place))\n",
    "    \n",
    "    kobeLst={}\n",
    "    for path in kobeDict:\n",
    "        dic2 = kobeDict[path]\n",
    "        lst = __runGenes(dic2)\n",
    "        kobeLst[path]=lst\n",
    "\n",
    "    runLst = list(kobeLst.keys())\n",
    "    corPLst=[]\n",
    "    nameLst=[]\n",
    "    for pathNum in range(len(runLst)):\n",
    "        path1 = runLst[pathNum]\n",
    "        for path2Num in range(pathNum,len(runLst)):\n",
    "            path2 = runLst[path2Num]\n",
    "            if path2 != path1:\n",
    "                lst1 = kobeLst[path1]\n",
    "                lst2 = kobeLst[path2]\n",
    "                for dfTup in dfLst:\n",
    "                    df = dfTup[0]\n",
    "                    lst1 = __goodGenes(lst1,df.index)\n",
    "                    lst2 = __goodGenes(lst2,df.index)\n",
    "                \n",
    "                corrLst=[]\n",
    "                for dfTup in dfLst:\n",
    "                    df = dfTup[0]\n",
    "                    if((hots or colds or diff) and not repeat):\n",
    "                        hotCols = dfTup[2]\n",
    "                        coldCols = dfTup[3]    \n",
    "                    ser1 = df.loc[lst1].mean()\n",
    "                    ser2 = df.loc[lst2].mean()\n",
    "                    corr = ser1.corr(ser2,method=meth)\n",
    "                    if(hots and not repeat):\n",
    "                        serH1 = ser1[hotCols]\n",
    "                        serH2 = ser2[hotCols]\n",
    "                        corrH = serH1.corr(serH2,method=meth)\n",
    "                        corr = corrH\n",
    "                    if(colds and not repeat):\n",
    "                        serC1 = ser1[coldCols];serC2 = ser2[coldCols]\n",
    "                        corrC = serC1.corr(serC2,method=meth);corr = corrC\n",
    "                    corrLst.append(corr)\n",
    "                nameLst.append(path1+', '+path2);corPLst.append(corrLst)\n",
    "    out = pd.DataFrame(corPLst,nameLst,columns=placeLst);out.index.name='Paths'\n",
    "    __addKs(out,lst=kobePlaceLst1,inplace=True);out.columns = getUniqueNames(out.columns)\n",
    "    out = out.T;out.index.name='Cancer Areas';out = out.T;cClus=not(fixPos);rClus=not(fixPos)\n",
    "    if(fixPos):\n",
    "        row, col = pos;out = __setCluster(out,row,col)\n",
    "    cg=sb.clustermap(out,cmap=cmapSpecial,col_cluster=cClus,row_cluster=rClus,metric=metric,yticklabels=1,xticklabels=1)\n",
    "    if not fixPos:\n",
    "        row = cg.dendrogram_row.reordered_ind;col = cg.dendrogram_col.reordered_ind\n",
    "    title = 'Kobe Database Pathway Pathway Correlation, '\n",
    "    if(hots and not repeat):title = title +'Only Hot Samples,'\n",
    "    if(colds and not repeat):title = title+'Only Cold Samples, '\n",
    "    title = title+' correction version '+str(ver)+', '+meth+', '+metric\n",
    "    plt.title(title)\n",
    "    if(save):\n",
    "        plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "    print(title)\n",
    "    \n",
    "    if(hots and repeat):\n",
    "        plotKobePPCorr(placeLst,Dict,meth,metric,ver,fixPos=True,pos=(row,col),\n",
    "                       hots=True,save=save,repeat=False)\n",
    "    if(colds and repeat):\n",
    "        plotKobePPCorr(placeLst,Dict,meth,metric,ver,fixPos=True,pos=(row,col),\n",
    "                       colds=True,save=save,repeat=False)\n",
    "    return 1\n",
    "def plotGeneCorrAll(placeLst,dicIn,version=7,meth='spearman',metric='cosine',\n",
    "                    hots=False,colds=False,diff=False,fixPos=False,pos={},indivPlaces=False,save=False):\n",
    "    if(save):\n",
    "        for img in glob.glob('Saved Images/*'):os.remove(img)\n",
    "    outDic={}\n",
    "    frst=True\n",
    "    for place in tq(placeLst,desc='allDF'):\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        if(hots or colds or diff):\n",
    "            dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "            dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t');__renameTPM(dfHeat);hot,cold = __getHotCold(dfHeat)\n",
    "            hotCols = __goodGenes(hot.columns,df.columns);coldCols = __goodGenes(cold.columns,df.columns)\n",
    "        if(diff):\n",
    "            dfH = df[hotCols];dfC = df[coldCols];dfH.index.name='Genes';dfC.index.name='Genes'\n",
    "        else:\n",
    "            if(hots):df = df[hotCols]\n",
    "            if(colds):df = df[coldCols]\n",
    "            df.index.name='Genes'\n",
    "        if(frst):\n",
    "            if(diff):\n",
    "                allDFh = dfH.copy();allDFc = dfC.copy()\n",
    "            else:allDF = df.copy()\n",
    "            frst=False\n",
    "        else:\n",
    "            if(diff):\n",
    "                allDFh = allDFh.merge(dfH,on='Genes');allDFh = allDFc.merge(dfH,on='Genes')\n",
    "            else:allDF = allDF.merge(df,on='Genes')\n",
    "    if(indivPlaces):\n",
    "        dfLst=[]\n",
    "        for place in tq(placeLst,desc='dfLst'):\n",
    "            df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "            if(hots or colds or diff):\n",
    "                dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "                dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t')\n",
    "                __renameTPM(dfHeat);hot,cold = __getHotCold(dfHeat)\n",
    "                hotCols = __goodGenes(hot.columns,df.columns);coldCols = __goodGenes(cold.columns,df.columns)\n",
    "            if(diff):dfH = df[hotCols];dfC = df[coldCols]\n",
    "            else:\n",
    "                if(hots):df = df[hotCols]\n",
    "                if(colds):df = df[coldCols]\n",
    "            dfLst.append((df,place))\n",
    "        for path in tq(dicIn,desc='Gene Gene Corr'):    \n",
    "            dic2 = dicIn[path];genes = __runGenes(dic2);genes = __goodGenes(genes,allDF.index)\n",
    "            for dfTup in dfLst:\n",
    "                df = dfTup[0];place = dfTup[1];genes = __goodGenes(genes,df.index);dfPath = df.loc[genes]\n",
    "                corr = dfPath.T.corr(method=meth);cClus=not(fixPos);rClus=not(fixPos)\n",
    "                if(fixPos):\n",
    "                    row,col = pos[path];corr = __setCluster(corr,row,col)\n",
    "                cg = sb.clustermap(corr,metric=metric,cmap=cmapSpecial,vmin=-1,vmax=1,yticklabels=0,xticklabels=0,\n",
    "                                   col_cluster=cClus,row_cluster=rClus)\n",
    "                if not(fixPos):\n",
    "                    row = cg.dendrogram_row.reordered_ind;col = cg.dendrogram_col.reordered_ind\n",
    "                outDic[path] = (row,col)\n",
    "                title = path+', '+meth+', '+metric+', version '+str(version)+', '\n",
    "                title +='Gene to gene Corr '+place+', '\n",
    "                if(hots):title += 'Only Hot Samples'\n",
    "                if(colds):title += 'Only Cold Samples'\n",
    "                plt.title(title)\n",
    "                if(save):plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "                plt.show();print(title)\n",
    "    else:        \n",
    "        for path in tq(dicIn,desc='Gene gene Corr'):    \n",
    "            dic2 = dicIn[path];genes = __runGenes(dic2)\n",
    "            if(diff):\n",
    "                genes = __goodGenes(__goodGenes(genes,allDFh.index),allDFc.index)\n",
    "                dfPathH = allDFh.loc[genes];dfPathC = allDFc.loc[genes]\n",
    "                corrH = dfPathH.T.corr(method=meth);corrC = dfPathC.T.corr(method=meth)\n",
    "                corr = corrH - corrC\n",
    "            else:\n",
    "                genes = __goodGenes(genes,allDF.index);dfPath = allDF.loc[genes];corr = dfPath.T.corr(method=meth)\n",
    "            \n",
    "            cClus=not(fixPos);rClus=not(fixPos)\n",
    "            if(fixPos):\n",
    "                row,col = pos[path];corr = __setCluster(corr,row,col)\n",
    "            cg = sb.clustermap(corr,metric=metric,cmap=cmapSpecial,yticklabels=0,xticklabels=0,\n",
    "                               col_cluster=cClus,row_cluster=rClus,vmin=-1,vmax=1)\n",
    "            if not(fixPos):\n",
    "                row = cg.dendrogram_row.reordered_ind;col = cg.dendrogram_col.reordered_ind\n",
    "            outDic[path] = (row,col)\n",
    "            title = path+', '+meth+', '+metric+', version '+str(version)+', ';title +='Gene to gene Corr All Cancers'\n",
    "            if(diff):title += ', Diff of Hot Corr and Cold Corr'\n",
    "            else:\n",
    "                if(hots):title += ', Only Hot Samples'\n",
    "                if(colds):title += ', Only Cold Samples'\n",
    "            plt.title(title)\n",
    "            if(save):plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "            plt.show();print(title)\n",
    "    return outDic\n",
    "\n",
    "def plotExpression(palceLst,Dict,version=7,save=False):\n",
    "    if(save):\n",
    "        for img in glob.glob('Saved Images/*'):os.remove(img)\n",
    "    frstDic = list(Dict.keys())[0]\n",
    "    dbLst=[]\n",
    "    for db in Dict[frstDic]:dbLst.append(db)\n",
    "    kobeDict = __getDBList(Dict,'KOBE')\n",
    "    for place in tq(placeLst,desc='Plot Expression'):\n",
    "        dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "        dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t')\n",
    "        __renameTPM(dfHeat);hot,cold = __getHotCold(dfHeat)\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        hotCols = __goodGenes(hot.columns,df.columns);coldCols = __goodGenes(cold.columns,df.columns)\n",
    "        hotCold = hotCols + coldCols;colData = __colDataFunc(hotCols,coldCols,groupName='Heat')\n",
    "        col_palette = dict(zip(colData.Heat.unique(), [\"Red\",\"Blue\"])) \n",
    "        col_colors1 = colData.Heat.map(col_palette);rowDict={};geneLst=[]\n",
    "        for path in kobeDict:\n",
    "            dic2 = kobeDict[path];genes = __runGenes(dic2);genes = __goodGenes(genes,df.index)\n",
    "            for elem in genes:\n",
    "                if not elem in geneLst:geneLst.append(elem)\n",
    "            rowDict[path] = genes\n",
    "        colorLst=['Red','Green','Blue','Black','Orange','Purple','Yellow','Gray','Brown'];num = 0;rowColorLst=[]\n",
    "        for pathway in rowDict:\n",
    "            geneLst2 = geneLst.copy()\n",
    "            for elem in rowDict[pathway]:geneLst2.remove(elem)\n",
    "            colData = __colDataFunc(rowDict[pathway],geneLst2,groupName=pathway);color = colorLst[num]\n",
    "            col_palette = dict(zip(colData[pathway].unique(), [color,\"White\"]));rowColor = colData[pathway].map(col_palette)\n",
    "            rowColor = rowColor.loc[geneLst];num += 1;rowColorLst.append(rowColor)\n",
    "        clusDF = df[hotCold].loc[geneLst];clusDF.index.name = 'Genes'\n",
    "        cg = sb.clustermap(clusDF,col_cluster=False,row_cluster=False, cmap=cmapSpecial,standard_scale=None,\n",
    "              row_colors=rowColorLst,col_colors=col_colors1,yticklabels=1,xticklabels=0)\n",
    "        for x,y in zip(list(rowDict.keys()), colorLst):\n",
    "            cg.ax_heatmap.plot(0, 0, color=y, label=x, linewidth=10, solid_capstyle=\"butt\")\n",
    "        cg.ax_heatmap.legend(loc=(-0.5,1), title=\"Pathway\")\n",
    "        title = place+', Gene Expression after Correction V'+str(version);plt.title(title)\n",
    "        if(save):plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "    return 1\n",
    "\n",
    "def plotRegDiffExpr(placeLst,num1,num2,dicIn,allPath=False,onlySkinny=False,noSkinnys=False,onlyOutliers=False,\n",
    "                    corrNum=2,regLine=True,regLineNum=0,regLine2=True,regLineNum2=1,corThres=0.1,size=(30,10),font=1.5,\n",
    "                    meth='spearman',save=False):\n",
    "    if(save):\n",
    "        for img in glob.glob('Saved Images/*'):os.remove(img)\n",
    "    for place in tq(placeLst,desc='Plot Diff'):\n",
    "        dfLst, nameLst = __getCorrectionVersion(0,0,num1,num2,place=place,fixOutliers=True)\n",
    "        v1 = dfLst[2].T;v2 = dfLst[3].T;corr = v2.corrwith(v1,method=meth)\n",
    "        genes = list(corr[corr<0.9].index);corr2 = corr[genes][genes];corrDict = corr2.to_dict();dicIn2={}\n",
    "        for path in dicIn:\n",
    "            dicLst=[];lst = __runGenes(everyDict[path]);diffDic={}\n",
    "            for g in genes:\n",
    "                if g in lst:dicLst.append(g)\n",
    "            diffDic['Diff'] = dicLst;dicIn2[path]=diffDic\n",
    "        __plotPurityCorrection2(dfLst,nameLst,[],dicIn2,allPath=allPath,\n",
    "                                onlySkinny=onlySkinny,onlyOutliers=onlyOutliers,\n",
    "                                size=size,font=font,place=place,meth=meth,noSkinnys=noSkinnys,corrNum=corrNum,\n",
    "                                regLine=regLine,regLineNum=regLineNum,regLine2=regLine2,\n",
    "                                regLineNum2=regLineNum2,corThres=corThres,save=save,diffCorr=True,corrDict=corrDict)\n",
    "    return 1\n",
    "\n",
    "def __totalRunGenes(dicIn):\n",
    "    totalLst=[]\n",
    "    for path in dicIn:\n",
    "        lst = __runGenes(dicIn[path])\n",
    "        for l in lst:\n",
    "            if not l in totalLst:totalLst.append(l)\n",
    "    return totalLst\n",
    "\n",
    "def countSkinnys(placeLst,dicIn):\n",
    "    countLst=[];percentLst=[];genes = __totalRunGenes(dicIn)\n",
    "    for place in tq(placeLst,desc='Counting Skinnies'):\n",
    "        count = 0;dfHeatName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "        dfHeat = pd.read_csv(dfHeatName,index_col=0,sep='\\t');__renameTPM(dfHeat);genes2 = __goodGenes(genes,dfHeat.index) \n",
    "        for g in genes2:\n",
    "            y = dfHeat.loc[g]\n",
    "            if(__skinyGene(y)):count += 1\n",
    "        percent = round(count / len(genes2),3);percent=round(percent*100,1);countLst.append(count);percentLst.append(percent)\n",
    "    dfOut = pd.DataFrame([countLst,percentLst],['Skinny Counts','Skinny Percent'],columns=placeLst).T\n",
    "    newIdx = replaceLst(dfOut.index,'Breast Hormone','Breast HR+');dfOut.index = newIdx\n",
    "    return dfOut\n",
    "\n",
    "def replaceLst(lst,repElm,repWith):\n",
    "    outLst=[]\n",
    "    for l in lst:\n",
    "        if(l==repElm):outLst.append(repWith)\n",
    "        else:outLst.append(l)\n",
    "    return outLst\n",
    "def __dfLstFunc(placeLst,version,idxName=None,pan=False):\n",
    "    dfLst = Parallel(n_jobs=num_cores)(delayed(__dfLstFuncHelp)(place,version,idxName,pan) for place in placeLst)\n",
    "    return dfLst\n",
    "def __dfLstFuncHelp(place,version,idxName=None,pan=False):\n",
    "    df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "    if(idxName):df.index.name=idxName\n",
    "    if(pan):\n",
    "        samples = random.sample(range(0, len(df.columns)),100);df = df.T.iloc[samples].T\n",
    "    return (place,df)\n",
    "def MergeDicts(dict1, dict2): \n",
    "    res = {**dict1, **dict2} \n",
    "    return res\n",
    "\n",
    "def numCancersGG(placeLst,dicIn,skipLst=[],version=7,corThres=0.6,positive=True,fontSize=16):\n",
    "    dfLst = __dfLstFunc(placeLst,version);dfLst.sort()\n",
    "    out = Parallel(n_jobs=num_cores)(delayed(__numCancersGGHelp)(path,dfLst=dfLst,dicIn=dicIn,skipLst=skipLst,\n",
    "                                                                 version=version,corThres=corThres,positive=positive,\n",
    "                                                                 fontSize=fontSize) for path in dicIn)\n",
    "    return 1\n",
    "def __numCancersGGHelp(place,version):\n",
    "    for path in tq(dicIn,desc='G-G'):\n",
    "        if not path in skipLst:\n",
    "            outDict={};genes = __runGenes(dicIn[path])\n",
    "            for df in dfLst:genes = __goodGenes(genes,df.index)\n",
    "            for i in tq(range(len(genes)),desc=path):\n",
    "                g1 = genes[i]\n",
    "                for j in range(i,len(genes)):\n",
    "                    g2 = genes[j]\n",
    "                    if not g1 == g2:\n",
    "                        num = 0 \n",
    "                        for df in dfLst:\n",
    "                            g1E = df.loc[g1];g2E = df.loc[g2]\n",
    "                            pCor = g1E.corr(g2E,method='pearson');sCor = g1E.corr(g2E,method='spearman');value=False\n",
    "                            if(positive):value = (pCor>corThres and sCor>corThres)\n",
    "                            else:value = (pCor<corThres and sCor<corThres)\n",
    "                            if(value):num += 1\n",
    "                        ggLst[num] = 1;outDict[g1+'_'+g2] = ggLst\n",
    "            df = pd.DataFrame.from_dict(outDict, orient='index');plt.figure(figsize=(40,20))\n",
    "            cg = sb.heatmap(df,cmap='Greys',yticklabels=0,xticklabels=1,cbar=False)\n",
    "            plt.setp(cg.get_xticklabels(),ha='right',size=fontSize)\n",
    "            title = 'Version '+str(version)+', '+path+', Number of Cancers above Corr '\n",
    "            title += str(corThres)+', for both Spearman and Pearson'\n",
    "            plt.title(title,size=40,pad=10);plt.show();print(title)\n",
    "    return 1\n",
    "\n",
    "def GetggCancerCluster(placeLst,dicIn,skipLst=[],version=7,parallel=True,meth='pearson',\n",
    "                          metric='cosine',save=False,threshold=True,thres=0.3,colorLow='White',\n",
    "                          colorHigh='Black',vmin=None,vmax=None):\n",
    "    inputs = tq(dicIn,desc='Getting DFs');outLst=[]\n",
    "    for path in inputs:\n",
    "        out = __ggCancerCluster(path,placeLst=placeLst,dicIn=dicIn,skipLst=skipLst,version=version,\n",
    "                                parallel=parallel,meth=meth,metric=metric,save=save,threshold=threshold,\n",
    "                                thres=thres,colorLow=colorLow,colorHigh=colorHigh,vmin=vmin,vmax=vmax)\n",
    "        outLst.append(out)\n",
    "    return outLst\n",
    "def __ggCancerCluster(path, placeLst,dicIn,skipLst=[],version=7,parallel=True,\n",
    "                    meth='pearson',metric='cosine',save=False,threshold=False,thres=0,\n",
    "                    colorLow='White',colorHigh='Black',vmin=None,vmax=None):\n",
    "    mpl.rcParams['figure.dpi'] = 150\n",
    "    dfLst = __dfLstFunc(placeLst,version)\n",
    "    if(save):\n",
    "        for img in glob.glob('Saved Images/*'):\n",
    "            os.remove(img)\n",
    "    outDict={}\n",
    "    if not path in skipLst:\n",
    "        genes = __runGenes(dicIn[path])\n",
    "        for dfTup in dfLst:\n",
    "            df = dfTup[1]\n",
    "            genes = __goodGenes(genes,df.index)\n",
    "        inputs=range(len(genes))\n",
    "        if(parallel):\n",
    "            out = Parallel(n_jobs=num_cores)(delayed(__ggCancerClusterHelp)(i,genes,dfLst,meth) for i in inputs)\n",
    "            outDict = dict(ChainMap(*out))\n",
    "        else:\n",
    "            for i in inputs:\n",
    "                outDict2 = __ggCancerHeatmapHelp(i,dfLst,meth)\n",
    "                outDict=MergeDicts(outDict,outDict2)\n",
    "        df = pd.DataFrame.from_dict(outDict, orient='index',columns=placeLst).T\n",
    "        newIdx = replaceLst(df.index,'Breast Hormone','Breast HR+')\n",
    "        df.index = newIdx\n",
    "        if(threshold):\n",
    "            cmap = thresBinCmap(df,thres,colorLow=colorLow,colorHigh=colorHigh,vmin=vmin,vmax=vmax)\n",
    "        else:\n",
    "            cmap=cmapSpecial\n",
    "        title = 'Version '+str(version)+', '+path+', '+meth.title()+' Correlation'\n",
    "        if(threshold):\n",
    "            title += ', Visual Threshold of '+str(thres)\n",
    "        return (title,cmap,df)\n",
    "\n",
    "def __ggCancerClusterHelp(i,genes,dfLst,meth='spearman'):\n",
    "    g1 = genes[i]\n",
    "    outDict={}\n",
    "    for j in range(i,len(genes)):\n",
    "        g2 = genes[j]\n",
    "        if not g1 == g2:\n",
    "            num = 0 \n",
    "            ggLst=[]\n",
    "            for dfTup in dfLst:\n",
    "                palce = dfTup[0]\n",
    "                df = dfTup[1]\n",
    "                g1E = df.loc[g1]\n",
    "                g2E = df.loc[g2]\n",
    "                corr = g1E.corr(g2E,method=meth)\n",
    "                ggLst.append(corr)\n",
    "            outDict[g1+'_'+g2] = ggLst\n",
    "    return outDict\n",
    "\n",
    "def thresBinCmap(df,thres=0,colorLow='Blue',colorHigh='Red',vmin=None,vmax=None):\n",
    "    if not(vmax):maxVal= df.max().max()\n",
    "    else:maxVal = vmax\n",
    "    if not(vmin):minVal= df.min().min()\n",
    "    else:minVal = vmin\n",
    "    if(thres>maxVal or thres<minVal):\n",
    "        raise Exception(\"Threshold is Out of Range\")\n",
    "    newMax = abs(minVal-maxVal);diff = newMax-maxVal;thres= thres+diff;shiftVal = thres/newMax\n",
    "    my_cmap = mpl.colors.LinearSegmentedColormap.from_list('', \n",
    "                                                 [(0,    colorLow),(shiftVal-0.001, colorLow),(shiftVal, colorHigh),\n",
    "                                                  (1,    colorHigh)])\n",
    "    return my_cmap\n",
    "def run_ggCancerCluster(placeLst,dicIn,runLst):\n",
    "    for run in tq(runLst,desc='Overall'):\n",
    "        version=run[0];skipLst=run[1];meth=run[2];threshold=run[3];thres=run[4]\n",
    "        x = master_ggCancerCluster(placeLst,dicIn,skipLst=skipLst,version=version,\n",
    "                                   meth=meth,threshold=threshold,thres=thres,metric='cosine',vmin=None,vmax=None)\n",
    "        print('Done with '+str(version)+', '+meth+', '+str(thres))\n",
    "    return 1\n",
    "\n",
    "def master_ggCancerCluster(placeLst,dicIn,skipLst=[],version=7,meth='pearson',threshold=True,thres=0.3,\n",
    "                           metric='cosine',vmin=None,vmax=None,save=False):\n",
    "    outLst = GetggCancerCluster(placeLst,dicIn,skipLst=skipLst,version=version,\n",
    "                                meth=meth,threshold=threshold,thres=thres)\n",
    "    for title,cmap,df in tq(outLst,desc='Plotting'):\n",
    "        t = plot_ggCancerCluster(df,cmap,title,vmin=vmin,vmax=vmax,metric=metric,save=save)\n",
    "    return 1\n",
    "\n",
    "def plot_ggCancerCluster(df,cmap,title,vmin=None,vmax=None,metric='cosine',save=False):\n",
    "    path = title.split(', ')[1]\n",
    "    if(len(df.columns)<50000):\n",
    "        cg = sb.clustermap(df,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=0,metric=metric);cg.fig.suptitle(title,y=1)\n",
    "        if(save):plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "        plt.show();print(title)\n",
    "    else:print('\\nGene-gene Pairs for '+path+' is to large to cluster, will be skipped\\n')\n",
    "    return 1\n",
    "def getdfAll(dfLst,idxName='Genes'):\n",
    "    if(len(dfLst)==0):return []\n",
    "    frst=True\n",
    "    for place,df in dfLst:\n",
    "        if(frst):\n",
    "            dfAll=df;frst=False\n",
    "        else:dfAll = dfAll.merge(df,on=idxName,how='inner')\n",
    "    return dfAll\n",
    "def maxLst(dicIn):\n",
    "    finalLst=[];finalNum=0\n",
    "    for lst in dicIn.values():\n",
    "        if(len(lst)>finalNum):finalLst = lst\n",
    "    return finalLst\n",
    "\n",
    "def plotCliques(placeLst,dicIn,version=7,meth='spearman',threshold=False,thres=0.3,minGenes=5,onlyTop=True):\n",
    "    outDict=getCliques(placeLst,dicIn,version=version,meth=meth,minGenes=minGenes,onlyTop=onlyTop)\n",
    "    master_ggCancerCluster(placeLst,outDict,version=version,meth=meth,threshold=threshold,thres=thres)\n",
    "    return 1\n",
    "def __plotCliqueClusterHelp(df,dfAll):\n",
    "    hotX=[];hotY=[]\n",
    "    for sample in df.columns:\n",
    "        dfSam = dfAll[sample];genes=dfAll.index\n",
    "        for i in range(len(genes)):\n",
    "            g1 = genes[i];x = dfSam.loc[g1]\n",
    "            for j in range(i,len(genes)):\n",
    "                g2 = genes[j]\n",
    "                if(g1 != g2):\n",
    "                    y= dfSam.loc[g2];hotX.append(x);hotY.append(y)\n",
    "    return hotX,hotY\n",
    "def plotGiantCliqueCluster(placeLst,dicIn,version=7,meth='spearman',idxName='Genes',save=False):\n",
    "    if(save):\n",
    "        for img in glob.glob('Saved Images/*'):os.remove(img)\n",
    "    outDict=getCliques(placeLst,dicIn,version=version,meth=meth);dfLst=__dfLstFunc(placeLst,version,idxName)\n",
    "    dfAll=getdfAll(dfLst,idxName);Hot,Cold=__getHotCold(dfAll);Not=__notHotOrCold(dfAll,Hot,Cold)\n",
    "    for path in tq(outDict,desc='Plot Giant Clique Cluster'):\n",
    "        genes = __runGenes(outDict[path]);dfPath=dfAll.loc[genes]\n",
    "        hotX, hotY = __plotCliqueClusterHelp(Hot,dfPath);coldX, coldY = __plotCliqueClusterHelp(Cold,dfPath)\n",
    "        notX, notY = __plotCliqueClusterHelp(Not,dfPath);num=int(len(hotX)/2)\n",
    "        for i in range(int(len(hotX)/num)):\n",
    "            plt.rcParams['figure.dpi'] = 150;mpl.rcParams['figure.dpi'] = 150\n",
    "            plt.figure(figsize=(80,40));plotX = hotX[i*num:(i+1)*num];plotY = hotY[i*num:(i+1)*num]\n",
    "            plt.plot(plotX,plotY,'o',color='red',label='Hots');plotX = coldX[i*num:(i+1)*num];plotY = coldY[i*num:(i+1)*num]\n",
    "            plt.plot(plotX,plotY,'o',color='blue',label='Colds');plotX = notX[i*num:(i+1)*num];plotY = notY[i*num:(i+1)*num]\n",
    "            plt.plot(plotX,plotY,'o',color='black',label='Neither')\n",
    "            title=\"Giant Clique Scatter Plot, Version \"+str(version)+', '+path+', '+meth.title()+', Part '+str(i+1)\n",
    "            plt.title(title,fontSize=100,pad=30);plt.xticks(fontsize=40);plt.yticks(fontsize=40)\n",
    "            if(save):plt.savefig('Saved Images/'+title+'.pdf',dpi=300,bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "        title=title.replace(', Part '+str(i+1),'');print(title)\n",
    "    return 1\n",
    "\n",
    "def getFixOutliers(placeLst):\n",
    "    for place in tq(placeLst):\n",
    "        if not place in skip:\n",
    "            prePure = pd.read_csv('Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv',index_col=0,sep='\\t')\n",
    "            __renameTPM(prePure);prePure = np.log2(prePure+1);prePure = __removeBadPlace(prePure)\n",
    "            prePure = pd.DataFrame(stats.zscore(prePure,axis=1),prePure.index,columns=prePure.columns)\n",
    "            prePure, _ = __fixOutliers(prePure,thres=100,scale=0.1)\n",
    "            prePure.to_csv('Purity/TPM/Outliers Fixed/TCGA_'+place+'_tpm.tsv',sep='\\t')\n",
    "    return 1\n",
    "\n",
    "def plotCancersThres(placeLst,dicIn,version=7,meth='spearman',idxName='Genes',minGenes=5,\n",
    "                     thres=0.3,fontSize=12,sizeThres=10,onlyTop=True):\n",
    "    outDict={};dfLst = __dfLstFunc(placeLst,version,idxName);inputs=tq(dicIn,desc='Finding Cliques');totalGenes=[]\n",
    "    for path in inputs:\n",
    "        genes = __runGenes(dicIn[path])\n",
    "        for place, df in dfLst:genes = __goodGenes(genes,df.index)\n",
    "        inputs=dfLst\n",
    "        out = Parallel(n_jobs=num_cores)(delayed(__getCliquesLst)\n",
    "                                         (df.loc[genes],meth,thres,minGenes,\n",
    "                                          bothMeths=True,retPlace=True,place=place,onlyTop=onlyTop) for place,df in inputs)\n",
    "        pathDic={}\n",
    "        for lst,thres,place in out:pathDic[place+'_'+str(thres)] = lst\n",
    "        outDict[path] = pathDic\n",
    "    for path in tq(outDict,desc='Plotting Cliques'):\n",
    "        dicPath = outDict[path];totalGenes=[]\n",
    "        for place in dicPath:\n",
    "            placeName = place.split('_')[0];lst=dicPath[place];totalGenes.extend(lst)\n",
    "        geneDic={}\n",
    "        for gene in totalGenes:\n",
    "            inLst=[]\n",
    "            for place in dicPath:\n",
    "                placeName = place.split('_')[0];lst=dicPath[place]\n",
    "                if(gene in lst):inLst.append(1)\n",
    "                else:inLst.append(0)\n",
    "            geneDic[gene]=inLst\n",
    "        dfPlot = pd.DataFrame.from_dict(geneDic,orient='index',columns=placeLst)\n",
    "        dfPlot.columns = getUniqueNames(dfPlot.columns);dfPlot = dfPlot.loc[dfPlot.T.sum()>12]\n",
    "        if(len(dfPlot.index)>1):\n",
    "            cg = sb.clustermap(dfPlot,cmap='Greys',yticklabels=1)\n",
    "            addOn = len(cg.ax_heatmap.get_yticklabels()) / sizeThres;newFont = fontSize - addOn\n",
    "            plt.setp(cg.ax_heatmap.get_yticklabels(),rotation=45,va='bottom',size=newFont)\n",
    "            plt.setp(cg.ax_heatmap.get_xticklabels(),rotation=45,ha='right')\n",
    "            title = 'Version '+str(version)+', Threshold '+str(thres)+', '+path\n",
    "            cg.fig.suptitle(title,y=1);mpl.rcParams['figure.dpi'] = 200;plt.show();print(title)\n",
    "        else:print('No genes in enough cancers for '+path)\n",
    "    return 1\n",
    "def getCliques(placeLst,dicIn,thres=0.3,version=7,meth='spearman',minGenes=5,idxName='Genes',\n",
    "               onlyTop=True,bothMeths=False,tqTrue=True,pan=False):\n",
    "    dfLst = __dfLstFunc(placeLst,version,idxName,pan=pan);dfAll = getdfAll(dfLst,idxName)\n",
    "    if(tqTrue):inputs=tq(dicIn,desc='Finding Cliques')\n",
    "    else:inputs=dicIn\n",
    "    out=[]\n",
    "    for path in inputs:out.append(__getCliquesHelp(dfAll,dicIn,thres,meth,path,minGenes,onlyTop,bothMeths))\n",
    "    outDict={}\n",
    "    for path,thres,lst in out:\n",
    "        dic={'clique':lst};outDict[path]=dic\n",
    "    return outDict\n",
    "def __getCliquesHelp(dfAll,dicIn,thres,meth,path,minGenes,onlyTop,bothMeths): \n",
    "    genes = __runGenes(dicIn[path]);genes = __goodGenes(genes,dfAll.index);dfPath = dfAll.loc[genes]\n",
    "    outLst,thres = __getCliquesLst(dfPath,meth,thres,minGenes,onlyTop=onlyTop,bothMeths=bothMeths)\n",
    "    outLst2=outLst.copy();thres2=thres\n",
    "    while(len(outLst2)>30):\n",
    "        outLst=outLst2.copy();thres=thres2;thres2 = round(thres2+0.05,2)\n",
    "        outLst2,thres2 = __getCliquesLst(dfPath,meth,thres2,minGenes,onlyTop=onlyTop,bothMeths=bothMeths)\n",
    "    return (path,thres,outLst)\n",
    "\n",
    "def __getCliquesLst(dfPath,meth,thres,minGenes,bothMeths=False,retPlace=False,place='',onlyTop=True):\n",
    "    if(bothMeths):\n",
    "        lst1, thres = __getCliquesLstHelp(dfPath,meth='spearman',thres=thres,minGenes=minGenes,onlyTop=onlyTop)\n",
    "        lst2, thres = __getCliquesLstHelp(dfPath,meth='pearson',thres=thres,minGenes=minGenes,onlyTop=onlyTop)\n",
    "        if(onlyTop):finalLst = list(set(lst1) | set(lst2))\n",
    "        else:finalLst = mergeDic(lst1,lst2)\n",
    "    else:finalLst, thres = __getCliquesLstHelp(dfPath,meth=meth,thres=thres,minGenes=minGenes,onlyTop=onlyTop)\n",
    "    if(retPlace):return finalLst, thres, place\n",
    "    else:return finalLst, thres\n",
    "    \n",
    "def __getCliquesLstHelp(dfPath,meth,thres,minGenes,onlyTop=True):\n",
    "    corr = dfPath.T.corr(method=meth);outClique={};seenLst=[];finalLst=[]\n",
    "    if not onlyTop:finalDict={}\n",
    "    finalNum=0\n",
    "    for gene in corr.index:\n",
    "        if not gene in seenLst:\n",
    "            ser = corr.loc[gene];cliqueGenes = ser[ser>thres].index\n",
    "            clique = corr.loc[cliqueGenes][cliqueGenes];cliqueThres = clique[clique>thres]\n",
    "            while(cliqueThres.isna().sum().max()>0):\n",
    "                maxId = cliqueThres.isna().sum().argmax();dropName = cliqueThres.iloc[maxId].name\n",
    "                cliqueThres = cliqueThres.drop(dropName);cliqueThres = cliqueThres.drop(dropName,axis=1)\n",
    "            lst = cliqueThres.index\n",
    "            if(len(lst)>minGenes):\n",
    "                if(onlyTop):\n",
    "                    if(len(lst)>finalNum):\n",
    "                        finalNum = len(lst);finalLst = list(lst)\n",
    "                else:\n",
    "                    finalDict[gene] = (list(lst))\n",
    "            seenLst.extend(list(lst))\n",
    "    if not onlyTop:\n",
    "        finalLst=finalDict\n",
    "    return finalLst,thres\n",
    "\n",
    "def mergeDic(dic1,dic2):\n",
    "    out={}\n",
    "    for p in dic1:\n",
    "        lst= dic1[p]\n",
    "        if p in dic2:\n",
    "            lst2 = dic2[p];lst = list(set(lst) | set(lst2))\n",
    "        out[p] = lst\n",
    "    for p in dic2:\n",
    "        if not p in dic1:\n",
    "            lst = dic2[p];out[p] = lst\n",
    "    return out\n",
    "\n",
    "def getUniversalCliques(placeLst,dicIn,version=7,idxName='Genes',meth='spearman',\n",
    "                        minGenes=3,thres=0.3):\n",
    "    outDict={}\n",
    "    if(True):\n",
    "        dfLst = __dfLstFunc(placeLst,version,idxName);inputs=tq(dicIn,desc='Finding Cliques');totalGenes=[]\n",
    "        for path in inputs:\n",
    "            genes = __runGenes(dicIn[path])\n",
    "            for place, df in dfLst:genes = __goodGenes(genes,df.index)\n",
    "            inputs=dfLst\n",
    "            out = Parallel(n_jobs=num_cores)(delayed(__getCliquesLst)\n",
    "                                             (df.loc[genes],meth,thres,minGenes,\n",
    "                                              bothMeths=True,retPlace=True,place=place,onlyTop=False) for place,df in inputs)\n",
    "\n",
    "            frst=True;plotDic={};excludedDic={}\n",
    "            for dic, thres, place in out:\n",
    "                plotDic2={}\n",
    "                if(frst):\n",
    "                    plotDic2= dic.copy()\n",
    "                    for p in dic:\n",
    "                        for elem in dic[p]:excludedDic[elem] = [1]\n",
    "                    frst=False\n",
    "                else:\n",
    "                    for p in plotDic:\n",
    "                        if p in dic:\n",
    "                            lst1 = dic[p];lst2 = plotDic[p];lst = __goodGenes(lst1,lst2)\n",
    "                            if(len(lst)>1):plotDic2[p]=lst\n",
    "                plotDic=plotDic2.copy()\n",
    "            outDict[path]=plotDic\n",
    "    return outDict\n",
    "def setupBNLearnPathways(placeLst,dicIn,pooledVersion=7,minGenes=5,runVLst=[],panCancer=False,\n",
    "                 numCancers=1,pooledClique=False,indivDBCliques=False,indivCancerCliques=False):\n",
    "    \"\"\"\n",
    "    setupBNLearnPathways:\n",
    "            Inputs:\n",
    "                placeLst: a list of cancer areas to use within the function, most important if pooledClique=True\n",
    "                    no default\n",
    "                dicIn: a dictionary telling which genes should belong to which pathways, \n",
    "                       for use in creating the pathway cliques\n",
    "                    no default, but everyDict is the recommened input\n",
    "                pooledVersion: the data correction version from which the pathway cliques will be created\n",
    "                    default: 7 (for v7 of correction)\n",
    "                minGenes: the minimun number of genes need to be considered a clique, \n",
    "                          Warning if number is set to high possiblity that no cliques will be found\n",
    "                    deafult: 5\n",
    "                runVLst: a list of the correction versions for which a BNLearn input file will be created,\n",
    "                         currently supports inputs of 1 thru 8 (for v1-v8) and 'PrePure'\n",
    "                    deafult: an empty list, running on deafult will create no files\n",
    "                numCancers: a number from how many of the biggest (in number of samples) cancer areas BNLearn input files\n",
    "                            will be created. If numCancers > length of placeLst all placeLst cancers will be used.\n",
    "                    deafult: 1\n",
    "                pooledClique: boolean telling if to use the \"Pooled\" method for deifning cliques, \n",
    "                              a method where, for each pathway (as defined by dicIn), the largest group of genes \n",
    "                              (of at least size minGenes) that all have correlation of at least 0.3 to all other \n",
    "                              genes in the group, with correaltion based on samples from all cancers in placeLst\n",
    "                              with pooledVersion data,\n",
    "                              is defined as the clique for that pathway.\n",
    "                              Warning: this method is heavily towards the largest cancer areas.\n",
    "                    default: False\n",
    "                indivDBClqieus: boolean telling if to use the individual databases (as defined in dicIn) pathways\n",
    "                                as the pathway cliques.\n",
    "                                Will create a clique for each database in dicIn which has at least minGenes in all pathways.\n",
    "                    deafult: False\n",
    "                indivCancerCliques: boolean telling if to use the \"Cancer Specific\" method for defing cliques,\n",
    "                                    which is very similar to the \"Pooled\" method, only instead of using all cancers in \n",
    "                                    placeLst it creates a clique for each cancer specifically \n",
    "                                    (using only that cacners samples)\n",
    "                    deafult: False\n",
    "                Warning:\n",
    "                    If the dafualts for pooledClique, indivDBCliques and indivCancerCliques are all left unchanged no \n",
    "                    input files will be created. If more than one of the three are set to True, uncertain what file will be \n",
    "                    created.\n",
    "            Actions:\n",
    "                Creates BNLearn input files for each of the N biggest cancer areas (N=numcancers). For each cacner area \n",
    "                    a file will be created for each data version in runVLst. \n",
    "                For each pathway it creates a clique (depending on which method was chosen), from the pathway genes defined in\n",
    "                    dicIn.\n",
    "                The BNLearn file will have each of those pathways as a column, along with Purity Scores and Heat Scores, \n",
    "                    and all the specific cancers samples as the rows. The data will the the average of that pathway's \n",
    "                    clique genes for the given sample, as well as the Purity and Heat Scores for that Sample.\n",
    "                The file's name will indicate the cancer area, the number of samples within that cancer, the clique \n",
    "                    method used, and the correction version used for that file's data.\n",
    "                The total number of files created will either be, numCancers*length runVLst (if indivDBCliques=False)\n",
    "                    or numCancers*length runVLst*databases within dicIn (if indivDBCliques=True).\n",
    "                    \n",
    "            Returns:\n",
    "                Should create the input BNLearn files requested in the 'Run BNLearn/Inputs/' directory, \n",
    "                returns 1 if no errors have occured \n",
    "    \"\"\"\n",
    "    if(pooledClique):\n",
    "        outDict= getCliques(placeLst,dicIn,version=pooledVersion,minGenes=minGenes,onlyTop=True,bothMeths=True,pan=False)\n",
    "        __setupBNHelp(numCancers=numCancers,runVLst=runVLst,outDict=outDict,title=', Pooled',panCancer=panCancer)\n",
    "    if (indivDBCliques):\n",
    "        frstDic = list(dicIn.keys())[0];dbLst=[]\n",
    "        for db in tq(dicIn[frstDic],desc='Setting up DBs'):\n",
    "            if not db =='HALLMARK':\n",
    "                outDict = __getDBList(dicIn,db);__setupBNHelp(numCancers=numCancers,runVLst=runVLst,\n",
    "                                                              outDict=outDict,title=', '+db,tqTrue=False,panCancer=panCancer)\n",
    "    if(indivCancerCliques):\n",
    "        pLst = getBiggestXCancers(numCancers)\n",
    "        if not panCancer:\n",
    "            for place,num in tq(pLst,desc='Setting up Cliques'):\n",
    "                outDict= getCliques([place],dicIn,version=pooledVersion,minGenes=minGenes,\n",
    "                                    onlyTop=True,bothMeths=True,tqTrue=False,thres=0.4)\n",
    "                __setupBNHelp(numCancers=numCancers,runVLst=runVLst,outDict=outDict,\n",
    "                              title=', Cancer Specific',tqTrue=False,allPlaces=False,setPlace=place,panCancer=panCancer)\n",
    "        else:\n",
    "            outDict= getCliques(placeLst,dicIn,version=pooledVersion,minGenes=minGenes,pan=True,\n",
    "                                onlyTop=True,bothMeths=True,tqTrue=True,thres=0.4)\n",
    "            __setupBNHelp(numCancers=numCancers,runVLst=runVLst,outDict=outDict,\n",
    "                              title=', Cancer Specific',tqTrue=True,allPlaces=True,setPlace='',panCancer=True)\n",
    "    return 1\n",
    "nameDict={}\n",
    "nameDict['T-effector']='T-Eff';nameDict['IFNG induced']='IFNg';nameDict['Antigen processing machinery']='Antigen Process'\n",
    "nameDict['Fatty acid']='FA';nameDict['GABA'] = 'GABA';nameDict['Cholesterol synthesis']='CS';nameDict['PI3K-AKT']='PI3K'\n",
    "def __setupBNHelp(numCancers, runVLst,outDict,title='',tqTrue=True,allPlaces=True,setPlace='',panCancer=False):\n",
    "    pLst = getBiggestXCancers(numCancers)\n",
    "    if(tqTrue):inputs=tq(runVLst,desc='Setting Up BNLearn')\n",
    "    else:inputs = runVLst\n",
    "    for runVersion in inputs:\n",
    "        if(panCancer):\n",
    "            dfLst=[];cancerNum=1\n",
    "        for place, placeLen in pLst:\n",
    "            if(allPlaces or place==setPlace):\n",
    "                if(runVersion!='PrePure'):df = pd.read_csv('Purity/TPM/v'+str(runVersion)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "                else:df = pd.read_csv('Purity/TPM/Outliers Fixed/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "                pathLst=[];serLst=[]\n",
    "                for path in outDict:\n",
    "                    pathLst.append(path);pathGenes = __runGenes(outDict[path]);pathGenes = __goodGenes(pathGenes,df.index)\n",
    "                    dfPath = df.loc[pathGenes];ser = dfPath.mean();serLst.append(ser)\n",
    "                dfBN = pd.DataFrame(serLst,pathLst);dfBN = __pureDf(dfBN,zscore=False)\n",
    "                dfBN = __heatDF(dfBN,place,zscore=True)[0];dfBN = dfBN.T;newCols=[]\n",
    "                for i in dfBN.columns:\n",
    "                    i2 = i.split('_')\n",
    "                    for num in range(len(i2)):\n",
    "                        elem = i2[num]\n",
    "                        if(elem in nameDict):i2[num] = nameDict[elem]\n",
    "                    i = ('_').join(i2);newCols.append(i)\n",
    "                dfBN.columns=newCols;dfBN.dropna(axis=1,inplace=True)\n",
    "                if(panCancer):\n",
    "                    placeLen = len(dfBN.index);samples = random.sample(range(0, placeLen), 100)\n",
    "                    dfBN = dfBN.iloc[samples];dfBN.insert(len(dfBN.columns),'Cancer Area',cancerNum)\n",
    "                    dfLst.append((place,dfBN));cancerNum+=1\n",
    "                else:\n",
    "                    if(runVersion!='PrePure'):\n",
    "                        dfBN.to_csv('Run BNLearn/Inputs/Pure '+place+', N = '+str(placeLen)+title+', v'+str(runVersion),sep='\\t')\n",
    "                    else:\n",
    "                        dfBN.to_csv('Run BNLearn/Inputs/Pure '+place+', N = '+str(placeLen)+title+', '+str(runVersion),sep='\\t')\n",
    "            if(panCancer):\n",
    "                if(len(dfLst)>0):\n",
    "                    dfAll = getDfPan(dfLst)\n",
    "                    if(runVersion!='PrePure'):\n",
    "                        dfAll.to_csv('Run BNLearn/Inputs/Pure Pre-BN Merged'+title+', v'+str(runVersion),sep='\\t')\n",
    "                    else:dfAll.to_csv('Run BNLearn/Inputs/Pure Pre-BN Merged'+title+', '+str(runVersion),sep='\\t')     \n",
    "    return 1\n",
    "def getDfPan(dfLst):\n",
    "    frst=True\n",
    "    for place, df in dfLst:\n",
    "        if(frst):\n",
    "            out = df.copy();frst=False\n",
    "        else:out = pd.concat([out,df])\n",
    "    return out\n",
    "def getKobeClique(getKobeDict=False):\n",
    "    kobeGenes = pd.read_excel('Genelist_desert.xlsx',index_col=0);pathDict={}\n",
    "    for pathway in kobeGenes['pathway'].unique():\n",
    "        dictN={};dictN['kobe'] = list(kobeGenes[kobeGenes['pathway']==pathway].index)\n",
    "        if(pathway in nameDict):pathway = nameDict[pathway]\n",
    "        pathDict[pathway]= dictN\n",
    "    if not getKobeDict:\n",
    "        return pathDict\n",
    "    else:\n",
    "        kobe = pathDict;kobeDict={}\n",
    "        for path in kobe:\n",
    "            genes = __runGenes(kobe[path])\n",
    "            for g in genes:\n",
    "                g = g.replace('-','');kobeDict[g] = path\n",
    "        kobeDict['Heat'] = 'Heat';kobeDict['Purity'] = 'Purity';kobeDict['CancerArea'] = 'Cancer Area'\n",
    "        return kobeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBNLearnRobustDBs(globDir='Run BNLearn/Outputs/*',metric='cosine',fsX=8,fsY=6,size=(20,20),\n",
    "                         kobeList=False,onlyN=True,dropNum=5,split=False,\n",
    "                         merged=True,indivCancers=True,onlyBGE=False,onlyBDE=False,save=False,fixedPos=False,thres=0.7,\n",
    "                         interPath=False,immuneNonOnly=False,N=4,nonToIm=False,allDir=False,pathways=False,excludePre=False,\n",
    "                         reverse=False,undirected=False,directed=False,mergedFixedPos=False,posDrop=([],[]),showMergeY=0):\n",
    "    \"\"\"\n",
    "    plotBNLearn:\n",
    "        Plots the plotBNLearnRobust Heatmap for each individual database in dicIn\n",
    "            for more info read description of plotBNLearnRobust\n",
    "    \"\"\"\n",
    "    \n",
    "    graphLst = __BNGraphsTinyBegin(globDir=globDir,pathways=pathways,onlyBGE=onlyBGE,onlyBDE=onlyBDE)\n",
    "    dbLs = []\n",
    "    for graph in graphLst:\n",
    "        ls = graph.split('\\\\')[1].split(',')\n",
    "        if('BN Merged' in ls[0]):\n",
    "            db = ls[1].strip()\n",
    "        else:\n",
    "            db = ls[2].strip()\n",
    "        dbLs.append(db)\n",
    "    dbLs = list(set(dbLs))\n",
    "    i=0\n",
    "    gL=[]\n",
    "    for db in tq(dbLs,desc='Plotting DB HMs'):\n",
    "        if(mergedFixedPos):\n",
    "            tup = posDrop[i]\n",
    "            pos = tup[0]\n",
    "            drop = tup[1]\n",
    "        else:\n",
    "            pos=[]\n",
    "            drop=[]\n",
    "        i+=1\n",
    "        dirGlob='Run BNLearn/Outputs/*'+db+'*'\n",
    "        col, drop = plotBNLearnRobust(metric=metric,fsX=fsX,fsY=fsY,size=size,merged=merged,indivCancers=indivCancers,\n",
    "                                      onlyBGE=onlyBGE,onlyBDE=onlyBDE,save=save,fixedPos=fixedPos,reverse=reverse,\n",
    "                                      undirected=undirected,excludePre=excludePre,tqOn=False,\n",
    "                                      directed=directed,mergedFixedPos=mergedFixedPos,pos=pos,drop=drop,split=split,\n",
    "                                      kobeList=kobeList,onlyN=onlyN,thres=thres,interPath=interPath,pathways=pathways,\n",
    "                                      immuneNonOnly=immuneNonOnly,N=N,nonToIm=nonToIm,allDir=allDir,\n",
    "                                      dirGlob=dirGlob,title=', Only '+db,showMergeY=showMergeY,dropNum=dropNum)\n",
    "        gL.append((col,drop))\n",
    "    return gL,dbLs\n",
    "    \n",
    "def plotBNLearnRobust(metric='cosine',fsX=8,fsY=8,size=(20,20),split=False,kobeList=False,onlyN=False,thres=0.7,N=4,\n",
    "                      pathways=False,nonToIm=False,allDir=False,excludePre=False,tqOn=True,\n",
    "                      merged=True,indivCancers=True,onlyBGE=False,onlyBDE=False,save=False,fixedPos=False,immuneNonOnly=False,\n",
    "                      reverse=False,undirected=False,directed=False,mergedFixedPos=False,pos=[],drop=[],interPath=False,\n",
    "                      dirGlob='Run BNLearn/Outputs/*',title='',showMergeY=0,dropImmune=False,dropNum=0):\n",
    "    \"\"\"\n",
    "        plotBNLearnRobust:\n",
    "            \n",
    "            Inputs:\n",
    "                    metric: the mertic by which to cluster the BNLearn results in the heatmaps\n",
    "                        deafualt: 'cosine'\n",
    "                    fsX: font size for the x-axis labels in the resulting heatmaps\n",
    "                        default: 8\n",
    "                    fsY: font size for the y-axis labels in the resulting heatmaps\n",
    "                        deafult: 6\n",
    "                    size: a tuple with the size of the resulting heatmap\n",
    "                        default: (20,20), works best when width and hight are equal\n",
    "                    merged: boolean telling if to plot the merged heatmap, using BNLearn output data from all possible cancer\n",
    "                            areas\n",
    "                        deafult: True\n",
    "                    indivCacners: boolean telling if to plot each possible BNLearn output cancer area data individually\n",
    "                        deafult: True\n",
    "                    \n",
    "                    If both merged and indivCacners are True, will first plot merged and then the individual cacners\n",
    "                    \n",
    "                    onlyBGE: boolean telling if to inlcude only BNLearn outputs that used the \"bge\" scoreing method in the\n",
    "                             heatmaps (if to only plot the 'bge' BNLearn results)\n",
    "                        deafult: False\n",
    "                    onlyBDE: boolean telling if to inlcude only BNLearn outputs that used the \"bde\" scoreing method in the\n",
    "                             heatmaps (if to only plot the 'bde' BNLearn results)\n",
    "                        deafult: False\n",
    "                    save: boolean telling if to save the resulting heatmaps in the 'Saved Images/' directory\n",
    "                        default: False\n",
    "                    fixedPos: boolean telling if to make the order the x-axis of the individual cancer heatmap on the same as\n",
    "                              the order of the merged heatmaps x-axis\n",
    "                        default: False\n",
    "                    reverse: boolean telling if to reverse the direction of the pathways in the x-axis (from A->B to B->A),\n",
    "                             all B->A directed edges will be colored blue-white-red, while all A->B directed and undirected \n",
    "                             edges will be grayscaled based on their edge strength.\n",
    "                        default: False\n",
    "                    undirected: boolean telling if to use undirected pathways in the x-axis (from A->B to A--B),\n",
    "                                all A--B directed edges will be colored blue-white-red, while all A->B and B->A directed\n",
    "                                edges will be grayscaled based on their edge strength\n",
    "                        deafult: False\n",
    "                    directed: boolean telling if to use the base x-axis direction, A->B directed edges will be colored \n",
    "                              blue-white-red, while all B->A directed and undirected edges will be grayscaled based on their \n",
    "                              edge strength.\n",
    "                        deafult: False\n",
    "                    \n",
    "                    If reverse=True, directed atomatically becomes True\n",
    "                    If undirected=False, both reverse and directed atomatically become False\n",
    "                    If reverse, directed and undirected are all False, heatmap plots direction agnostic, where all edges\n",
    "                        are colored blue-white-red, with the input being the highest strength (form any direction) for \n",
    "                        each edge.\n",
    "                    \n",
    "                    mergedFixedPos, boolean telling if to base the order of the x-axis of the Merged heatmap on the pos input\n",
    "                        deafult: False\n",
    "                    pos: List of ints telling the order of elements to order the Merged Heatmap, ints must be within the range \n",
    "                             of the length of the Merged Heatmap's x-axis.\n",
    "                         A run of the plotBNLearnRobust function returns a list of ints that can be used as the pos input,\n",
    "                             (it is recommended that a previous run of plotBNLearnRobust be the only way you get a pos input)\n",
    "                        \n",
    "                        deafult: an empty list (will error if mergedFixedPos=True, and deafult pos is kept)\n",
    "                \n",
    "                Actions:\n",
    "                    The functions takes all the BNLearn outputs in the 'BNLearn/Outputs/' directory, if \n",
    "                        onlyBGE or onlyBDE were set to True then the outputs taken would be limited to only \n",
    "                        outputs with that scoreing method.\n",
    "                    Then plots a heatmap of those outputs, mainly the strength of the different possible edges. If heatmap is\n",
    "                        not direction agnostic, then the strength of the directed edges are blue-white-red while the strength\n",
    "                        of edges for the other directions are greyscaled. The y-axis ordering is based on the cluster metric\n",
    "                        given be metric, while the x-axis order is either also clustered or fixed \n",
    "                        (if fixedPos or mergedFixedPos = True).\n",
    "                    The created plots can also be saved, if the option is chosen.\n",
    "                \n",
    "                Outputs:\n",
    "                    On success returns a list of ints detailing the x-axis order for the last heatmap, which can be used in \n",
    "                        future calls of this function for the pos input.\n",
    "                    \n",
    "    \"\"\"\n",
    "    if(reverse):\n",
    "        directed=True\n",
    "    if(undirected):\n",
    "        reverse=False\n",
    "        directed=False\n",
    "    if not pathways:\n",
    "        graphLst = glob.glob(dirGlob)\n",
    "    else:\n",
    "        graphLst = globExclude(dirGlob,exclude='Kobe Genes')\n",
    "    if(excludePre):\n",
    "        graphLst = __removeLstFunc(graphLst,'PrePure')\n",
    "    if(len(graphLst)==0):\n",
    "        return [],[]\n",
    "    sizeX=(size[0]/20)+1\n",
    "    sizeY=(size[1]/20)+1\n",
    "    fsX=fsX*sizeX\n",
    "    fsY=fsY*sizeY\n",
    "    graphLst = __onlyBGEorBDE(graphLst,onlyBGE,onlyBDE)\n",
    "    if(merged):\n",
    "        graphLst2 = graphLst = __removeLstFunc(graphLst,'Pre-BN')\n",
    "        if not mergedFixedPos:\n",
    "            col,drop = __plotBNLearnRobustHelp(graphLst2,metric=metric,fsX=fsX,fsY=fsY,title=', Merged Graph'+title,\n",
    "                                               size=size,save=save,onlyBGE=onlyBGE,onlyBDE=onlyBDE,split=split,\n",
    "                                               reverse=reverse,undirected=undirected,directed=directed,fixedPos=False,\n",
    "                                               showMergeY=showMergeY,dropImmune=dropImmune,dropNum=dropNum,allDir=allDir,\n",
    "                                               immuneNonOnly=immuneNonOnly,N=N,nonToIm=nonToIm,pathways=pathways,\n",
    "                                               kobeList=kobeList,onlyN=onlyN,thres=thres,interPath=interPath)\n",
    "        else:\n",
    "            col,drop = __plotBNLearnRobustHelp(graphLst2,metric=metric,fsX=fsX,fsY=fsY,title=', Merged Graph'+title,split=split,\n",
    "                                               size=size,save=save,onlyBGE=onlyBGE,onlyBDE=onlyBDE,drop=drop,allDir=allDir,\n",
    "                                               kobeList=kobeList,onlyN=onlyN,thres=thres,interPath=interPath,\n",
    "                                               immuneNonOnly=immuneNonOnly,N=N,nonToIm=nonToIm,pathways=pathways,\n",
    "                                               reverse=reverse,undirected=undirected,fixedPos=True,pos=pos,directed=directed,\n",
    "                                               showMergeY=showMergeY,dropImmune=dropImmune,dropNum=dropNum)\n",
    "    else:\n",
    "        if fixedPos:\n",
    "            print(\"Error: fixedPos=True option must also have merged=True\")\n",
    "            return 0\n",
    "    if(indivCancers):\n",
    "        placeLs = []\n",
    "        for graph in graphLst:\n",
    "            place = graph.split('\\\\')[1].split(',')[0].strip()\n",
    "            placeLs.append(place)\n",
    "        placeLs = list(set(placeLs))\n",
    "        if(tqOn):\n",
    "            inputs = tq(placeLs,desc='Plotting')\n",
    "        else:\n",
    "            inputs = placeLs\n",
    "        for place in inputs:\n",
    "            graphLst2 = [p for p in graphLst if place in p]\n",
    "            col,drop = __plotBNLearnRobustHelp(graphLst2,metric=metric,fsX=fsX-2,fsY=fsY,title=', '+place+title,\n",
    "                                               interPath=interPath,immuneNonOnly=immuneNonOnly,\n",
    "                                               size=size,save=save,onlyBGE=onlyBGE,onlyBDE=onlyBDE,fixedPos=fixedPos,pos=col,\n",
    "                                               drop=drop,dropNum=dropNum,split=split,kobeList=kobeList,onlyN=onlyN,N=N,\n",
    "                                               thres=thres,nonToIm=nonToIm,pathways=pathways,allDir=allDir,\n",
    "                                               reverse=reverse,undirected=undirected,directed=directed,dropImmune=dropImmune)\n",
    "    return col, drop\n",
    "\n",
    "def __plotBNLearnRobustHelp(graphLst,metric,fsX,fsY,title,split,kobeList,onlyN,N,thres,immuneDict,dictIn,\n",
    "                            size,save,onlyBGE,onlyBDE,fixedPos,pos,drop,interPath,\n",
    "                            reverse=False,undirected=False,directed=False,showMergeY=0,dropImmune=False,dropNum=0,\n",
    "                            immuneNonOnly=False,nonToIm=False,pathways=False,allDir=False):\n",
    "    outDict, nameLst = __BNOutDict(graphLst,reverse=reverse,undirected=undirected,directed=directed,dropImmune=dropImmune,\n",
    "                                   allDir=allDir)\n",
    "    df = pd.DataFrame.from_dict(outDict,orient='index',columns=nameLst)\n",
    "    if(len(df.index)==0):\n",
    "        return pos,drop\n",
    "    newIdx,newNames,l1 = __renameBNOut(df)\n",
    "    df.columns=newIdx\n",
    "    df =df.T\n",
    "    df = df.fillna(0)\n",
    "    if(interPath):\n",
    "        df = interPathwayOnly(df,immuneDict=immuneDict,dictIn=dictIn,graphviz=False,\n",
    "                              immuneNonOnly=immuneNonOnly,nonToIm=nonToIm,pathways=pathways,allDir=allDir)\n",
    "    colors = ['red','blue','green','yellow','purple','black','orange','grey','white',\n",
    "              'brown','fuchsia','pink','gold','seagreen','salmon','olive','teal','crimson','cyan']\n",
    "    \n",
    "    title2 = 'Strength of BNLearn Pathway Relationships'+title\n",
    "    cClust = not(fixedPos)\n",
    "    if fixedPos:\n",
    "        col = pos.copy()\n",
    "        drop2 = __changeDrop(drop,directed=directed,reverse=reverse,undirected=undirected)\n",
    "        drop2 = __goodGenes(drop2,df.columns)\n",
    "        df1 = df.drop(columns=drop2)\n",
    "        df1 = __setCluster(df1,range(len(df1.index)),col)\n",
    "    else:\n",
    "        colColors=None\n",
    "        colLut='R'\n",
    "        df1 = df.copy()\n",
    "        if(kobeList and (len(newNames)>1)):\n",
    "            pLst=[]\n",
    "            for row in df1.index:\n",
    "                place = row.split(',')[0]\n",
    "                pLst.append(place)\n",
    "            pLst = list(set(pLst))\n",
    "            outDict={}\n",
    "            for place in pLst:\n",
    "                rows = [p for p in df1.index if place in p]\n",
    "                place = place.replace('Kobe Genes ','')\n",
    "                dfRows = df1.loc[rows]\n",
    "                outDict[place] = dfRows.mean()\n",
    "            dfOut = pd.DataFrame.from_dict(outDict, orient='index')\n",
    "            notNans = dfOut[dfOut < thres].isnull().sum(axis=0)\n",
    "            if(onlyN):\n",
    "                isNans = notNans[notNans < N]\n",
    "                notNans = notNans[notNans >= N] \n",
    "            notNans = notNans.index\n",
    "            df1 = dfOut[notNans]\n",
    "    if(kobeList):\n",
    "        colColors,colLut = BNLearnColColors(df1,reverse=reverse,undirected=undirected,directed=directed)\n",
    "    else:\n",
    "        colColors=None\n",
    "        colLut='R'\n",
    "    if(directed or undirected):\n",
    "        cmap = cmapSpecial4\n",
    "        vmin = -1\n",
    "        vmax = 1\n",
    "    else:\n",
    "        cmap = cmapSpecial\n",
    "        vmin=0\n",
    "        vmax=1\n",
    "    if(len(newNames)>1):\n",
    "        fx = df1.sum() != 0\n",
    "        colLst=[]\n",
    "        for col in df1.columns:\n",
    "            if fx[col]:\n",
    "                colLst.append(col)\n",
    "        df1 = df1[colLst]\n",
    "        lut,placeColors = bnLearnRowColors(df1.index.unique(),colors)\n",
    "        row_colors = df1.index.unique().map(lut)\n",
    "        cg = sb.clustermap(df1,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,col_cluster=cClust,col_colors=colColors,\n",
    "                           yticklabels=showMergeY,metric=metric,figsize=size,row_colors=row_colors)\n",
    "        if not fixedPos:\n",
    "            col = cg.dendrogram_col.reordered_ind\n",
    "        if((not fixedPos) and (dropNum > 0 or kobeList)):\n",
    "            plt.close()\n",
    "            df2 = __setCluster(df1,range(len(df1.index)),col)\n",
    "            if(kobeList):\n",
    "                drop = list(isNans)\n",
    "            else:\n",
    "                drop = df2.columns[:dropNum]\n",
    "                drop2 = __changeDrop(drop,directed=directed,reverse=reverse,undirected=undirected)\n",
    "                drop2 = __goodGenes(drop2,df.columns)\n",
    "                df1 = df1.drop(columns=drop2)\n",
    "            lut,placeColors = bnLearnRowColors(df1.index.unique(),colors)\n",
    "            row_colors = df1.index.unique().map(lut)\n",
    "            cg = sb.clustermap(df1,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,col_colors=colColors,\n",
    "                               yticklabels=showMergeY,metric=metric,figsize=size,row_colors=row_colors,col_cluster=cClust)\n",
    "            col = cg.dendrogram_col.reordered_ind\n",
    "        handles = [Patch(facecolor=placeColors[name]) for name in placeColors]\n",
    "        leg1 = plt.legend(handles, placeColors, title='Places',bbox_to_anchor=(0.175, 0.75),\n",
    "                          bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "        if not colLut=='R':\n",
    "            handles = [Patch(facecolor=colLut[name]) for name in colLut]\n",
    "            leg2 = plt.legend(handles, colLut, title='',bbox_to_anchor=(1.175, 0.75),\n",
    "                              bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "    else:\n",
    "        if(kobeList):\n",
    "            colColors,colLut = BNLearnColColors(df1,reverse=reverse,undirected=undirected,directed=directed)\n",
    "        else:\n",
    "            colColors=None\n",
    "            colLut='R'\n",
    "        cg = sb.clustermap(df1,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,yticklabels=1,col_cluster=cClust,\n",
    "                           metric=metric,figsize=size,col_colors=colColors)\n",
    "        title2 += ', '+l1\n",
    "        if not colLut=='R':\n",
    "            handles = [Patch(facecolor=colLut[name]) for name in colLut]\n",
    "            plt.legend(handles, colLut, title='',\n",
    "                       bbox_to_anchor=(1.175, 0.75), bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "        if not(fixedPos):\n",
    "            plt.close()\n",
    "            col = cg.dendrogram_col.reordered_ind\n",
    "            df2 = __setCluster(df1,range(len(df1.index)),col) \n",
    "            if(kobeList):\n",
    "                drop = isNans\n",
    "            else:\n",
    "                drop = df2.columns[:dropNum]\n",
    "                df1 = df1.drop(columns=drop)\n",
    "            if(kobeList):\n",
    "                colColors,colLut = BNLearnColColors(df1,reverse=reverse,undirected=undirected,directed=directed)\n",
    "            else:\n",
    "                colColors=None\n",
    "                colLut='R'\n",
    "            cg = sb.clustermap(df1,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,yticklabels=1,col_cluster=cClust,\n",
    "                               metric=metric,figsize=size,col_colors=colColors)\n",
    "            if not colLut=='R':\n",
    "                handles = [Patch(facecolor=colLut[name]) for name in colLut]\n",
    "                plt.legend(handles, colLut, title='',\n",
    "                           bbox_to_anchor=(1.175, 0.75), bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "            col = cg.dendrogram_col.reordered_ind        \n",
    "        \n",
    "    if(onlyBGE):\n",
    "        title2 += ', Only BGE'\n",
    "    if(onlyBDE):\n",
    "        title2 += ', Only BDE'\n",
    "    if(kobeList):\n",
    "        title2 += ', Kobe Gene List, thres = '+str(thres)\n",
    "    if(undirected):\n",
    "        title2 ='Undirected, '+title2\n",
    "    else:\n",
    "        if(directed):\n",
    "            if(reverse):\n",
    "                title2 ='Direction B-A, '+title2\n",
    "            else:\n",
    "                title2 ='Direction A-B, '+title2\n",
    "        else:\n",
    "            if(allDir):\n",
    "                title2 = 'All Directions, '+title2\n",
    "            else:\n",
    "                title2 = 'Direction Agnostic, '+title2 \n",
    "    \n",
    "    if(split):\n",
    "        plt.close()\n",
    "        df2 = __setCluster(df,range(len(df.index)),col)\n",
    "        half = round(len(df2.columns)/2)\n",
    "        dfP1 = df2.columns[:half]\n",
    "        dfP2 = df2.columns[half:]\n",
    "        dfP1 = df2[dfP1]\n",
    "        dfP2 = df2[dfP2]\n",
    "        if(len(newNames)>1):\n",
    "            if(kobeList):\n",
    "                colColors,colLut = BNLearnColColors(dfP1,reverse=reverse,undirected=undirected,directed=directed)\n",
    "            else:\n",
    "                colColors=None\n",
    "                colLut='R'\n",
    "            cg = sb.clustermap(dfP1,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,col_cluster=False,col_colors=colColors,\n",
    "                               yticklabels=showMergeY,metric=metric,figsize=size,row_colors=row_colors)\n",
    "            title3 = title2+', Part 1'\n",
    "            cg.ax_heatmap.set_xlabel('Pathway Pairings',size=20)\n",
    "            cg.ax_heatmap.set_ylabel('Input Data',size=20)\n",
    "            cg.ax_row_dendrogram.set_visible(False)\n",
    "            cg.ax_col_dendrogram.set_visible(False)\n",
    "            plt.setp(cg.ax_heatmap.get_xticklabels(),rotation='45',ha='right',size=fsX)\n",
    "            plt.setp(cg.ax_heatmap.get_yticklabels(),va='bottom',size=fsY,rotation='0')\n",
    "            title3=title3.replace(', ,',', ').replace(' , ','').replace('  ','').replace(',P',', P')\n",
    "            plt.title(title3,size=25,y=1,x=8)\n",
    "            handles = [Patch(facecolor=placeColors[name]) for name in placeColors]\n",
    "            plt.legend(handles, placeColors, title='Places',bbox_to_anchor=(0.175, 0.75),\n",
    "                       bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "            if not colLut=='R':\n",
    "                handles = [Patch(facecolor=colLut[name]) for name in colLut]\n",
    "                plt.legend(handles, colLut, title='',\n",
    "                           bbox_to_anchor=(1.175, 0.75), bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "            \n",
    "            if(save):\n",
    "                plt.savefig('Saved Images/'+title3+'.pdf',bbox_inches = \"tight\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                print(title3)\n",
    "            plt.close()\n",
    "            if(kobeList):\n",
    "                colColors,colLut = BNLearnColColors(dfP2,reverse=reverse,undirected=undirected,directed=directed)\n",
    "            else:\n",
    "                colColors=None\n",
    "                colLut='R'\n",
    "            cg = sb.clustermap(dfP2,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,col_cluster=False,col_colors=colColors,\n",
    "                               yticklabels=showMergeY,metric=metric,figsize=size,row_colors=row_colors)\n",
    "            handles = [Patch(facecolor=placeColors[name]) for name in placeColors]\n",
    "            plt.legend(handles, placeColors, title='Places',bbox_to_anchor=(0.175, 0.75),\n",
    "                       bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "            title3 = title2+', Part 2'\n",
    "            title3=title3.replace(', ,',', ').replace(' , ','').replace('  ','').replace(',P',', P')\n",
    "            cg.ax_heatmap.set_xlabel('Pathway Pairings',size=20)\n",
    "            cg.ax_heatmap.set_ylabel('Input Data',size=20)\n",
    "            cg.ax_row_dendrogram.set_visible(False)\n",
    "            cg.ax_col_dendrogram.set_visible(False)\n",
    "            plt.setp(cg.ax_heatmap.get_xticklabels(),rotation='45',ha='right',size=fsX)\n",
    "            plt.setp(cg.ax_heatmap.get_yticklabels(),va='bottom',size=fsY,rotation='0')\n",
    "            plt.title(title3,size=25,y=1,x=8)\n",
    "            if not colLut=='R':\n",
    "                handles = [Patch(facecolor=colLut[name]) for name in colLut]\n",
    "                plt.legend(handles, colLut, title='',\n",
    "                           bbox_to_anchor=(1.175, 0.75), bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "            if(save):\n",
    "                plt.savefig('Saved Images/'+title3+'.pdf',bbox_inches = \"tight\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                print(title3)\n",
    "            plt.close()\n",
    "            \n",
    "        else:\n",
    "            if(kobeList):\n",
    "                colColors,colLut = BNLearnColColors(dfP1,reverse=reverse,undirected=undirected,directed=directed)\n",
    "            else:\n",
    "                colColors=None\n",
    "                colLut='R'\n",
    "            cg = sb.clustermap(dfP1,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,col_cluster=False,yticklabels=1,\n",
    "                               metric=metric,figsize=size,col_colors=colColors)\n",
    "\n",
    "            title3 = title2+', Part 1'\n",
    "            title3=title3.replace(', ,',', ').replace(' , ','').replace('  ','').replace(',P',', P')\n",
    "            cg.ax_heatmap.set_xlabel('Pathway Pairings',size=20)\n",
    "            cg.ax_heatmap.set_ylabel('Input Data',size=20)\n",
    "            cg.ax_row_dendrogram.set_visible(False)\n",
    "            cg.ax_col_dendrogram.set_visible(False)\n",
    "            plt.setp(cg.ax_heatmap.get_xticklabels(),rotation='45',ha='right',size=fsX)\n",
    "            plt.setp(cg.ax_heatmap.get_yticklabels(),va='bottom',size=fsY,rotation='0')\n",
    "            plt.title(title3,size=25,y=1,x=8)\n",
    "            if not colLut=='R':\n",
    "                handles = [Patch(facecolor=colLut[name]) for name in colLut]\n",
    "                plt.legend(handles, colLut, title='',\n",
    "                           bbox_to_anchor=(1.175, 0.75), bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "            if(save):\n",
    "                plt.savefig('Saved Images/'+title3+'.pdf',bbox_inches = \"tight\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                print(title3)\n",
    "            plt.close()\n",
    "            \n",
    "            if(kobeList):\n",
    "                colColors,colLut = BNLearnColColors(dfP2,reverse=reverse,undirected=undirected,directed=directed)\n",
    "            else:\n",
    "                colColors=None\n",
    "                colLut='R'\n",
    "            \n",
    "            cg = sb.clustermap(dfP2,cmap=cmap,vmin=vmin,vmax=vmax,xticklabels=1,yticklabels=1,col_cluster=False,\n",
    "                               metric=metric,figsize=size,col_colors=colColors)\n",
    "            title3 = title2+', Part 2'\n",
    "            title3=title3.replace(', ,',', ').replace(' , ','').replace('  ','').replace(',P',', P')\n",
    "            cg.ax_heatmap.set_xlabel('Pathway Pairings',size=20)\n",
    "            cg.ax_heatmap.set_ylabel('Input Data',size=20)\n",
    "            cg.ax_row_dendrogram.set_visible(False)\n",
    "            cg.ax_col_dendrogram.set_visible(False)\n",
    "            plt.setp(cg.ax_heatmap.get_xticklabels(),rotation='45',ha='right',size=fsX)\n",
    "            plt.setp(cg.ax_heatmap.get_yticklabels(),va='bottom',size=fsY,rotation='0')\n",
    "            plt.title(title3,size=25,y=1,x=8)\n",
    "            if not colLut=='R':\n",
    "                handles = [Patch(facecolor=colLut[name]) for name in colLut]\n",
    "                plt.legend(handles, colLut, title='',\n",
    "                           bbox_to_anchor=(1.175, 0.75), bbox_transform=plt.gcf().transFigure, loc=0, prop={'size': 15})\n",
    "            if(save):\n",
    "                plt.savefig('Saved Images/'+title3+'.pdf',bbox_inches = \"tight\")\n",
    "            else:\n",
    "                plt.show()\n",
    "                print(title3)\n",
    "            plt.close()\n",
    "    else:     \n",
    "        cg.ax_heatmap.set_xlabel('Pathway Pairings',size=20)\n",
    "        cg.ax_heatmap.set_ylabel('Input Data',size=20)\n",
    "        cg.ax_row_dendrogram.set_visible(False)\n",
    "        cg.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "        plt.setp(cg.ax_heatmap.get_xticklabels(),rotation='45',ha='right',size=fsX)\n",
    "        plt.setp(cg.ax_heatmap.get_yticklabels(),va='bottom',size=fsY,rotation='0')\n",
    "        plt.title(title2,size=25,y=1,x=8)\n",
    "        if(save):\n",
    "            plt.savefig('Saved Images/'+title2+'.pdf',bbox_inches = \"tight\")\n",
    "        else:\n",
    "            plt.show()\n",
    "            print(title2)\n",
    "        plt.close()\n",
    "    if fixedPos:\n",
    "        col = pos.copy()\n",
    "        drop = drop.copy()\n",
    "    return col,drop\n",
    "\n",
    "def __BNOutDict(graphLst,reverse=False,undirected=False,directed=False,dropImmune=False,allDir=False,sub1=True):\n",
    "    if(allDir):\n",
    "        outDict, nameLst = __BNOutDict(graphLst,directed=True,dropImmune=dropImmune,allDir=False,sub1=False)\n",
    "        out1 = __BNOutDict(graphLst,directed=True,reverse=True,dropImmune=dropImmune,allDir=False,sub1=False)[0]\n",
    "        out2 = __BNOutDict(graphLst,undirected=True,dropImmune=dropImmune,allDir=False,sub1=False)[0]\n",
    "        outDict = {**outDict, **out1}\n",
    "        outDict = {**outDict, **out2}\n",
    "    else:\n",
    "        immuneLst=['T.Eff','IFNg','Antigen']\n",
    "        outDict={}\n",
    "        nameLst=[]\n",
    "        frst=True\n",
    "        for graph in graphLst:\n",
    "            outName = graph.split('\\\\')[1].replace('.csv','').strip()\n",
    "            nameLst.append(outName)\n",
    "            g = pd.read_csv(graph,index_col=0)\n",
    "            if(frst):\n",
    "                cols = g['from'].unique()\n",
    "                for num in range(len(cols)):\n",
    "                    pair1 = cols[num]\n",
    "                    pair1 = pair1.replace('.Scores','')\n",
    "                    for num2 in range(num,len(cols)):\n",
    "                        pair2 = cols[num2]\n",
    "                        pair2 = pair2.replace('.Scores','')\n",
    "                        if(pair1!=pair2 and pair1!='Purity' and pair2!='Purity'):\n",
    "                            val = (pair1 in immuneLst or pair2 in immuneLst)\n",
    "                            if not (dropImmune and val):\n",
    "                                if undirected:\n",
    "                                    outDict[pair1+' -- '+pair2]=[]\n",
    "                                else:\n",
    "                                    if directed:\n",
    "                                        if reverse:\n",
    "                                            outDict[pair2+' -> '+pair1]=[]\n",
    "                                        else:\n",
    "                                            outDict[pair1+' -> '+pair2]=[]\n",
    "                                    else:\n",
    "                                        outDict[pair1+' '+pair2]=[]\n",
    "                frst=False\n",
    "            for pair in g.index:\n",
    "                direct = g.loc[pair]['direction']\n",
    "                strength = g.loc[pair]['strength'] \n",
    "                if(undirected):\n",
    "                    fromm = g.loc[pair]['from']\n",
    "                    to = g.loc[pair]['to']\n",
    "                    g2 = g.loc[g['to'] == fromm]\n",
    "                    g2 = g2.loc[g2['from']==to]\n",
    "                    direct2 = g2['direction'].values[0]\n",
    "                    if((direct < 0.35 or direct2 < 0.35) and sub1):\n",
    "                        strength = strength-1\n",
    "                else:\n",
    "                    if(directed and direct < 0.65 and sub1):\n",
    "                        strength = strength-1\n",
    "                if(undirected):\n",
    "                    pairing = g.loc[pair]['from']+' -- '+g.loc[pair]['to']\n",
    "                else:\n",
    "                    if(directed):\n",
    "                        pairing = g.loc[pair]['from']+' -> '+g.loc[pair]['to']\n",
    "                    else:\n",
    "                        pairing = g.loc[pair]['from']+' '+g.loc[pair]['to']\n",
    "                pairing = pairing.replace('.Scores','')\n",
    "                if(direct==0):\n",
    "                    strength = 0.0\n",
    "                if(pairing in outDict):\n",
    "                    outDict[pairing].append(strength)\n",
    "    return outDict, nameLst\n",
    "\n",
    "def __renameBNOut(dfIn):\n",
    "    df = dfIn.copy()\n",
    "    dfInx =[]\n",
    "    for col in df.columns:\n",
    "        if not col.split(',')[0] in dfInx: \n",
    "            dfInx.append(col.split(',')[0])\n",
    "    newNames = getUniqueNames(dfInx)\n",
    "    sepNum = math.ceil(len(df.columns)/len(newNames))\n",
    "    newIdx=[]\n",
    "    num=0\n",
    "    newNamesNum=0\n",
    "    for col in df.columns:\n",
    "        if num ==sepNum:\n",
    "            newNamesNum+=1\n",
    "        lst = col.split(',')\n",
    "        l0 = newNames[newNamesNum]\n",
    "        l1 = lst[1]\n",
    "        l2 = lst[2]\n",
    "        newL = [l0,l1,l2]\n",
    "        newL2 = [l0,l2]\n",
    "        if(len(lst)>3):\n",
    "            l3 = lst[3]\n",
    "            newL.append(l3)\n",
    "            newL2.append(l3)\n",
    "        if(len(lst)>4):\n",
    "            l4 = lst[4]\n",
    "            newL.append(l4)\n",
    "            newL2.append(l4)\n",
    "        if(len(newNames)>1 or (l0 == 'Pre-BN')):\n",
    "            newIdx.append(','.join(newL))\n",
    "        else:\n",
    "            newIdx.append(','.join(newL2))\n",
    "        if(num==sepNum):\n",
    "            num=1\n",
    "        else:\n",
    "            num +=1\n",
    "    return newIdx, newNames, l1\n",
    "\n",
    "def __onlyBGEorBDE(graphLst,onlyBGE=True,onlyBDE=False):\n",
    "    if(onlyBDE or onlyBGE):\n",
    "        if(onlyBGE):\n",
    "            tpy='G'\n",
    "        if(onlyBDE):\n",
    "            tpy='MN'\n",
    "        graphLst2=[]\n",
    "        for graph in graphLst:\n",
    "            ls = graph.split('\\\\')[1]\n",
    "            if tpy in ls:\n",
    "                graphLst2.append(graph)\n",
    "        graphLst=graphLst2\n",
    "    return graphLst\n",
    "\n",
    "def renameBNLearnOut():\n",
    "    graphLst = glob.glob('Run BNLearn/Outputs/*')\n",
    "    for graph in graphLst:\n",
    "        start = graph.split('\\\\')[0]\n",
    "        ls = graph.split('\\\\')[1].split(',')\n",
    "        g = ls[-1]\n",
    "        if('BGE' in g):\n",
    "            g = ' G.csv'\n",
    "        if('BDE' in g):\n",
    "            g = ' MN.csv'\n",
    "        graphNew = ','.join([ls[0],ls[1],ls[2],ls[3],g])\n",
    "        graphNew = '\\\\'.join([start,graphNew])\n",
    "        os.rename(graph,graphNew)    \n",
    "    return 1\n",
    "\n",
    "def __BNGraphsTinyBegin(globDir,pathways,onlyBGE,onlyBDE):\n",
    "    if not pathways:\n",
    "        graphLst = glob.glob(globDir)\n",
    "    else:\n",
    "        graphLst = globExclude(globDir,exclude='Kobe Genes')\n",
    "    graphLst = __onlyBGEorBDE(graphLst,onlyBGE=onlyBGE,onlyBDE=onlyBDE)\n",
    "    return graphLst\n",
    "\n",
    "def makeBNGraphsDBs(thres=0.5,onlyBGE=False,onlyBDE=False,merged=False,dirThres=0.65,below=False,thresFloor=0.3,\n",
    "                    undirected=False,dropImmune=False,globDir='Run BNLearn/Outputs/*',dropPure=False,colored=False,\n",
    "                    pathways=False,title='',excludePre=False,nonToIm=False,colorDict={},useDict={},\n",
    "                    kobeColor=False,onlyConnected=True,erase=False,interPath=False,immuneNonOnly=False,mergedAll=False):\n",
    "    graphLst = __BNGraphsTinyBegin(globDir=globDir,pathways=pathways,onlyBGE=onlyBGE,onlyBDE=onlyBDE)\n",
    "    dbLs = []\n",
    "    for graph in graphLst:\n",
    "        ls = graph.split('\\\\')[1].split(',')\n",
    "        if('BN Merged' in ls[0]):\n",
    "            db = ls[1].strip()\n",
    "        else:\n",
    "            db = ls[2].strip()\n",
    "        dbLs.append(db)\n",
    "    dbLs = list(set(dbLs))\n",
    "    for db in dbLs:\n",
    "        globDir2 = globDir+db+'*'\n",
    "        title2 = 'DataBase is '+db+title+', '\n",
    "        placeLs = makeBNGraphs(thres=thres,onlyBGE=onlyBGE,onlyBDE=onlyBDE,merged=merged,dirThres=dirThres,below=below,\n",
    "                               title=title2,thresFloor=thresFloor,undirected=undirected,dropImmune=dropImmune,\n",
    "                               globDir=globDir2,dropPure=dropPure,colored=colored,pathways=pathways,kobeColor=kobeColor,\n",
    "                               onlyConnected=onlyConnected,erase=erase,interPath=interPath,immuneNonOnly=immuneNonOnly,\n",
    "                               mergedAll=mergedAll,excludePre=excludePre,nonToIm=nonToIm,\n",
    "                               colorDict=colorDict,useDict=useDict)\n",
    "    if(mergedAll):\n",
    "        placeLs.append('Post-BN Merged')\n",
    "    return placeLs, dbLs\n",
    "\n",
    "def makeBNGraphs(thres=0.5,onlyBGE=False,onlyBDE=False,merged=False,dirThres=0.65,below=False,thresFloor=0.3,\n",
    "                 undirected=False,dropImmune=False,globDir='Run BNLearn/Outputs/*',dropPure=False,colored=False,\n",
    "                 pathways=False,title='',excludePre=False,agnostic=False,nonToIm=False,\n",
    "                 colorDict={},useDict={},blackList=False,blackListFile='',dictIn={},\n",
    "                 kobeColor=False,onlyConnected=True,erase=False,interPath=False,immuneNonOnly=False,mergedAll=False,\n",
    "                 allowPaths=False,depthOfPaths=1,rmvLen=False):\n",
    "    \"\"\"\n",
    "    makeGraphs:\n",
    "        Inputs:\n",
    "            thres: the edge strength threshold that must be passed for an edge to be inlcuded in the graph\n",
    "                default: 0.5\n",
    "            onlyBGE and onlyBDE, booleans telling if to only create plots for BNLearn outputs that used \n",
    "                    'bge'/'bde' scoreing methods \n",
    "                deafult: False for both\n",
    "            merged: boolean telling if to create a single graph for each cancer \n",
    "                    (using the average edge and direction strengths of all outputs related to that cacner), or plot each\n",
    "                    output individually\n",
    "                default: False\n",
    "            dirThres: an edge in the graph will be deemed as directed if that edge's direction strength is \n",
    "                      greater than dirThres, if both directions of an edge are below dirThres that edge will be \n",
    "                      considered as undirected.\n",
    "                deafult: 0.65\n",
    "            undirected: boolean telling if to inlcude undirected edges in the graph (as defined by dirThres), or\n",
    "                        ignore them and only plot directed edges\n",
    "                default: False\n",
    "        Actions:\n",
    "            Using all the outputs from BNLearn (all files in the 'Run BNLearn/Outputs/' directory), this function creates a\n",
    "                graphviz image from that output. Inlcuding all nodes from the output, and all edges that have a \n",
    "                strength/confidence > thres and the direction strength > dirThres. \n",
    "                If undirected=True will also inlcude edges where no direction is > dirThres, as undirected edges.\n",
    "                Inlcudes a label on all edges with the edge strength and the direction strength (in parenthesis), \n",
    "                undirected edges only have the edge strength for a label.\n",
    "            All the created graphs will be saved in the 'Graphs/' directory, if graphviz is intalled correctly will save pdfs\n",
    "                of the graphviz image, else will be saved as a graphviz file that can be graphed with other graphviz software\n",
    "                (http://graphviz.it/#/new)\n",
    "            Output:\n",
    "                On sucess returns 1.\n",
    "    \"\"\"\n",
    "    graphLst = __BNGraphsTinyBegin(globDir=globDir,pathways=pathways,onlyBGE=onlyBGE,onlyBDE=onlyBDE);placeLs = []\n",
    "    if(excludePre):graphLst = __removeLstFunc(graphLst,'PrePure')\n",
    "    for graph in graphLst:place = graph.split('\\\\')[1].split(',')[0].strip();placeLs.append(place)\n",
    "    placeLs = list(set(placeLs));title2 = title+'All Methods'\n",
    "    if(onlyBGE):title2 = title+'Only BGE'\n",
    "    if(onlyBDE):title2 = title+'Only BDE'\n",
    "    if(interPath):\n",
    "        title2 += ', Only InterPathway Edges'\n",
    "        if(immuneNonOnly):\n",
    "            if nonToIm:title2 += ' Non-Immune Edges'\n",
    "            else:title2 += ' Immune-Non Edges'\n",
    "    if(immuneNonOnly):title += ', '\n",
    "    title2 +=', Confidence '+str(thres)\n",
    "    if not mergedAll:\n",
    "        for place in tq(placeLs,desc='Making BN Graphs'):\n",
    "            graphLst2 = [p for p in graphLst if place in p]\n",
    "            helpMakeGraphs(graphLst=graphLst2,merged=merged,thres=thres,title=title2,undirected=undirected,interPath=interPath,\n",
    "                           dirThres=dirThres,dropImmune=dropImmune,dropPure=dropPure,colored=colored,kobeColor=kobeColor,\n",
    "                           agnostic=agnostic,nonToIm=nonToIm,pathways=pathways,blackList=blackList,\n",
    "                           blackListFile=blackListFile,dictIn=dictIn,allowPaths=allowPaths,depthOfPaths=depthOfPaths,\n",
    "                           colorDictIn=colorDict,useDict=useDict,mergedAll=False,rmvLen=rmvLen,\n",
    "                           below=below,thresFloor=thresFloor,onlyConnected=onlyConnected,immuneNonOnly=immuneNonOnly)\n",
    "    else:\n",
    "        if(agnostic):\n",
    "            __BNGraphsAgnosMerged(placeLs=placeLs,graphLst=graphLst,dropImmune=dropImmune,dropPure=dropPure,\n",
    "                                  agnostic=agnostic,dirThres=dirThres,nonToIm=nonToIm,pathways=pathways,\n",
    "                                  thres=thres,thresFloor=thresFloor,interPath=interPath,immuneNonOnly=immuneNonOnly,\n",
    "                                  below=below,undirected=undirected,colored=colored,title=title,\n",
    "                                  onlyBDE=onlyBDE,onlyBGE=onlyBGE)\n",
    "        else:\n",
    "            graphLst = __removeLstFunc(graphLst,'Pre-BN')\n",
    "            helpMakeGraphs(graphLst=graphLst,merged=merged,thres=thres,title=title2,undirected=undirected,interPath=interPath,\n",
    "                           dirThres=dirThres,dropImmune=dropImmune,dropPure=dropPure,colored=colored,kobeColor=kobeColor,\n",
    "                           agnostic=agnostic,nonToIm=nonToIm,pathways=pathways,mergedAll=True,\n",
    "                           colorDictIn=colorDict,useDict=useDict,blackList=blackList,rmvLen=rmvLen,\n",
    "                           blackListFile=blackListFile,dictIn=dictIn,allowPaths=allowPaths,depthOfPaths=depthOfPaths,\n",
    "                           below=below,thresFloor=thresFloor,onlyConnected=onlyConnected,immuneNonOnly=immuneNonOnly)\n",
    "            \n",
    "        makeBNGraphs(thres=thres,onlyBGE=onlyBGE,onlyBDE=onlyBDE,merged=merged,dirThres=dirThres,below=below,title=title,\n",
    "                     thresFloor=thresFloor,undirected=undirected,dropImmune=dropImmune,globDir=globDir,dropPure=dropPure,\n",
    "                     colored=colored,kobeColor=kobeColor,onlyConnected=onlyConnected,erase=erase,interPath=interPath,\n",
    "                     excludePre=excludePre,useDict=useDict,colorDict=colorDict,\n",
    "                     immuneNonOnly=immuneNonOnly,mergedAll=False,pathways=pathways,agnostic=agnostic,nonToIm=nonToIm)\n",
    "    if(erase):\n",
    "        for file in glob.glob('Graphs/*'):\n",
    "            if not '.pdf' in file:os.remove(file)\n",
    "    return placeLs\n",
    "\n",
    "def helpMakeGraphs(graphLst,merged,thres,title,undirected,below,thresFloor,mergedAll,\n",
    "                   dirThres,dropImmune,colored,dropPure,interPath,immuneNonOnly,dictIn,\n",
    "                   kobeColor,onlyConnected,agnostic,nonToIm,pathways,blackList,blackListFile,\n",
    "                   colorDictIn,useDict,allowPaths,depthOfPaths,rmvLen):\n",
    "    if not merged:\n",
    "        for graph in graphLst:\n",
    "            outName = graph.split('\\\\')[1].replace('.csv','').strip()\n",
    "            g = __getMergedG([graph],immuneDict=colorDict,dictIn=useDict,dropImmune=dropImmune,\n",
    "                             dropPure=dropPure,agnostic=agnostic,thres=thres,nonToIm=nonToIm,below=False,\n",
    "                             thresFloor=thresFloor,interPath=interPath,immuneNonOnly=immuneNonOnly,dirThres=dirThres,\n",
    "                             pathways=pathways,allowPaths=allowPaths,depthOfPaths=depthOfPaths,rmvLen=rmvLen)\n",
    "            outName = outName+', '+title\n",
    "            __helpMakeGraphsCreate(g[0],thres,outName,undirected=undirected,kobeColor=kobeColor,onlyConnected=onlyConnected,\n",
    "                                   immuneNonOnly=immuneNonOnly,inputsLst=g[2],colorDictIn=colorDictIn,\n",
    "                                   useDict=useDict,blackList=blackList,blackListFile=blackListFile,\n",
    "                                   dirThres=dirThres,colored=colored,below=below,thresFloor=thresFloor,interPath=interPath)\n",
    "    else:\n",
    "        g = __getMergedG(graphLst,immuneDict=colorImmuneDict,dictIn=colorDictIn,dropImmune=dropImmune,\n",
    "                         dropPure=dropPure,agnostic=agnostic,dirThres=dirThres,nonToIm=nonToIm,pathways=pathways,\n",
    "                         allowPaths=allowPaths,depthOfPaths=depthOfPaths,rmvLen=rmvLen,\n",
    "                         thres=thres,thresFloor=thresFloor,interPath=interPath,immuneNonOnly=immuneNonOnly)\n",
    "        g1P = g[1].replace('Kobe Genes ','');outName = g1P+' Average'\n",
    "        if(g1P==''):return 0\n",
    "        if(g1P!='Pre-BN Merged'):\n",
    "            df = pd.read_csv('Purity/TPM/v1/TCGA_'+g1P+'_tpm.tsv',sep='\\t',index_col=0)\n",
    "            placeLen = str(len(df.columns));outName += ', N = '+placeLen\n",
    "        if(mergedAll):outName = 'Post-BN Merged Average'\n",
    "        if(agnostic):outName += ', Gene Agnostic'\n",
    "        else:\n",
    "            if(kobeColor):outName += ', Genes'\n",
    "            else:outName += ', Pathways'\n",
    "        if(below):outName += ', Confidence Range '+str(thresFloor)+' to '+str(thres)\n",
    "        else:outName=outName+', Confidence Range '+str(thres)+' to '+str(1)\n",
    "        outName += ', Direction '+str(dirThres)+', '+title\n",
    "        if not agnostic:\n",
    "            __helpMakeGraphsCreate(g[0],thres=thres,kobeColor=kobeColor,onlyConnected=onlyConnected,immuneNonOnly=immuneNonOnly,\n",
    "                                   outName=outName,below=below,thresFloor=thresFloor,interPath=interPath,colorsLst=colorsLst,\n",
    "                                   colorDictIn=colorDictIn,colorImmuneDict=colorImmuneDict,blackList=blackList,\n",
    "                                   blackListFile=blackListFile,\n",
    "                                   undirected=undirected,dirThres=dirThres,colored=colored,inputsLst=g[2])\n",
    "        else:\n",
    "            ____helpMakeGraphsCreateAgnos(g[0],outName=outName,undirected=undirected,colored=colored)\n",
    "    return 1\n",
    "def agnosticLists(direct,undirect,frm,to,frmLst,toLst,numLst,dirLst):\n",
    "    g2 = direct[direct['from']==frm];g2 = g2[g2['to']==to];num = len(g2.index)\n",
    "    frmLst.append(frm);toLst.append(to);numLst.append(num);dirLst.append(1);g2 = undirect[undirect['from']==frm]\n",
    "    g2 = g2[g2['to']==to];num = len(g2.index);frmLst.append(frm);toLst.append(to);numLst.append(num);dirLst.append(0)\n",
    "    return 1\n",
    "def ____helpMakeGraphsCreateAgnos(df,outName,undirected=False,colored=True):\n",
    "    Nodes = df['from'].unique();Nodes2 = df['to'].unique();Nodes = list(set(list(Nodes)+list(Nodes2)))\n",
    "    direct = df[df['Directed']==1];undirect = df[df['Directed']==0];dot = Digraph()\n",
    "    dot.attr(width=\"900pt\", height=\"18000pt\",fixedsize='true')\n",
    "    if(colored):\n",
    "        topLs=[];n1 = direct['from'].unique();n2 = direct['to'].unique()\n",
    "        u1 = list(undirect['from'].unique());u2 = list(undirect['to'].unique());u1.extend(n1)\n",
    "        u1 = list(set(u1));u2.extend(n2);u2 = list(set(u2));topLs=[]\n",
    "        for row in u1:\n",
    "            if not row in u2:topLs.append(row)\n",
    "        colorPathDict={};kobe = getKobeClique();kobe2={}\n",
    "        for path in kobe:\n",
    "            lst = __runGenes(kobe[path]);kobe2[path]=lst\n",
    "        immuneLst=['T-Eff','IFNg','Antigen Process'];colorImmune=['red','indianred1','crimson']\n",
    "        colorLst=list(range(1,7));j=0;i=0\n",
    "        for path in kobe2:\n",
    "            lst = kobe2[path]\n",
    "            if path in immuneLst:color = colorImmune[j];j+=1\n",
    "            else:color = colorLst[i];i+=1\n",
    "            colorPathDict[path] = color\n",
    "        colorPathDict['Heat']= 'orangered';colorPathDict['Purity'] = 'grey';colorPathDict['Cancer Area'] = 'aliceblue'\n",
    "    colorLst=[]    \n",
    "    for node in Nodes:\n",
    "        node = node.replace('Scores','');node = node.replace('.','')\n",
    "        if(colored):\n",
    "            color= colorPathDict[node]\n",
    "            if(type(color)==str):dot.node(node,style='filled',color=color);colorLst.append(color)\n",
    "            else:dot.node(node,style='filled',colorscheme='pastel26',color=str(color));colorLst.append(color)\n",
    "        else:dot.node(node)\n",
    "        dot.node(node+'3',style='invis');dot.node(node+'4',style='invis')\n",
    "    for i in direct.index:\n",
    "        if colored:color='blue'\n",
    "        else:color ='blue'\n",
    "        if(type(color)==str):\n",
    "            dot.edge(direct['from'][i],direct['to'][i],label=str(direct['Number of Connections'][i]),color=color)\n",
    "        else:\n",
    "            dot.edge(direct['from'][i],direct['to'][i],label=str(direct['Number of Connections'][i]),\n",
    "                     colorscheme='pastel26',color=str(color))\n",
    "        mid = direct['from'][i]+'3';mid2 = direct['from'][i]+'4'\n",
    "        dot.edge(direct['from'][i],mid,style='invis')\n",
    "        dot.edge(mid,mid2,style='invis');dot.edge(mid2,direct['to'][i],style='invis')\n",
    "    if(undirected):\n",
    "        for i in undirect.index:\n",
    "            dot.edge(undirect['from'][i],undirect['to'][i],label=str(undirect['Number of Connections'][i]),\n",
    "                     arrowhead='none')\n",
    "            mid = undirect['from'][i]+'3';mid2 = undirect['from'][i]+'4'\n",
    "            dot.edge(undirect['from'][i],mid,style='invis')\n",
    "            dot.edge(mid,mid2,style='invis');dot.edge(mid2,undirect['to'][i],style='invis')\n",
    "    if(colored):\n",
    "        if(len(Nodes)>0):\n",
    "            legend = Digraph(name='clusterLegend');legend.attr(label='Legend')\n",
    "            for path in colorPathDict:\n",
    "                color = colorPathDict[path]\n",
    "                if(color in colorLst):\n",
    "                    if(type(color)==str):legend.node(path+'1',style='filled',color=color,label='')\n",
    "                    else:legend.node(path+'1',style='filled',colorscheme='pastel26',color=str(color),label='')\n",
    "                    legend.node(path+'2',label=path,shape=\"plaintext\");legend.edge(path+'1',path+'2',style='invis')\n",
    "            dot.subgraph(legend);n=0;addOn = max((len(topLs)//len(colorPathDict)),1)\n",
    "            if(len(topLs)>0):\n",
    "                for path in colorPathDict:\n",
    "                    color = colorPathDict[path]\n",
    "                    if(color in colorLst):\n",
    "                        node = topLs[n];dot.edge(path+'2',node,style='invis')\n",
    "                        if(n<len(topLs)-addOn):n+=addOn\n",
    "                        else:break\n",
    "    outName = outName.replace(', ,',\",\");dot.attr(label=outName);dot.attr(fontsize='20')\n",
    "    outName = outName.replace(', ,',',')\n",
    "    try:dot.render('Graphs/'+outName,view=False)\n",
    "    except:x=1\n",
    "    return 1\n",
    "\n",
    "def __getMergedG(graphLst,thres,thresFloor,dirThres,dropImmune,dropPure,agnostic,pathways,immuneDict,dictIn,\n",
    "                 below,interPath,immuneNonOnly,nonToIm,allowPaths=False,depthOfPaths=1,rmvLen=False):\n",
    "    if allowPaths:interPath=False;immuneNonOnly=False;nonToIm=False\n",
    "    immuneLst=['T.Eff','IFNg','Antigen'];dfDirLst=[];dfStrLst=[];inputsLst=[]\n",
    "    for graph in graphLst:\n",
    "        inputName = graph.replace('Outputs','Inputs').replace(', G.csv','').replace(', MN.csv','');inputsLst.append(inputName)\n",
    "        outName = graph.split('\\\\')[1].replace('.csv','').strip().split(',')[0]\n",
    "        df = pd.read_csv(graph,index_col=0);df.index = df['from']+'_'+df['to'];df.index.name='Index'\n",
    "        df=df.drop(columns=['from','to']);\n",
    "        if dropPure or dropImmune:\n",
    "            dropLst=[]\n",
    "            for idx in df.index:\n",
    "                if(('Purity' in idx) and dropPure):dropLst.append(idx)\n",
    "                pair1 = idx.split('_')[0];pair2 = idx.split('_')[1]\n",
    "                if( dropImmune and (pair1 in immuneLst or pair2 in immuneLst)):dropLst.append(idx)\n",
    "            df = df.drop(dropLst)\n",
    "        dfDirLst.append(('',df.drop(columns=['strength'])));dfStrLst.append(('',df.drop(columns=['direction'])))\n",
    "    dfAllDir = getdfAll(dfDirLst,idxName='Index');dfAllStr = getdfAll(dfStrLst,idxName='Index')\n",
    "    if type(dfAllStr) == list or type(dfAllDir) == list:\n",
    "        g=pd.DataFrame();return(g,'',[])\n",
    "    strength = dfAllStr.T.mean();idxLst=[]\n",
    "    for idx in strength.index:\n",
    "        idx = idx.replace('.Scores','').replace('.','');idxLst.append(idx)\n",
    "    strength.index=idxLst;direction = dfAllDir.T.mean();direction.index=idxLst;toLst=[];fromLst=[]\n",
    "    for idx in strength.index:\n",
    "        elem = idx.split('_');fromLst.append(elem[0]);toLst.append(elem[1])\n",
    "    g = pd.DataFrame([fromLst,toLst,strength,direction],['from','to','strength','direction']).T\n",
    "    if not(below):g = g[g['strength']>=thres]\n",
    "    else:g = g[g['strength']<thres];g = g[g['strength']>=thresFloor]\n",
    "    if(interPath):\n",
    "        g = interPathwayOnly(g,immuneDict=immuneDict,dictIn=dictIn,immuneNonOnly=immuneNonOnly,nonToIm=nonToIm,\n",
    "                             pathways=pathways)\n",
    "    newToLst=[];newFrmLst=[]\n",
    "    \n",
    "    #for row in g.index:\n",
    "    #    print(g.loc[row])\n",
    "    #    newFrmLst.append(conversionDict[g.loc[row]['from']]);newToLst.append(conversionDict[g.loc[row]['to']])\n",
    "    #g['from']=newFrmLst;g['to']=newToLst\n",
    "    if allowPaths:\n",
    "        g=__getNonToImmPath(depthOfPaths=depthOfPaths,immuneDict=immuneDict,g=g,dictIn=dictIn,immuneNonOnly=immuneNonOnly,\n",
    "                            nonToIm=nonToIm,rmvLen=rmvLen)\n",
    "    if(agnostic):\n",
    "        direct = g[g['direction']>=dirThres];dropLst=[]\n",
    "        for pair in g.index:\n",
    "            direct1 = g.loc[pair]['direction'];fromm = g.loc[pair]['from'];to = g.loc[pair]['to'];g2 = g.loc[g['to'] == fromm]\n",
    "            if(len(g2.index)>0):\n",
    "                g2 = g2.loc[g2['from']==to];direct2 = g2['direction'].values[0]\n",
    "                if not pair in dropLst:dropLst.append(g2.index[0])\n",
    "                if(direct1>dirThres or direct2>dirThres):dropLst.append(pair)\n",
    "        undirect = g.drop(dropLst);kobe = getKobeClique(True);__agnosKobe(direct);__agnosKobe(undirect)\n",
    "        ls = list(set(kobe.values()));dirLst=[];numLst=[];frmLst=[];toLst=[]\n",
    "        for i in range(len(ls)):\n",
    "            for j in range(i+1,len(ls)):\n",
    "                to = ls[i];frm = ls[j]\n",
    "                agnosticLists(direct,undirect,frm,to,frmLst,toLst,numLst,dirLst);to = ls[j];frm = ls[i]\n",
    "                agnosticLists(direct,undirect,frm,to,frmLst,toLst,numLst,dirLst)\n",
    "        df = pd.DataFrame([frmLst,toLst,numLst,dirLst]);df.index = ['from','to','Number of Connections','Directed']\n",
    "        df =df.T;df = df[df['Number of Connections']>0];g = df.dropna()\n",
    "    return (g,outName,inputsLst)\n",
    "def __agnosKobe(df):\n",
    "    kobe = getKobeClique(True)\n",
    "    for row in df.index:\n",
    "        frm = df.loc[row]['from'];too = df.loc[row]['to'];frmPath = kobe[frm];tooPath = kobe[too]\n",
    "        df.loc[row]['from'] = frmPath;df.loc[row]['to'] = tooPath\n",
    "    return 1\n",
    "def __getCorrInputsLst(inputsLst,clique=False):\n",
    "    conversionDict={'Heat':'Heat'};conversionDict['Heat Scores']='HeatScores';frst=True\n",
    "    for fileName in inputsLst:\n",
    "        place=fileName.split(',')[0]\n",
    "        if clique:\n",
    "            place=fileName.split(',')[1];lst=place.split(' N ');place=','.join([lst[0],' N '+lst[1]])\n",
    "            dfNonImm=pd.read_csv('Cliques/Overlapping Cliques, Non-Immune,'+place+'.csv')\n",
    "            dfImm=pd.read_csv('Cliques/Overlapping Cliques, Immune,'+place+'.csv')\n",
    "            for i in dfImm.columns:\n",
    "                conversionDict['Immune'+str(i)]='Immune'+str(i)+'_'+str(len(dfImm[i].dropna()))\n",
    "                conversionDict['Immune '+str(i)]='Immune'+str(i)+'_'+str(len(dfImm[i].dropna()))\n",
    "            for i in dfNonImm.columns:\n",
    "                conversionDict['NonImmune'+str(i)]='NonImmune'+str(i)+'_'+str(len(dfNonImm[i].dropna()))\n",
    "                conversionDict['Non Immune '+str(i)]='NonImmune'+str(i)+'_'+str(len(dfNonImm[i].dropna()))\n",
    "        # Sanatize to avoid removal\n",
    "        fileName=fileName.replace('Glioblastoma','xGlioblastoma') \n",
    "        # Remove Extra info\n",
    "        fileName=fileName.replace(', G','').replace(', NM','').replace(', Sparse','').replace('.csv','')\n",
    "        # Safe to bring back G\n",
    "        fileName=fileName.replace('xG','G')\n",
    "        inpt = pd.read_csv(fileName,sep='\\t',index_col=0)\n",
    "        if frst:\n",
    "            spearTotal=inpt.corr(method='spearman');pearTotal=inpt.corr(method='pearson');frst=False\n",
    "        else:\n",
    "            spear=inpt.corr(method='spearman');pear=inpt.corr(method='pearson');spearTotal += spear;pearTotal += pear\n",
    "    spearTotal /= len(inputsLst);pearTotal /= len(inputsLst);corr=(spearTotal+pearTotal)/2;newLst=[]\n",
    "    for i in corr.index:newLst.append(i.replace('-','.').replace(' ','.'))\n",
    "    corr.index=newLst;corr.columns=newLst\n",
    "    return corr\n",
    "\n",
    "def __getNode2(node,antigen=True,scores=False,corr=True,rmvLen=False):\n",
    "    node2 = node\n",
    "    if corr:\n",
    "        if '-' in node: node2=node.replace('-','.')\n",
    "        if(node=='HLAA'):node2 = 'HLA.A'\n",
    "        if('MT' in node):\n",
    "            splt = node.split('MT')[-1]\n",
    "            node2='MT.'+splt\n",
    "    if(antigen and (node=='PI3K' or node=='AKT')):node2 = 'PI3K/AKT'\n",
    "    if(node=='TEff'):node2='T-Eff'\n",
    "    if(antigen and node=='Antigen'):node2='Antigen.Process'\n",
    "    if scores and 'Purity' in node:node2 = 'Purity.Scores'\n",
    "    if scores and 'Heat' in node:node2 = 'Heat.Scores'\n",
    "    if 'Cancer' in node:node2 = 'Cancer.Area'\n",
    "    if rmvLen:node2 = node.split('_')[0]\n",
    "    return node2\n",
    "\n",
    "def __helpMakeGraphsCreate(g,thres,outName,undirected,dirThres,kobeColor,immuneNonOnly,colorDictIn,useDict,\n",
    "                           colored,onlyConnected,below,thresFloor,interPath,inputsLst,blackList,blackListFile):\n",
    "    setupOut = __setupHelpMakeGraphsCreate(g=g,undirected=undirected,dirThres=dirThres,colored=colored,\n",
    "                                           blackList=blackList,blackListFile=blackListFile,\n",
    "                                           colorDictIn=colorDictIn,useDict=useDict,onlyConnected=onlyConnected)\n",
    "    Nodes,direct,undirect,colorDict,colorDictPath,topLs = setupOut\n",
    "    numNodes = len(Nodes)/10;DPI = str(1000);FS = (round(numNodes*10)+20);NodeFS = str(0.75*FS);FS=str(FS)\n",
    "    numNodes = numNodes/2\n",
    "    if(numNodes)>0.5:RankSep = str(numNodes*3)\n",
    "    else:RankSep = str(0.5)\n",
    "    outName = outName.replace(', ,',',')\n",
    "    dot = Digraph();dot.attr(ranksep=RankSep,dpi=DPI,fontsize=FS,label=outName,size='10,15!',fixedsize='true');colorLst=[]\n",
    "    for node in Nodes:\n",
    "        node = node.replace('Scores','');node = node.replace('.','')\n",
    "        if(colored):\n",
    "            color= colorDict[node]\n",
    "            if(color[0]==0):dot.node(node,style='filled',color=color[1],fontsize=NodeFS);colorLst.append(color)\n",
    "            else:dot.node(node,style='filled',colorscheme=color[1],color=str(color[0]),fontsize=NodeFS);colorLst.append(color)\n",
    "        else:dot.node(node)\n",
    "    corr = __getCorrInputsLst(inputsLst);corr2 = corr.copy()\n",
    "    for i in direct.index:\n",
    "        frm=direct['from'][i];to=direct['to'][i];frm2 = __getNode2(frm,antigen=False,scores=True)\n",
    "        to2 = __getNode2(to,antigen=False,scores=True);corrVal=corr2.loc[frm2][to2]\n",
    "        color = str(__corrValColor(corrVal,rg=True))\n",
    "        if corrVal > 0:\n",
    "            dot.edge(frm,to,label=str(round(direct['strength'][i],2))+\n",
    "                     ' ('+str(round(direct['direction'][i],2))+')',color=color,fontsize=NodeFS)\n",
    "        else:\n",
    "            dot.edge(frm,to,label=str(round(direct['strength'][i],2))+\n",
    "                     ' ('+str(round(direct['direction'][i],2))+')',color=color,fontsize=NodeFS,arrowhead='tee')\n",
    "    if(undirected):\n",
    "        for i in undirect.index:\n",
    "            frm=undirect['from'][i];to=undirect['to'][i]\n",
    "            frm2 = __getNode2(frm,antigen=False,scores=True);to2 = __getNode2(to,antigen=False,scores=True)\n",
    "            corrVal=corr2.loc[frm2][to2];color = str(__corrValColor(corrVal,rg=True))\n",
    "            dot.edge(frm,to,label=str(round(undirect['strength'][i],2)),\n",
    "                     arrowhead='none',color=color,style='dashed',fontsize=NodeFS)\n",
    "    if(colored):\n",
    "        legend = Digraph(name='clusterLegend');legend.attr(label='Legend')\n",
    "        for path in colorDictPath:\n",
    "            color = colorDictPath[path]\n",
    "            if(color[0]==0):legend.node(path+'1',style='filled',color=color[1],label='')\n",
    "            else:legend.node(path+'1',style='filled',colorscheme=color[1],color=str(color[0]),label='')\n",
    "            legend.node(path+'2',label=path,shape=\"plaintext\",fontsize=str(float(NodeFS)*0.75))\n",
    "            legend.edge(path+'1',path+'2',style='invis')\n",
    "        dot.subgraph(legend);n=0;addOn = max((len(topLs)//len(colorDictPath)),1)\n",
    "        if len(topLs)>0:\n",
    "            for path in colorDictPath:\n",
    "                node = topLs[n];dot.edge(path+'2',node,style='invis')\n",
    "                if(n<len(topLs)-addOn):n+=addOn\n",
    "                else:break\n",
    "    try:dot.render('Graphs/'+outName,view=False)\n",
    "    except:x=1\n",
    "    return 1\n",
    "def __setupHelpMakeGraphsCreate(g,undirected,dirThres,colored,onlyConnected,colorDictIn,useDict,\n",
    "                                blackList,blackListFile):\n",
    "    if blackList:\n",
    "        dropNumLst=[];blDf = pd.read_csv(blackListFile,index_col=0)\n",
    "        for gene in blDf.index:\n",
    "            lst = list(blDf.loc[gene].dropna())\n",
    "            l1 = list(g[g['from'] == gene].index);l2 = list(g[g['to'] == gene].index);l3=l1+l2\n",
    "            for i in l3:\n",
    "                if ((g.loc[i]['from'] == gene and g.loc[i]['to'] in lst) or \n",
    "                    (g.loc[i]['to'] == gene and g.loc[i]['from'] in lst)):dropNumLst.append(i)\n",
    "        dropNumLst = list(set(dropNumLst));newIdx=[]\n",
    "        for i in g.index:\n",
    "            if not i in dropNumLst:newIdx.append(i)\n",
    "        g=g.loc[newIdx]\n",
    "    Nodes = g['from'].unique()\n",
    "    Nodes2 = g['to'].unique();Nodes = list(set(list(Nodes)+list(Nodes2)));direct = g[g['direction']>=dirThres]\n",
    "    n1 = direct['from'].unique();n2 = direct['to'].unique();topLs=[]\n",
    "    for row in n1:\n",
    "        if not row in n2:topLs.append(row)\n",
    "    undirect=0\n",
    "    if(undirected):\n",
    "        dropLst=[]\n",
    "        for pair in g.index:\n",
    "            save=False;direct1 = g.loc[pair]['direction'];strength = g.loc[pair]['strength'] \n",
    "            fromm = g.loc[pair]['from'];to = g.loc[pair]['to'];g2 = g.loc[g['to'] == fromm];g2 = g2.loc[g2['from']==to]\n",
    "            if(g2.index>0):\n",
    "                direct2 = g2['direction'].values[0]\n",
    "                if not pair in dropLst and (direct1<dirThres and direct2<dirThres):save=True\n",
    "            if not save:dropLst.append(pair)\n",
    "        undirect = g.drop(dropLst)\n",
    "        for row in direct.index:\n",
    "            pairF = direct.loc[row]['from'];pairT = direct.loc[row]['to']\n",
    "        u1 = list(undirect['from'].unique());u2 = list(undirect['to'].unique())\n",
    "        u1.extend(n1);u1 = list(set(u1));u2.extend(n2);u2 = list(set(u2));topLs=[]\n",
    "        for row in u1:\n",
    "            if not row in u2:topLs.append(row)\n",
    "    if(onlyConnected):    \n",
    "        n1 = list(direct['from'].unique());n2 = list(direct['to'].unique());Nodes = list(set(n1+n2))\n",
    "        if(undirected):\n",
    "            n3 = list(undirect['from'].unique());n4 = list(undirect['to'].unique());Nodes = list(set(n1+n2+n3+n4))\n",
    "    colorDictOut={};colorDictPath={}\n",
    "    if(colored):\n",
    "        colorDictOut={}\n",
    "        for node in Nodes:\n",
    "            path = useDict[node]\n",
    "            color = colorDict[path]\n",
    "            colorDictOut[node]=color\n",
    "            if not path in colorDictPath:\n",
    "                colorDictPath[path]=color\n",
    "    return Nodes,direct,undirect,colorDictOut,colorDictPath,topLs\n",
    "\n",
    "def interPathwayOnly(dfIn,immuneDict,dictIn,immuneNonOnly,nonToIm,pathways=False,graphviz=True,rmvLen=False):\n",
    "    gDF = dfIn.copy();kobeDict=dictIn.copy();keepLst=[];specialLst=['Heat','Cancer Area','Purity']\n",
    "    if(graphviz):\n",
    "        for row in gDF.index:\n",
    "            val2=True;ser = gDF.loc[row];frm = __getNode2(ser['from'],rmvLen=rmvLen);too=__getNode2(ser['to'],rmvLen=rmvLen)\n",
    "            if(pathways):node1Path = frm;node2Path = too\n",
    "            else:\n",
    "                if frm in specialLst or too in specialLst:\n",
    "                    if frm in specialLst:node1Path = frm\n",
    "                    else:\n",
    "                        if frm in kobeDict:node1Path = kobeDict[frm]\n",
    "                        else:val2=False\n",
    "                    if too in specialLst:node2Path = too\n",
    "                    else:\n",
    "                        if too in kobeDict:node1Path = kobeDict[too]\n",
    "                        else:val2=False\n",
    "                else:\n",
    "                    if frm in kobeDict and too in kobeDict:node1Path=kobeDict[frm];node2Path=kobeDict[too]\n",
    "                    else:val2=False\n",
    "            val=True\n",
    "            if(immuneNonOnly and nonToIm):\n",
    "                direct = gDF.loc[row]['direction']\n",
    "                if direct<0.35:val=False\n",
    "            if(val and val2):\n",
    "                if(__immuneNonPaths(node1Path=node1Path,node2Path=node2Path,immuneNonOnly=immuneNonOnly,\n",
    "                                    nonToIm=nonToIm,immuneDict=immuneDict)):keepLst.append(row)\n",
    "        gDF=gDF.loc[keepLst]\n",
    "    else:\n",
    "        for col in gDF.columns:\n",
    "            val=True;colL = col.split()\n",
    "            if(allDir and len(colL)<2):val = False\n",
    "            if len(colL)>2:node1 = colL[0];node2 = colL[2]\n",
    "            else:node1 = colL[0];node2 = colL[1]\n",
    "            if(pathways):node1Path = node1.replace('.','');node2Path = node2.replace('.','')\n",
    "            else:node1Path = kobeDict[node1.replace('.','')];node2Path = kobeDict[node2.replace('.','')]\n",
    "            if(node1Path=='Heat'):val=False\n",
    "            if(val):\n",
    "                if(__immuneNonPaths(node1Path=node1Path,node2Path=node2Path,immuneNonOnly=immuneNonOnly,\n",
    "                                    nonToIm=nonToIm,graphviz=False,immuneDict=immuneDict)):keepLst.append(col)\n",
    "        gDF = gDF[keepLst]\n",
    "    return gDF\n",
    "\n",
    "def __immuneNonPaths(node1Path,node2Path,immuneDict,immuneNonOnly=False,nonToIm=False,graphviz=True):\n",
    "    if(node1Path==node2Path):return False\n",
    "    if(immuneNonOnly):\n",
    "        if nonToIm:\n",
    "            if((node2Path in immuneDict) and (not node1Path in immuneDict)):return True\n",
    "            else:return False\n",
    "        else:\n",
    "            if(node1Path in immuneDict):\n",
    "                if(node2Path in immuneDict):return False\n",
    "                else:return True\n",
    "            else:\n",
    "                if(node2Path in immuneDict):return True\n",
    "                else:return False\n",
    "    else:return True\n",
    "def __changeDrop(dropLst,directed=False,reverse=False,undirected=False):\n",
    "    if not directed and not reverse and not undirected:return dropLst\n",
    "    else:\n",
    "        outLst=[]\n",
    "        for elem in dropLst:\n",
    "            if(undirected):outLst.append(elem.replace(' ',' -- '))\n",
    "            if(directed):\n",
    "                if(reverse):\n",
    "                    pairs = elem.split(' ');pair1 = pairs[0];pair2 = pairs[1];outLst.append(pair2+' -> '+pair1)\n",
    "                else:outLst.append(elem.replace(' ',' -> '))\n",
    "        return outLst \n",
    "\n",
    "def mergeGraphs(directory='/Users/USER/Downloads/',title='Average BNLearn',erase=False):\n",
    "    \"\"\"Merges together all BN plots within a given directory\"\"\"\n",
    "    images = glob.glob(directory+'*graphviz*png*');from PIL import Image;pdfLst=[]\n",
    "    for image in images:\n",
    "        image1 = Image.open(image)\n",
    "        im1 = image1.convert('RGB');imageName = image.split('.')[0];im1.save(imageName+'.pdf');pdfLst.append(imageName+'.pdf')\n",
    "    __mergePDFs(pdfLst,title)\n",
    "    for pdf in pdfLst:os.remove(pdf)\n",
    "    if erase:\n",
    "        for image in images:os.remove(image)\n",
    "    return 1\n",
    "def setupBNLearnGenes(pLst,runVLst=[],title='',panCancer=False,onlyKobeGenes=True,genesIn=[],blackList=False,\n",
    "                      blDict={},blPlaceLst=[],blCutoff=5,blTitle='',tqOn=False,areaTitle='Kobe Genes'):\n",
    "    if onlyKobeGenes:\n",
    "        kobe = getKobeClique();geneLst=[]\n",
    "        for path in kobe:\n",
    "            genes = __runGenes(kobe[path]);geneLst.extend(genes)\n",
    "    else:geneLst = genesIn.copy()\n",
    "    for runVersion in runVLst:\n",
    "        if panCancer or blackList:dfLst=[];dfLstBl=[];cancerNum=1\n",
    "        inputs=pLst\n",
    "        if tqOn:inputs=tq(pLst,desc=str(runVersion))\n",
    "        for place in inputs:\n",
    "            if(runVersion!='PrePure'):\n",
    "                df = pd.read_csv('Purity/TPM/v'+str(runVersion)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "            else:df = pd.read_csv('Purity/TPM/Outliers Fixed/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "            placeLen = len(df.columns);gL = __goodGenes(geneLst,df.index); df = df.loc[gL]\n",
    "            \n",
    "            \n",
    "            if blackList:dfLstBl.append((place,df))\n",
    "            if panCancer :\n",
    "                df = df.T;sampleLen = min(100,placeLen);samples = random.sample(range(0, placeLen), sampleLen)\n",
    "                df = df.iloc[samples].T;df = __pureDf(df,zscore=True);df = __heatDF(df,place,zscore=True)[0];df =df.T\n",
    "                df.insert(len(df.columns),'Cancer Area',float(cancerNum));df.index.name='Genes';df =df.T\n",
    "                dfLst.append((place,df));cancerNum +=1\n",
    "            else:\n",
    "                df = __pureDf(df,zscore=True);df = __heatDF(df,place,zscore=True)[0];df=df.T\n",
    "                if(runVersion!='PrePure'):\n",
    "                    df.to_csv('Run BNLearn/Inputs/'+areaTitle+', '+place+', N = '+str(placeLen)+title+', v'+str(runVersion),\n",
    "                              sep='\\t')\n",
    "                else:\n",
    "                    df.to_csv('Run BNLearn/Inputs/'+areaTitle+', '+place+', N = '+str(placeLen)+title+', '+str(runVersion),\n",
    "                              sep='\\t')\n",
    "        if panCancer:\n",
    "            dfAll = getdfAll(dfLst);dfAll = dfAll.T\n",
    "            if(runVersion!='PrePure'):\n",
    "                title2= 'Run BNLearn/Inputs/'+areaTitle+', Pre-BN Merged'+title+', v'+str(runVersion)\n",
    "                dfAll.to_csv(title2,sep='\\t')\n",
    "            else:\n",
    "                title2= 'Run BNLearn/Inputs/'+areaTitle+', Pre-BN Merged'+title+', '+str(runVersion)\n",
    "                dfAll.to_csv(title2,sep='\\t')\n",
    "        if blackList:\n",
    "            __setupBNLearnBlackList(blDict=blDict,blPlaceLst=blPlaceLst,cutoff=blCutoff,title=blTitle+', v'+str(runVersion),\n",
    "                                    dfLst=dfLstBl)        \n",
    "    return 1\n",
    "\n",
    "def __setupBNLearnBlackList(blDict,dfLst,blPlaceLst,cutoff=5,title=''):\n",
    "    keys = list(blDict.keys());placeBlDict={}\n",
    "    for place, df in tq(dfLst):\n",
    "        blackLstDict={}\n",
    "        if place in blPlaceLst:\n",
    "            for i in range(len(keys)):\n",
    "                pathway1 = keys[i];blLst=[]\n",
    "                for j in range(len(keys)):\n",
    "                    pathway2 = keys[j]\n",
    "                    if not pathway1 == pathway2:\n",
    "                        genes1 = blDict[pathway1];genes1=__goodGenes(genes1,df.index)\n",
    "                        genes2 = blDict[pathway2];genes2=__goodGenes(genes2,df.index);bl=True\n",
    "                        for g1 in genes1:\n",
    "                            for g2 in genes2:\n",
    "                                a=df.loc[g1];b=df.loc[g2];cor=stats.spearmanr(a, b)[0];cor+=stats.pearsonr(a,b)[0];cor/=2\n",
    "                                if cor > 0.3:\n",
    "                                    bl=False;break\n",
    "                        if bl:\n",
    "                            if not (pathway1,pathway2) in blLst:blLst.append((pathway1,pathway2))\n",
    "                blackLstDict[pathway1]=blLst\n",
    "            placeBlDict[place] = blackLstDict\n",
    "    blPaths={}\n",
    "    for place in placeBlDict:\n",
    "        dict2 = placeBlDict[place]\n",
    "        for a in dict2:\n",
    "            for b in dict2[a]:\n",
    "                if b in blPaths:blPaths[b] += 1\n",
    "                else:blPaths[b] = 1\n",
    "    blDf = pd.DataFrame.from_dict(blPaths,orient='index',columns=['Number'])\n",
    "    blDf = blDf[blDf['Number']>cutoff];pairDf = __getPairDf(blDf);pairDf.to_csv('Run BNLearn/BlackList'+title+'.csv')\n",
    "    return 1\n",
    "\n",
    "def __getPairDf(df):\n",
    "    pairDict={}\n",
    "    for pair in df.index:\n",
    "        path1 = pair[0].strip();path2=pair[1].strip()\n",
    "        for gene1 in blDict[path1]:\n",
    "            lst = blDict[path2].copy()\n",
    "            if gene1 in pairDict:pairDict[gene1].extend(lst)\n",
    "            else:pairDict[gene1]=lst\n",
    "        gc.collect()\n",
    "    maxLen=0\n",
    "    for g in pairDict:\n",
    "        if len(pairDict[g])>maxLen:maxLen = len(pairDict[g])\n",
    "    for g in pairDict:\n",
    "        lst = pairDict[g].copy()\n",
    "        for i in range(maxLen-len(pairDict[g])):lst.append('')\n",
    "        pairDict[g] = lst\n",
    "    pairDf = pd.DataFrame.from_dict(pairDict, orient='index')\n",
    "    return pairDf\n",
    "def shiftLst(lst,num):\n",
    "    lst2=[lst[num]];i=0\n",
    "    for elem in lst:\n",
    "        if i != num:lst2.append(elem)\n",
    "        i += 1\n",
    "    return lst2\n",
    "def plotHistograms(pLst,size=(60,20),save=False,show=True):\n",
    "    import math\n",
    "    dfLst=[];fsT = round(size[0]/2)+5;fsL = round(size[0]/2);legSize = round(size[0]/2)\n",
    "    for place in tq(pLst,desc='dfLst'):\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(7)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        df2 = pd.read_csv('Purity/TPM/v'+str(8)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        df = df.loc[gL];df2 = df2.loc[gL];dfLst.append((df,df2,place))\n",
    "    for gene in tq(gL,desc='Plotting Histograms'):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=size);axNum=0;height = 0 \n",
    "        for dfTup in dfLst:\n",
    "            ax = axes[axNum];df = dfTup[0];df2 = dfTup[1]\n",
    "            place = dfTup[2];dfG1 = df.loc[gene];dfG2 = df2.loc[gene]\n",
    "            weights = np.ones_like(dfG1)/float(len(dfG1));ax.hist(dfG1,label='v7',bins=100,weights=weights,alpha=0.5)\n",
    "            ax.hist(dfG2,label='v8',bins=100,weights=weights,alpha=0.5);ax.legend(prop={'size': legSize})\n",
    "            ax.set_title(gene+', '+place,fontsize=fsT);ax.set_xlabel('ZScore of Log2 TPM Gene Expression',fontsize=fsL)\n",
    "            ax.set_ylabel('Percent of data',fontsize=fsL);axNum += 1;bot, top = ax.get_ylim()\n",
    "            if(top > height):height = top\n",
    "        for ax in axes:ax.set_ylim(0,height)\n",
    "        if(save):\n",
    "            plt.savefig('Saved Images/'+gene+', Histogram.pdf',bbox_inches = \"tight\");plt.close()\n",
    "        if(show):plt.show()\n",
    "    return 1\n",
    "\n",
    "def BNLearnColColors(df,reverse=False,undirected=False,directed=False):\n",
    "    colors = ['green','yellow','purple','black','orange','grey','white',\n",
    "              'brown','fuchsia','pink','gold','seagreen','salmon','olive','teal','crimson','cyan']\n",
    "    kobe = getKobeClique(True);lutCol = dict(zip(set(kobe.values()), colors));col1=[];col2=[];sep=' '\n",
    "    if(undirected):sep= ' -- '\n",
    "    else:\n",
    "        if(directed or reverse):sep=' -> '\n",
    "    for row in df:\n",
    "        split = row.split(sep);frst = split[0].replace('.','');snd = split[1].replace('.','')\n",
    "        path1 = kobe[frst];path2 = kobe[snd];col1.append(lutCol[path1]);col2.append(lutCol[path2])\n",
    "    colColors=[col1,col2]\n",
    "    return colColors, lutCol\n",
    "\n",
    "def orderShiftLst(files,orderLst=[]):\n",
    "    for order in orderLst:\n",
    "        n=0\n",
    "        for file in files:\n",
    "            if order in file:take=n\n",
    "            n += 1\n",
    "        files = shiftLst(files,take)\n",
    "    return files\n",
    "\n",
    "def globExclude(globDir,exclude):\n",
    "    files = glob.glob(globDir);files2=[]\n",
    "    for file in files:\n",
    "        if not exclude in file:files2.append(file)\n",
    "    return files2\n",
    "\n",
    "def bnLearnRowColors(ls,colors):\n",
    "    places=[]\n",
    "    for elem in ls:places.append(elem.split(',')[0])\n",
    "    places = list(set(places));n=0\n",
    "    if(len(places)>len(colors)):sys.exit('ERROR, Not Enough Colors for Rows')\n",
    "    place_colors={}\n",
    "    for place in places:color = colors[n];place_colors[place]=color;n+=1\n",
    "    row_colors={}\n",
    "    for elem in ls:place = elem.split(',')[0];color = place_colors[place];row_colors[elem] = color\n",
    "    return row_colors, place_colors\n",
    "\n",
    "def mergeBNGraphsAgnos(thresLst,orderLst,dirThres=0.65,merged=True,undirected=True,excludePre=True,onlyBGE=True,erase=True,\n",
    "                       mergedAll=True,onlyBDE=False,interPath=True,immuneNonOnly=True,colored=True,nonToIm=False):\n",
    "    for thres in tq(thresLst,desc='Overall'):\n",
    "        pl = makeBNGraphs(globDir='Run BNLearn/Outputs/*Kobe Genes*',pathways=False,thres=thres,dirThres=dirThres,\n",
    "                          merged=merged,undirected=undirected,excludePre=excludePre,onlyBGE=onlyBGE,erase=erase,\n",
    "                          colored=colored,nonToIm=nonToIm,\n",
    "                          agnostic=True,mergedAll=mergedAll,onlyBDE=onlyBDE,interPath=interPath,immuneNonOnly=immuneNonOnly)\n",
    "        files = glob.glob('Graphs/*');files = orderShiftLst(files,orderLst);nameL = files[3].split('\\\\')[1].split(',')\n",
    "        if(len(nameL)>5):name = \",\".join(['Graphviz Graphs',nameL[2],nameL[3],nameL[4],nameL[5]]).strip()\n",
    "        else:name = \",\".join(['Graphviz Graphs',nameL[1],nameL[2],nameL[4]]).strip()\n",
    "        name = name.replace('.pdf','');name = 'Saved PDFs/Agnostic/'+name;__mergePDFs(files,name,erase=True)\n",
    "    return 1\n",
    "\n",
    "def __corrValColor(corVal,minn=-1,sepLen=12,rg=False):\n",
    "    if not rg:\n",
    "        sep = 2/sepLen;val=True\n",
    "        if(corVal==0):val=False\n",
    "        if(corVal>0 and corVal-sep<=0):val=False\n",
    "        if(corVal<0 and corVal+sep>=0):val=False\n",
    "        corVal2 = corVal;color = 0\n",
    "        while(corVal2-minn >= sep):\n",
    "            color +=1;corVal2 += minn*sep\n",
    "        if val:\n",
    "            if corVal < 0:icolor += 1\n",
    "            else:color -= 1\n",
    "    else:\n",
    "        if abs(corVal) <= 0.2:color='black'\n",
    "        else:\n",
    "            if corVal > 0:color = 'green'\n",
    "            else:color='red'\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __BNGraphsAgnosMerged(placeLs,graphLst,dropImmune,dropPure,agnostic,dirThres,nonToIm,pathways,thres,thresFloor,\n",
    "                          interPath,below,undirected,colored,title,onlyBDE,onlyBGE,immuneNonOnly):\n",
    "    gLst=[]\n",
    "    for place in placeLs:\n",
    "        graphLst2 = [p for p in graphLst if place in p]\n",
    "        g = __getMergedG(graphLst2,dropImmune=False,dropPure=False,agnostic=agnostic,dirThres=0.65,nonToIm=nonToIm,\n",
    "                         pathways=pathways,thres=thres,thresFloor=0.3,interPath=interPath,\n",
    "                         immuneNonOnly=immuneNonOnly,below=False)[0]\n",
    "        if(len(g.index)>0):\n",
    "            gLst.append(g)\n",
    "    maxId = 0\n",
    "    for g in gLst:\n",
    "        ls = max(list(g.index))\n",
    "        if ls > maxId:\n",
    "            maxId = ls\n",
    "    maxId += 1\n",
    "    frmLst=[]\n",
    "    toLst=[]\n",
    "    dirLst=[]\n",
    "    canLst=[]\n",
    "    iLst=[]\n",
    "    for i in range(maxId):\n",
    "        canNum=0\n",
    "        frst=True\n",
    "        for g in gLst:\n",
    "            if i in g.index:\n",
    "                canNum +=1\n",
    "                if(frst):\n",
    "                    frmLst.append(g.loc[i]['from'])\n",
    "                    toLst.append(g.loc[i]['to'])\n",
    "                    dirLst.append(g.loc[i]['Directed'])\n",
    "                    frst=False\n",
    "        if not frst:\n",
    "            canNum = str(canNum)+'/'+str(len(gLst));canLst.append(canNum);iLst.append(i)\n",
    "    df = pd.DataFrame([frmLst,toLst,canLst,dirLst]);df.index = ['from','to','Number of Connections','Directed']\n",
    "    df =df.T;df.index = iLst;outName = 'Post-BN Merged Average, Gene Agnostic'\n",
    "    if(below):\n",
    "        outName += ', Confidence Range '+str(thresFloor)+' to '+str(thres)\n",
    "    else:\n",
    "        outName=outName+', Confidence Range '+str(thres)+' to '+str(1)\n",
    "    outName += ', Direction '+str(dirThres)\n",
    "    if onlyBDE:outName += ', Only BDE'\n",
    "    if onlyBGE:outName += ', Only BGE'\n",
    "    if interPath:\n",
    "        outName += ', Only InterPathway'\n",
    "        if immuneNonOnly:addOn = ' Immune-Non Edges'\n",
    "        if nonToIm:addOn = ' Non-Immune Edges'\n",
    "        outName += addOn\n",
    "    outName += title\n",
    "    ____helpMakeGraphsCreateAgnos(df,outName=outName,undirected=undirected,colored=colored)\n",
    "    return 1\n",
    "def __hotColdDfLstHelp(place,vNum,extra):\n",
    "    fileName = 'Genes/TPM/TCGA_'+place+'_tpm.fullIDs.remapped.tsv'\n",
    "    df = pd.read_csv(fileName,index_col=0,sep='\\t');__renameTPM(df);Hot,Cold = __getHotCold(df,extra=extra)\n",
    "    if vNum != 'PrePure':fileName = 'Purity/TPM/v'+str(vNum)+'/TCGA_'+place+'_tpm.tsv'\n",
    "    df = pd.read_csv(fileName,index_col=0,sep='\\t');hotCols = __goodGenes(Hot.columns,df.columns);Hot = df[hotCols]\n",
    "    coldCols = __goodGenes(Cold.columns,df.columns);Cold = df[coldCols]\n",
    "    return (place,hotCols,coldCols,df)\n",
    "def getTsvFromMsig():\n",
    "    for file in glob.glob('MsigDB/*.gmt'):\n",
    "        f = open(file)\n",
    "        outDict={}\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','');ls = line.split('\\t');name = ls[0];lst = ls[2:];outDict[name] = [lst]\n",
    "        df = pd.DataFrame.from_dict(outDict);df.index=['Genes'];df.to_csv(file+'.tsv',sep='\\t')\n",
    "    return 1\n",
    "def getFullDict(outputLst=True,useLst=[]):\n",
    "    fullDict=[]\n",
    "    for file in glob.glob('MsigDB/*.gmt'):\n",
    "        outDict={}\n",
    "        fName=file.split('\\\\')[1].replace('.v7.2.symbols.gmt','')\n",
    "        f = open(file)\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            ls = line.split('\\t')\n",
    "            name = ls[0]\n",
    "            lst = ls[2:]\n",
    "            outDict[name] = lst\n",
    "        fullDict.append((fName,outDict))\n",
    "    if outputLst:\n",
    "        return fullDict\n",
    "    else:\n",
    "        outDict={}\n",
    "        for name,dic in fullDict:\n",
    "            if name in useLst:\n",
    "                outDict.update(dic)\n",
    "        return outDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getBNnodes(pathways,place,thres):\n",
    "    if pathways:\n",
    "        globDir='Run BNLearn/Outputs/*'\n",
    "    else:\n",
    "        globDir='Run BNLearn/Outputs/*Kobe Genes*'\n",
    "    graphLst = __BNGraphsTinyBegin(globDir=globDir,pathways=pathways,onlyBGE=True,onlyBDE=False)\n",
    "    graphLst = __removeLst(graphLst,'PrePure')\n",
    "    graphLst = [p for p in graphLst if place in p]\n",
    "    g = __getMergedG(graphLst,dropImmune=False,dropPure=False,agnostic=False,dirThres=0.65,nonToIm=False,\n",
    "                     pathways=pathways,thres=thres,thresFloor=0,interPath=False,immuneNonOnly=False)[0]\n",
    "    Nodes = __setupHelpMakeGraphsCreate(g=g,undirected=True,dirThres=0.65,colored=False,onlyConnected=True,colorsLst=[],\n",
    "                                        colorDictIn={},colorImmuneDict={},blackList=False,blackListFile='')[0]\n",
    "    return Nodes\n",
    "def makeBNScatterPlots(placeL,date,pathways=True,spotCheck=False,thres=0.3):\n",
    "    kobeDict=getKobeClique(True)\n",
    "    if pathways:\n",
    "        globDir='BN Learn/Outputs/*Kobe Genes*'\n",
    "    else:\n",
    "        globDir='BN Learn/Outputs/*'\n",
    "    imLst = ['T-Eff','IFNg','Antigen Process']\n",
    "    for place in tq(placeL,desc='Plotting'):\n",
    "        nodes = __getBNnodes(pathways,place,thres=thres)\n",
    "        if pathways:\n",
    "            if not os.path.exists('Saved PDFs/'+place+', Correlation Scatter Plots, '+date):\n",
    "                os.mkdir('Saved PDFs/'+place+', Correlation Scatter Plots, '+date)\n",
    "            lst = glob.glob('Run BNLearn/Inputs/*'+place+\"*\")\n",
    "            lst = __removeLstFunc(lst,'Kobe Genes')\n",
    "            typLst=[]\n",
    "            for i in lst:\n",
    "                typ = i.split(',')[-2].strip()\n",
    "                typLst.append(typ)\n",
    "            typLst=list(set(typLst))\n",
    "        else:\n",
    "            lst = glob.glob('Run BNLearn/Inputs/*Kobe Genes*'+place+\"*\")\n",
    "            typLst = ['Kobe Genes']\n",
    "        for typ in typLst:\n",
    "            lst2 = [p for p in lst if typ in p]\n",
    "            dfLst=[]\n",
    "            cols=[]\n",
    "            frst=True\n",
    "            for l in lst2:\n",
    "                lname = l.split(',')[-1].strip()\n",
    "                df = pd.read_csv(l,sep='\\t',index_col=0)\n",
    "                if frst:\n",
    "                    cols = df.columns\n",
    "                    frst=False\n",
    "                else:\n",
    "                    cols = __goodGenes(cols,df.columns)\n",
    "                dfLst.append((lname,df))\n",
    "            saveLst=[]\n",
    "            num =len(cols)\n",
    "            for i in tq(range(num),desc=''):\n",
    "                for j in range(i,num):\n",
    "                    col1 = cols[i]\n",
    "                    col2 = cols[j]\n",
    "                    coL1 = col1.replace(' Scores','').replace('A-A','AA')\n",
    "                    coL2 = col2.replace(' Scores','').replace('A-A','AA')\n",
    "                    if col2 != col1 and coL1 in nodes and coL2 in nodes:\n",
    "                        frstDF=True\n",
    "                        for dfTup in dfLst:\n",
    "                            lname = dfTup[0]\n",
    "                            df = dfTup[1]\n",
    "                            spear = df.corr(method='spearman').loc[col1][col2]\n",
    "                            pear = df.corr(method='pearson').loc[col1][col2]\n",
    "                            if lname != 'PrePure':\n",
    "                                if frstDF:\n",
    "                                    corr = (spear+pear)/2\n",
    "                                    n=1\n",
    "                                    frstDF=False\n",
    "                                else:\n",
    "                                    corr += ((spear+pear)/2)\n",
    "                                    n+=1\n",
    "                            plt.scatter(df[col1],df[col2],label=lname)\n",
    "                        corr /= n\n",
    "                        corr = round(corr,2)\n",
    "                        if not pathways:\n",
    "                            path1 = kobeDict[coL1]\n",
    "                            path2 = kobeDict[coL2]\n",
    "                        val=True\n",
    "                        if spotCheck:\n",
    "                            val = __BNSpotCheck(path1=path1,path2=path2,corr=corr,\n",
    "                                                kobeDict=kobeDict)\n",
    "                        if val:\n",
    "                            plt.xlabel(col1,fontsize=5)\n",
    "                            plt.ylabel(col2,fontsize=5)\n",
    "                            if pathways:\n",
    "                                title = 'Database is '+typ+', Correlation between '+col1+' and '+col2+', '\n",
    "                                title += place+', Correlation is '+str(corr)\n",
    "                            else:\n",
    "                                title = 'Database is '+typ+', Correlation between '+col1+'('+path1.replace('/','-')+') and '\n",
    "                                title += col2+'('+path2.replace('/','-')+'), '+place+', Correlation is '+str(corr)\n",
    "                            plt.title(title,fontsize=6)\n",
    "                            plt.legend(fontsize=6)\n",
    "                            plt.savefig(directory+title+'.pdf')\n",
    "                            saveLst.append(directory+title+'.pdf')\n",
    "                        plt.close()\n",
    "            if pathways:\n",
    "                __mergePDFs(saveLst,\n",
    "                            'Saved PDFs/'+place+', Correlation Scatter Plots, '+date+'/Database is '+\n",
    "                            typ+', Correlation Scatter Plots',erase=True)\n",
    "            else:\n",
    "                __mergePDFs(saveLst,\n",
    "                            'Saved PDFs/'+place+', Database is '+\n",
    "                            typ+', Correlation Scatter Plots',erase=True)\n",
    "    return 1\n",
    "\n",
    "def __BNSpotCheck(path1,path2,corr,kobeDict):\n",
    "    imLst = ['T-Eff','IFNg','Antigen Process']\n",
    "    val = True\n",
    "    if path1 in imLst and path2 in imLst and (corr>-0.2):\n",
    "        val=False\n",
    "    else:\n",
    "        if path1 not in imLst and path2 not in imLst and (corr>-0.2):\n",
    "            val=False\n",
    "    if path1 in imLst and path2 not in imLst and (corr<0.2):\n",
    "        val=False\n",
    "    if path1 not in imLst and path2 in imLst and (corr<0.2):\n",
    "        val=False\n",
    "    if path1=='Heat' or path2=='Heat' or path1=='Purity' or path2=='Purity':\n",
    "        val=False\n",
    "    return val\n",
    "\n",
    "def countNotNaNs(df,rev=False):\n",
    "    out=pd.Series()\n",
    "    for row in df.index:\n",
    "        ser = df.loc[row]\n",
    "        num = np.count_nonzero(np.isnan(ser))\n",
    "        if rev:\n",
    "            num = len(ser) - num\n",
    "        out[row]=num\n",
    "    return out\n",
    "\n",
    "def __getBothSupers(superDfNesIn,superDfFdrIn):\n",
    "    superDfNes=superDfNesIn.copy();superDfFdr=superDfFdrIn.copy()\n",
    "    superDfNes.index.name='Pathways';superDfFdr.index.name='Pathways'\n",
    "    both = superDfNes.merge(superDfFdr,how='outer',on='Pathways')\n",
    "    colLst=[]\n",
    "    for col in both.columns:\n",
    "        if not(col=='MSigDB Category_x' or col=='MSigDB Category_y'):\n",
    "            colN = col.replace('_x','_NES').replace('_y','_FDR')\n",
    "        else:\n",
    "            colN = col.replace('_x','')\n",
    "        colLst.append(colN)\n",
    "    both.columns = colLst\n",
    "    both = both.drop(columns=['MSigDB Category_y'])\n",
    "\n",
    "    sLst=[]\n",
    "    for col in both.columns:\n",
    "        if not col=='MSigDB Category':\n",
    "            colN = col.replace('_NES','').replace('_FDR','')\n",
    "            sLst.append(colN)\n",
    "    sLst2=[]\n",
    "    for elem in sLst:\n",
    "        if not elem in sLst2:\n",
    "            sLst2.append(elem)\n",
    "    sLst2.reverse()\n",
    "    finLst=[]\n",
    "    for elem in sLst2:\n",
    "        finLst.append(elem+'_FDR')\n",
    "        finLst.append(elem+'_NES')\n",
    "    finLst.append('MSigDB Category')\n",
    "    newCols = orderShiftLst(both.columns,finLst)\n",
    "    both = both[newCols]\n",
    "    return both\n",
    "\n",
    "def __getUpinCold(superDfNes,superDfFdr,coldNum,fdrNum,fdrVal):\n",
    "    coldUps = superDfNes[superDfNes<0];numColds = countNotNaNs(coldUps,rev=True);numColds2 = numColds[numColds >= coldNum]\n",
    "    superDfNes2 = superDfNes.loc[numColds2.index];superDfFdr2 = superDfFdr.loc[numColds2.index]\n",
    "    keepLst=[]\n",
    "    for row in superDfNes2.index:\n",
    "        count = 0\n",
    "        for col in superDfNes2.columns:\n",
    "            ser = superDfNes2.loc[row][col]\n",
    "            if ser < 0:\n",
    "                serF = superDfFdr2.loc[row][col]\n",
    "                if serF < fdrVal:\n",
    "                    count +=1\n",
    "                    if count >= fdrNum:\n",
    "                        break\n",
    "        if count >=fdrNum:\n",
    "            keepLst.append(row)\n",
    "    superDfNes2 = superDfNes2.loc[keepLst]\n",
    "    superDfFdr2 = superDfFdr2.loc[keepLst]\n",
    "    return superDfNes2,superDfFdr2\n",
    "\n",
    "def getGSEAxCellFile(ver,dateIn,placeLst,coldNum,dbLstIn='All',fdrVal=0.25,dbName='All',direct='',removeBad=False):\n",
    "    date = dateIn+', v'+str(ver)\n",
    "    if dbLstIn == 'All':\n",
    "        dbLst=[]\n",
    "        for gsea in glob.glob('GSEA Output/'+date+'/*'):\n",
    "            dbLst.append(gsea.split('\\\\')[-1])\n",
    "    else:\n",
    "        dbLst = dbLstIn.copy()\n",
    "    superDfNes,superDfFdr = __superDfGSEA(date,dbLst=dbLst,placeLst=placeLst,\n",
    "                                          desktop=False,skipImmune=False,\n",
    "                                          preRank=True,coldNum=coldNum,fdrVal=fdrVal)\n",
    "    superDfNes,superDfFdr,pathLst,catLst = __getPathLst(superDfNes,superDfFdr,removeBad=False)\n",
    "    superDfNes.insert(0,'MSigDB Category',catLst)\n",
    "    superDfFdr.insert(0,'MSigDB Category',catLst)\n",
    "    superDfNes.index.name='Pathways';superDfFdr.index.name='Pathways'\n",
    "    if dbName=='c2.all':\n",
    "        dbName = dbName+' '+msigNameDict[dbName]\n",
    "        df1,df2 = __C2SplitGSEA(superDfNes,superDfFdr,useLst=True,lst=catLst)\n",
    "        superDfNes1,superDfFdr1,catLst1 = df1\n",
    "        superDfNes2,superDfFdr2,catLst2 = df2\n",
    "        \n",
    "        directory = dbName+' Canonical'+direct\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        directory+='/'\n",
    "        superDfNes1.to_excel(directory+dbName+' Canonical, GSEA Agnostic v'+str(ver)+', At least '+str(coldNum)+\n",
    "                             ' Up in Cold'+', Results, NES.xlsx')\n",
    "        superDfFdr1.to_excel(directory+dbName+' Canonical, GSEA Agnostic v'+str(ver)+', At least '+str(coldNum)+\n",
    "                             ' Up in Cold'+', Results, FDR.xlsx')\n",
    "        both = __getBothSupers(superDfNes1,superDfFdr1)\n",
    "        both.to_excel(directory+dbName+' Canonical, GSEA Agnostic v'+str(ver)+', At least '+str(coldNum)+\n",
    "                      ' Up in Cold, Results, Both NES and FDR.xlsx')\n",
    "        \n",
    "        directory = dbName+' Chemical and Genetic Perturbations'+direct\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        directory+='/'\n",
    "        superDfNes2.to_excel(directory+dbName+' Chemical and Genetic Perturbations, GSEA Agnostic v'+str(ver)+\n",
    "                             ', At least '+str(coldNum)+' Up in Cold'+', Results, NES.xlsx')\n",
    "        superDfFdr2.to_excel(directory+dbName+' Chemical and Genetic Perturbations, GSEA Agnostic v'+str(ver)+\n",
    "                             ', At least '+str(coldNum)+' Up in Cold'+', Results, FDR.xlsx')\n",
    "        both = __getBothSupers(superDfNes2,superDfFdr2)\n",
    "        both.to_excel(directory+dbName+' Chemical and Genetic Perturbations, GSEA Agnostic v'+str(ver)+\n",
    "                      ', At least '+str(coldNum)+' Up in Cold, Results, Both NES and FDR.xlsx')\n",
    "        \n",
    "    else:\n",
    "        if dbName=='c5.all':\n",
    "            df1,df4 = __C2SplitGSEA(superDfNes,superDfFdr,useLst=True,lst=catLst,keep=['GO'])\n",
    "            superDfNes1,superDfFdr1,catLst1 = df1\n",
    "            dbName = dbName+' '+msigNameDict[dbName]\n",
    "            directory = dbName+' GO Biological Process'+direct\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            directory+='/'\n",
    "            superDfNes1.to_excel(directory+dbName+' GO Biological Process, GSEA Agnostic v'+str(ver)+\n",
    "                                 ', At least '+str(coldNum)+\n",
    "                                 ' Up in Cold'+', Results, NES.xlsx')\n",
    "            superDfFdr1.to_excel(directory+dbName+' GO Biological Process, GSEA Agnostic v'+str(ver)+\n",
    "                                 ', At least '+str(coldNum)+\n",
    "                                 ' Up in Cold'+', Results, FDR.xlsx')\n",
    "            both = __getBothSupers(superDfNes1,superDfFdr1)\n",
    "            both.to_excel(directory+dbName+' GO Biological Process, GSEA Agnostic v'+str(ver)+', At least '+str(coldNum)+\n",
    "                          ' Up in Cold, Results, Both NES and FDR.xlsx')\n",
    "        else:\n",
    "            dbName = dbName+' '+msigNameDict[dbName]\n",
    "            directory = dbName\n",
    "            directory = dbName+direct\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            directory+='/'\n",
    "\n",
    "            superDfNes.to_excel(directory+dbName+', GSEA Agnostic v'+str(ver)+', At least '+str(coldNum)+' Up in Cold'+\n",
    "                                ', Results, NES.xlsx')\n",
    "            superDfFdr.to_excel(directory+dbName+', GSEA Agnostic v'+str(ver)+', At least '+str(coldNum)+' Up in Cold'+\n",
    "                                ', Results, FDR.xlsx')\n",
    "            both = __getBothSupers(superDfNes,superDfFdr)\n",
    "            both.to_excel(directory+dbName+', GSEA Agnostic v'+str(ver)+', At least '+str(coldNum)+\n",
    "                          ' Up in Cold, Results, Both NES and FDR.xlsx')\n",
    "    return 1\n",
    "\n",
    "def getMSigCategories(v,coldNum,placeLst,fdrVal=0.1,containsColdCluster=(False,False,0),\n",
    "                      desktop=False,skipImmune=False,preRank=True):\n",
    "    date='2020-11-13, v'+str(v)\n",
    "    dbLst=[]\n",
    "    for gsea in glob.glob('GSEA Output/'+date+'/*'):\n",
    "        dbLst.append(gsea.split('\\\\')[-1])\n",
    "\n",
    "    superDfNes,superDfFdr = __superDfGSEA(date,dbLst=dbLst,placeLst=placeLst,\n",
    "                                          desktop=desktop,skipImmune=skipImmune,\n",
    "                                          preRank=preRank,coldNum=coldNum,fdrVal=fdrVal,\n",
    "                                          containsColdCluster=containsColdCluster)\n",
    "    fullDict = getFullDict()\n",
    "    fullLst=[]\n",
    "    for name,dic in fullDict:\n",
    "        for path in dic:\n",
    "            fullLst.extend(dic[path])\n",
    "    fullLst=list(set(fullLst))\n",
    "    nDict={}\n",
    "    for name, dic in fullDict:\n",
    "        lst2=[]\n",
    "        for row in superDfNes.index:\n",
    "            group = row.split('_')[0].replace('MSigDB','')\n",
    "            if group == name:\n",
    "                lst2.append(row)\n",
    "        df2 = superDfNes.loc[lst2]\n",
    "        df2,df3,pathLst,catLst = __getPathLst(df2,df2,removeBad=False)\n",
    "        pathways = df2.index\n",
    "        lst=[]\n",
    "        for path in dic:\n",
    "            if path in pathways:\n",
    "                lst.extend(dic[path])\n",
    "        lst = list(set(lst))\n",
    "        for i in range(len(fullLst)-len(lst)):\n",
    "            lst.append('')\n",
    "        nDict[name]=lst\n",
    "    df = pd.DataFrame.from_dict(nDict)\n",
    "    df.index = fullLst\n",
    "    title = 'Saved Images/V'+str(v)+', fdr '+str(fdrVal)+' Up in '+str(coldNum)\n",
    "    title+= ' Cancers'+title+', GSEA Agnostic, Msig Gene Lists.tsv'\n",
    "    if containsColdCluster[0]:\n",
    "        title = 'Saved Images/V'+str(v)+', fdr '+str(fdrVal)+', Up in at least '\n",
    "        title += str(containsColdCluster[2])\n",
    "        if containsColdCluster[1]:\n",
    "            title += ' Other-Cluster Cancer Areas'\n",
    "        else:\n",
    "            title += ' Cold-Cluster Cancer Areas'\n",
    "        title += ', GSEA Agnostic, Msig Gene Lists.tsv'\n",
    "    df.to_csv(title,sep='\\t')\n",
    "    gc.collect()\n",
    "    return 1\n",
    "def all0s(ser):\n",
    "    out=True\n",
    "    for elem in ser:\n",
    "        elem = float(elem)\n",
    "        if elem != 0.0:\n",
    "            out=False\n",
    "            break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterTTest(ver,pvalCutoff):\n",
    "    superDfNes = pd.read_csv('SuperDfNes_c2_c5_hall_v'+str(ver)+'.tsv',sep='\\t',index_col=0)\n",
    "    p4=['Adrenocortical','Breast HR+','K_Lung adenocarcinoma','K_Lung squamous','Thyroid','K_Skin'];p5=[]\n",
    "    for place in superDfNes.columns:\n",
    "        if not place in p4:\n",
    "            p5.append(place)\n",
    "    p6 = p4+p5\n",
    "    coldClus=superDfNes[p4]\n",
    "    othrClus=superDfNes[p5]\n",
    "    bothClus=superDfNes[p6]\n",
    "\n",
    "    dfIn = coldClus\n",
    "    outDf = __helpClusterTTest(dfIn,pvalCutoff)\n",
    "    outDf.to_excel('C1 coldCluster cancers, 1 sample ttest up in cold, v'+str(ver)+', pval '+str(pvalCutoff)+'.xlsx')\n",
    "\n",
    "    dfIn = othrClus\n",
    "    outDf = __helpClusterTTest(dfIn,pvalCutoff)\n",
    "    outDf.to_excel('C2 otherCluster cancers, 1 sample ttest up in cold, v'+str(ver)+', pval '+str(pvalCutoff)+'.xlsx')\n",
    "\n",
    "    dfIn = bothClus\n",
    "    outDf = __helpClusterTTest(dfIn,pvalCutoff)\n",
    "    outDf.to_excel('C Union bothCluster cancers, 1 sample ttest up in cold, v'+str(ver)+', pval '+str(pvalCutoff)+'.xlsx')\n",
    "    return 1\n",
    "\n",
    "def __helpClusterTTest(dfIn,pvalCutoff):\n",
    "    df=dfIn.copy()\n",
    "    keepLst=[]\n",
    "    for path in df.index:\n",
    "        ser = df.loc[path]\n",
    "        if not all0s(ser):\n",
    "            keepLst.append(path)\n",
    "    df = df.loc[keepLst]\n",
    "    outDict={}\n",
    "    for path in df.index:\n",
    "        ser = df.loc[path]\n",
    "        stat = stats.ttest_1samp(ser,0)\n",
    "        outDict[path]=stat\n",
    "    dfOut = pd.DataFrame.from_dict(outDict)\n",
    "    dfOut.index = ['TStat','Pval']\n",
    "    dfOut=dfOut.T\n",
    "    dfOut=dfOut[dfOut['TStat'] < 0]\n",
    "    dfOut=dfOut[dfOut['Pval'] < pvalCutoff]\n",
    "    return dfOut\n",
    "def __helpCondensePaths(inDict,pathLst,path1,cutoff,condenseLst,inplace=True,doneLst=[]):\n",
    "    path1Genes = inDict[path1]\n",
    "    if inplace:\n",
    "        condenseLst2 = condenseLst\n",
    "    else:\n",
    "        condenseLst2 = condenseLst.copy()\n",
    "    for j in range(len(pathLst)):\n",
    "        path2 = pathLst[j]\n",
    "        if path2 == path1:\n",
    "            condenseLst2.append(path2)\n",
    "        else:\n",
    "            if(not path2 in doneLst):\n",
    "                path2Genes = inDict[path2]\n",
    "                if percentInLst(path1Genes,path2Genes) >= cutoff or percentInLst(path2Genes,path1Genes) >= cutoff:\n",
    "                    condenseLst2.append(path2)\n",
    "    return condenseLst2\n",
    "def maxLenDict(dic):\n",
    "    maxLen=0\n",
    "    for i in dic:\n",
    "        num = len(dic[i])\n",
    "        if num > maxLen:\n",
    "            maxLen = num\n",
    "    return maxLen\n",
    "def percentInLst(l1,l2):\n",
    "    n = len(list(set(l1).intersection(l2)))\n",
    "    percent = n/len(l1)\n",
    "    return percent\n",
    "\n",
    "def __testCondense(inDict,cutoffLst,testPath,fullDict,doneLst=[]):\n",
    "    testDict={}\n",
    "    for cutoff in cutoffLst:\n",
    "        outDict={}\n",
    "        pathLst = list(inDict.keys())\n",
    "        if testPath:\n",
    "            path1 = testPath\n",
    "        condenseLst=[]\n",
    "        __helpCondensePaths(inDict=fullDict,pathLst=pathLst,path1=path1,cutoff=cutoff,\n",
    "                            condenseLst=condenseLst,doneLst=doneLst)\n",
    "        if len(condenseLst)>1:\n",
    "            outDict[path1] = condenseLst\n",
    "        if testPath in outDict.keys():\n",
    "            testLst = outDict[testPath]\n",
    "            testDict['Overlap Percentage '+str(cutoff)]=testLst\n",
    "        else:\n",
    "            testDict['Overlap Percentage '+str(cutoff)] = [path1]\n",
    "    return testDict\n",
    "def __helpTestCondense(testDict):\n",
    "    maxLen = maxLenDict(testDict)\n",
    "    testDict2={}\n",
    "    for i in testDict:\n",
    "        lst = testDict[i].copy()\n",
    "        length = len(lst)\n",
    "        for j in range(maxLen-len(lst)):\n",
    "            lst.append('')\n",
    "        testDict2[i+', # of Pathways is '+str(length)]=lst\n",
    "    df = pd.DataFrame.from_dict(testDict2)\n",
    "    return df\n",
    "def getColNum(col):\n",
    "    splt = col.split()\n",
    "    num=0\n",
    "    for i in splt:\n",
    "        i=i.replace(',','')\n",
    "        try:\n",
    "            num=float(i)\n",
    "            break\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return num\n",
    "def condensePathways(cutoffLst,useLst,testPath,useName):\n",
    "    fullDict = getFullDict(outputLst=False,useLst=useLst)\n",
    "    inDict = fullDict.copy()\n",
    "    testPathName = testPath\n",
    "    testDict = __testCondense(inDict=inDict,cutoffLst=cutoffLst,testPath=testPath)\n",
    "    df = __helpTestCondense(testDict)\n",
    "    name = testPathName+', '+useName+', Condensing Pathways Test, ' \n",
    "    name+=' condensed group at different overlap percentages.xlsx'\n",
    "    df.to_excel(name)\n",
    "    return 1\n",
    "metabolicLst = ('Metabloic',['METABOLISM','METABOLIC','CATABOLISM','CATABOLIC','GLUCOSE','GLUCONEOGENESIS','GLYCOLYSIS'])\n",
    "lipidLst = ('Lipid',['LIPID','FATTY_ACID','CHOLESTEROL'])\n",
    "prolifLst = ('Prolifiration',['ELONGATION','INITIATION','TRANSLATION','TRANSCRIPTION'])\n",
    "mitochanLst = ('Mitochandrial',['ELECTRON_TRANSPORT','MITOCH'])\n",
    "testLstLists = [metabolicLst,lipidLst,prolifLst,mitochanLst]\n",
    "\n",
    "def plotUpinClusterClumps(dateIn,coldNum,placeLst,metric='cosine',save=False,numParts=30,reverseOrder=False,noParts=False,\n",
    "                          fixPos=False,Position={},fontSize=12,rot=45,figSize=(60,40),containsColdCluster=(True,False,4),\n",
    "                          cutoff=0.2,plot=False,excel=False,rowColors=None,replace=False):\n",
    "    ver = dateIn.split('v')[1]\n",
    "    gc.collect()\n",
    "    if containsColdCluster[1]:\n",
    "        pathName = 'Up in at least '+str(coldNum)+' Other-Cluster Cancer Areas, V'+ver\n",
    "    else:\n",
    "        pathName = 'Up in at least '+str(coldNum)+' Cold-Cluster Cancer Areas, V'+ver\n",
    "    lstDict={}\n",
    "    for file in glob.glob('Lists/GSEA Pathways/*'):\n",
    "        lst = readLst(file)\n",
    "        splt = file.split(',')\n",
    "        fName =','.join([splt[1],splt[2]]).replace(' U','U')\n",
    "        lstDict[fName]=lst\n",
    "    pathways = lstDict[pathName]\n",
    "    plotClumps(pathways=pathways,dateIn=dateIn,coldNum=coldNum,metric=metric,save=save,numParts=numParts,\n",
    "               reverseOrder=reverseOrder,noParts=noParts,fixPos=fixPos,placeLst=placeLst,Position=Position,fontSize=fontSize,\n",
    "               rot=rot,figSize=figSize,containsColdCluster=containsColdCluster,cutoff=cutoff,rowColors=rowColors,\n",
    "               plot=plot,excel=excel,pathName=pathName,replace=replace)\n",
    "    return 1\n",
    "def plotClumps(pathways,dateIn,coldNum,placeLst,metric='cosine',save=False,numParts=30,reverseOrder=False,noParts=False,\n",
    "               fixPos=False,colors=[],cGroups=(False,[]),replace=False,testLstLists=testLstLists,\n",
    "               Position={},fontSize=12,rot=45,figSize=(60,40),containsColdCluster=(True,False,4),cutoff=0.2,\n",
    "               plot=False,excel=False,pathName='',geneSpecific=False,excelGeneSpecific=False):\n",
    "    useLst = ['c2.cp','c5.go.bp','h.all']\n",
    "    fullDict = getFullDict(outputLst=False,useLst=useLst)\n",
    "    inDict = fullDict.copy()\n",
    "    hallLst=[]\n",
    "    smallerDict={}\n",
    "    for path in pathways:\n",
    "        if path in fullDict.keys():\n",
    "            smallerDict[path] = fullDict[path]\n",
    "    inDict = smallerDict.copy()\n",
    "\n",
    "    for i in fullDict.keys():\n",
    "        if 'HALLMARK' in i:\n",
    "            hallLst.append(i)\n",
    "    clumps={}\n",
    "    doneLst=[]\n",
    "    for testPath in hallLst:\n",
    "        testPathName = testPath\n",
    "        testDict = __testCondense(inDict=inDict,cutoffLst=[cutoff],testPath=testPath,doneLst=doneLst,fullDict=fullDict)\n",
    "        lst = testDict['Overlap Percentage '+str(cutoff)]\n",
    "        if len(lst)>1:\n",
    "            clumps[testPathName] = lst\n",
    "        doneLst.extend(lst)\n",
    "    for name,test_list in testLstLists:\n",
    "        lst=[]\n",
    "        for path in pathways:\n",
    "            res = any(elem for elem in test_list if(elem in path))\n",
    "            if res:\n",
    "                lst.append(path)\n",
    "        clumps[name]=lst\n",
    "    notHallLst=[]\n",
    "    for pathway in inDict:\n",
    "        if not pathway in doneLst:\n",
    "            notHallLst.append(pathway)\n",
    "    clumps['Uncategorized'] = notHallLst\n",
    "    dbLst=[]\n",
    "    for gsea in glob.glob('GSEA Output/'+dateIn+'/*'):\n",
    "        dbLst.append(gsea.split('\\\\')[-1])\n",
    "    df1,df2=__superDfGSEA(dateIn,dbLst,placeLst,desktop=False,skipImmune=False,preRank=True,coldNum=coldNum,\n",
    "                          fdrVal=0.1,containsColdCluster=containsColdCluster)    \n",
    "    df1,df2,catLst = __getPathLst(df1,df2,removeBad=False)\n",
    "    ls = df1.index.copy()\n",
    "    for hallClump in tq(clumps,desc='Working on Clumps'):\n",
    "        gc.collect()\n",
    "        lst = clumps[hallClump]\n",
    "        pathways = __goodGenes(ls,lst)\n",
    "        if len(pathways)>1:\n",
    "            df3 = df1.loc[pathways]\n",
    "            df4 = df2.loc[pathways]\n",
    "            title=pathName;db='Gene Sets Overlapping with '+hallClump+', '\n",
    "            if geneSpecific or excelGeneSpecific:\n",
    "                clumpCountDict = countSpecificUpinColdGenes(ver=ver,inDict=inDict,placeLst=placeLst,\n",
    "                                                            pvalCutoff=pvalCutoffGenes,pathways=pathways)\n",
    "            if plot:\n",
    "                title2 = 'Saved Images/Gene Sets Overlapping with '+hallClump+', '+title+', '+metric+'.pdf'\n",
    "                title2=title2.replace(', ,',',')\n",
    "                if replace or not os.path.exists(title2):\n",
    "                    suptitleName = hallClump.replace('HALLMARK_','').replace('_',' ')\n",
    "                    if hallClump != 'Uncategorized':\n",
    "                        suptitleName += ' Associated' \n",
    "                    suptitleName+= ' Gene Lists'\n",
    "                    if cGroups[0]:\n",
    "                        c1 = cGroups[1][0];c2 = cGroups[1][1];c3 = cGroups[1][2]\n",
    "                        rowColors = getRowColorsCs(pathways=list(df3.index),c1=c1,c2=c2,c3=c3,colors=colors)\n",
    "                        names=zip(['C All','C2','C1'],colors)\n",
    "                        rowColors=(rowColors,names)\n",
    "                    else:\n",
    "                        rowColors=(None,'')\n",
    "                    row,col = __helpPlotGSEA(df3,df4,title=title,db=db,metric=metric,suptitleName=suptitleName,\n",
    "                                             rowColors=rowColors,\n",
    "                                             save=save,numParts=numParts,reverseOrder=reverseOrder,noParts=noParts,\n",
    "                                             catLst=[],figSize=figSize,fixPos=fixPos,pos=Position,fontSize=fontSize,rot=rot)\n",
    "            if excel:\n",
    "                title2 = 'Excel/Gene Sets Overlapping with '+hallClump+', '+title+', '+metric\n",
    "                df3.to_excel(title2+', NES.xlsx');df4.to_excel(title2+', FDR.xlsx')\n",
    "                both = __getBothSupers(df3,df4);both.to_excel(title2+', Both NES and FDR.xlsx')\n",
    "            if excelGeneSpecific:\n",
    "                title2 = 'Excel/Gene Sets Overlapping with '+hallClump+', Counts of Specific Genes up in Cold' \n",
    "                title2+=', '+title+', '+metric\n",
    "                countDf= pd.DataFrame.from_dict(clumpCountDict);order = list([countDf.columns[-1]])+list(countDf.columns[:-1])\n",
    "                countDf = countDf[order];countDf.to_excel(title2+'.xlsx')\n",
    "    return 1\n",
    "def __helpMergePDFs(directory,name,moveLast=False,erase=False,move2=False):\n",
    "    if os.path.exists(name+'.pdf'):\n",
    "        os.remove(name+'.pdf')\n",
    "    images = glob.glob(directory)\n",
    "    if moveLast:\n",
    "        if move2:\n",
    "            half = int(len(images)/2)\n",
    "            l2 = images[:half]\n",
    "            l3 = images[half:]\n",
    "            l2 = l2[1:]+[l2[0]]\n",
    "            l3 = l3[1:]+[l3[0]]\n",
    "            images = l2+l3\n",
    "        else:\n",
    "            images = [images[-1]]+images[:-1]\n",
    "    __mergePDFs(images,name,erase=erase)\n",
    "    return 1\n",
    "\n",
    "def getRowColorsCs(pathways,c1,c2,c3,colors):\n",
    "    rowColors=[]\n",
    "    for cPath,color in [(c1,colors[0]),(c2,colors[1]),(c3,colors[2])]:\n",
    "        rowLst=[]\n",
    "        for path in pathways:\n",
    "            if path in cPath:\n",
    "                rowLst.append(color)\n",
    "            else:\n",
    "                rowLst.append('White')\n",
    "        rowColors.append(rowLst)\n",
    "    return rowColors\n",
    "def countSpecificUpinColdGenes(ver,placeLstIn,inDict,pvalCutoff,pathways,acceptLst=['C1','C2','C All'],\n",
    "                               count=True,useGenes=False,genesIn=[],tqOn=False,excludeGenes=[]):\n",
    "    superDfNes = pd.read_csv('SuperDfNes_c2_c5_hall_v'+str(ver)+'.tsv',sep='\\t',index_col=0)\n",
    "    p4=['Adrenocortical','Breast HR+','K_Lung adenocarcinoma','K_Lung squamous','Thyroid','K_Skin'];p5=[]\n",
    "    for place in superDfNes.columns:\n",
    "        if not place in p4:p5.append(place)\n",
    "    p6 = p4+p5;shortNamePlaceLst = list(superDfNes.columns);shortNamePlaceLst = shortNamePlaceLst[1:]+[shortNamePlaceLst[0]]\n",
    "    CareasLst = [(p4,'C1'),(p5,'C2'),(p6,'C All')];dfLst=[];frst=True\n",
    "    for place in placeLstIn:\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(ver)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        if frst:allGenes = list(df.index);frst=False\n",
    "        else:allGenes.extend(list(df.index))\n",
    "        if len(df.index)>1:Hot,Cold = __getHotCold(df);dfLst.append((place,Hot,Cold))\n",
    "    allGenes = list(set(allGenes));clumpCountDict={}\n",
    "    if count:\n",
    "        totalCountDict={}\n",
    "        for areas,name in CareasLst:\n",
    "            if name in acceptLst:totalCountDict[name]=0\n",
    "        totalCountDict['Total # Genes in Clump']=0\n",
    "    for path in pathways:\n",
    "        gc.collect()\n",
    "        if path in inDict.keys() or useGenes:\n",
    "            if useGenes:\n",
    "                if genesIn =='All':genes = allGenes.copy()\n",
    "                else:genes = genesIn.copy()\n",
    "            else:genes = inDict[path]\n",
    "            dfLstPath=[];pathwayDict={};inputs=genes\n",
    "            if tqOn:inputs=tq(genes)\n",
    "            for gene in inputs:\n",
    "                geneLst=[]\n",
    "                for place,Hot,Cold in dfLst:\n",
    "                    if gene in Hot.index and gene in Cold.index:\n",
    "                        a = Hot.loc[gene];b = Cold.loc[gene];tStat,pval = stats.ttest_ind(a,b);geneLst.append(tStat)\n",
    "                    else:geneLst.append(0)\n",
    "                pathwayDict[gene] = geneLst\n",
    "            pathwayDf = pd.DataFrame.from_dict(pathwayDict, orient='index',columns=shortNamePlaceLst);pathwayCountDict={}\n",
    "            for areas,name in CareasLst:\n",
    "                if name in acceptLst:\n",
    "                    if count:countN=0\n",
    "                    else:countN=[]\n",
    "                    pathwayDfC = pathwayDf[areas]\n",
    "                    for gene in pathwayDfC.index:\n",
    "                        ser = pathwayDfC.loc[gene];stat,pval = stats.ttest_1samp(ser,0)\n",
    "                        if stat < 0 and pval <= pvalCutoff:\n",
    "                            if count:countN +=1;totalCountDict[name] += 1\n",
    "                            else:countN.append(gene)\n",
    "                    pathwayCountDict[name] = countN\n",
    "            if count:\n",
    "                pathwayCountDict['Total # Genes In Pathway']=len(genes);totalCountDict['Total # Genes in Clump']+=len(genes)\n",
    "            clumpCountDict[path] = pathwayCountDict\n",
    "    if count:clumpCountDict['Total Count'] = totalCountDict\n",
    "    return clumpCountDict\n",
    "def plotCGroupClumps(ver,placeLst,pvalCutoff=0.05,coldNum=1,metric='cosine',save=False,numParts=30,noParts=False,\n",
    "                     reverseOrder=False,replace=False,merge=False,pvalCutoffGenes=0.05,\n",
    "                     fixPos=False,Position={},fontSize=12,rot=45,figSize=(60,40),containsColdCluster=(False,False,0),\n",
    "                     clumpCutoff=0.2,plot=False,excel=False,colors=['Orange','Purple','Green'],\n",
    "                     geneSpecific=False,excelGeneSpecific=False):\n",
    "    clusterTTest(ver,pvalCutoff)\n",
    "    c1 = pd.read_excel('C1 coldCluster cancers, 1 sample ttest up in cold, v'+str(ver)+', pval '+str(pvalCutoff)+'.xlsx',\n",
    "                       sep='\\t',index_col=0);c1Paths = list(c1.index)\n",
    "    c2 = pd.read_excel('C2 otherCluster cancers, 1 sample ttest up in cold, v'+str(ver)+', pval '+str(pvalCutoff)+'.xlsx',\n",
    "                       sep='\\t',index_col=0);c2Paths = list(c2.index)\n",
    "    c3 = pd.read_excel('C Union bothCluster cancers, 1 sample ttest up in cold, v'+str(ver)+', pval '+str(pvalCutoff)+'.xlsx',\n",
    "                       sep='\\t',index_col=0);c3Paths = list(c3.index)\n",
    "    pathways = list(set(c1Paths+c2Paths+c3Paths))\n",
    "    pathName = 'Up in C Groups per 1 sample Ttest, v'+str(ver)+', pval '+str(pvalCutoff);dateIn = '2020-11-13, v'+str(ver)\n",
    "    plotClumps(pathways,dateIn=dateIn,coldNum=coldNum,metric=metric,save=save,numParts=numParts,replace=replace,\n",
    "               reverseOrder=reverseOrder,noParts=noParts,fixPos=fixPos,Position=Position,fontSize=fontSize,rot=rot,\n",
    "               figSize=figSize,containsColdCluster=containsColdCluster,cutoff=clumpCutoff,plot=plot,excel=excel,\n",
    "               placeLst=placeLst,pathName=pathName,colors=colors,cGroups=(True,[c3Paths,c2Paths,c1Paths]),\n",
    "               geneSpecific=geneSpecific,excelGeneSpecific=excelGeneSpecific)\n",
    "    if merge:\n",
    "        files= glob.glob('Saved Images/*Gene Sets*v'+str(ver)+'*')\n",
    "        name='Saved Images\\\\Gene Sets Overlapping, Up in C Groups per 1 sample Ttest, v'+str(ver)\n",
    "        name+= ', pval '+str(pvalCutoff)+', '+metric;__mergePDFs(files,name,erase=True)\n",
    "    return 1\n",
    "def getListofGenes(ver,pvalLst,genesIn,title):\n",
    "    outDict={}\n",
    "    for pval in tq(pvalLst,desc='Getting Genes'):\n",
    "        output = countSpecificUpinColdGenes(ver=ver,placeLstIn=placeLst3,inDict={},pvalCutoff=pval,pathways=['All Genes'],\n",
    "                                            acceptLst=['C1'],tqOn=False,\n",
    "                                            count=False,useGenes=True,genesIn=genesIn) \n",
    "        countDf= pd.DataFrame.from_dict(output);genes = countDf['All Genes']['C1'];outDict[pval] = genes\n",
    "    maxLen = len(outDict[0.05])\n",
    "    for pv in outDict:\n",
    "        lst = outDict[pv]\n",
    "        for i in range(maxLen-len(lst)):lst.append('')\n",
    "        lst.insert(0,str(len(lst)));outDict[pv]=lst\n",
    "    df = pd.DataFrame.from_dict(outDict);df.to_excel(title+'.xlsx')\n",
    "    return 1\n",
    "def __helpGetBLDict(dfIn,col,blDict={},blDict2={},usePathwayName=True,useGenes=False,genesIn=[]):\n",
    "    df = dfIn.copy();useLst = ['c2.cp','h.all'];fullDict = getFullDict(outputLst=False,useLst=useLst)\n",
    "    for cat in list(df[col].unique()):\n",
    "        df3 = df[df[col]==cat];cat = cat.strip();lst=[]\n",
    "        if usePathwayName:\n",
    "            for ind in df3.index:\n",
    "                if ind in fullDict.keys():pathLst = fullDict[ind];lst.extend(pathLst)\n",
    "        else:lst =  list(df3.index)\n",
    "        for elem in lst:blDict2[elem]=cat\n",
    "        lst=list(set(lst));blDict[cat] = lst.copy()\n",
    "    if useGenes:\n",
    "        blDict2_b={};blDict_b={}\n",
    "        for path in blDict:blDict_b[path]=[]\n",
    "        for gene in genesIn:\n",
    "            if gene in blDict2:path = blDict2[gene];blDict_b[path].append(gene);blDict2_b[gene]=path\n",
    "        blDict = blDict_b.copy();blDict2 = blDict2_b.copy()\n",
    "    return blDict,blDict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInteractTypeOrder(interactType):\n",
    "    lst=interactType.split('=')\n",
    "    for i in lst:\n",
    "        if '+' in i:\n",
    "            return (True,False)\n",
    "        if '-' in i:\n",
    "            return (False,True)\n",
    "def BNLearnHMs(thres,globDir,titleIn,genesIn,dictIn,immuneDict,metric='cosine',size=(30,20),excludePre=True,pathways=False,\n",
    "               onlyBGE=False,onlyBDE=False,mergedAll=True,indivCancers=False,interPath=False,immuneNonOnly=False,\n",
    "               nonToIm=False,dirThres=0.65,cancersNum=1,excel=False,ylabels=0):\n",
    "    graphLst = __BNGraphsTinyBegin(globDir=globDir,pathways=pathways,onlyBGE=onlyBGE,onlyBDE=onlyBDE);placeLs = []\n",
    "    if(excludePre):graphLst = __removeLstFunc(graphLst,'PrePure')\n",
    "    for graph in graphLst:\n",
    "        place = graph.split('\\\\')[1].split(',')[0].strip();placeLs.append(place)\n",
    "    placeLs = list(set(placeLs))\n",
    "    if mergedAll:\n",
    "        graphLst = __removeLstFunc(graphLst,'Pre-BN')\n",
    "        __BNLearnHMsHelp(graphLst,genesIn=genesIn,immuneDict=immuneDict,dropImmune=False,excel=excel,metric=metric,\n",
    "                         ylabels=ylabels,\n",
    "                         dropPure=False,thres=thres,dirThres=dirThres,pathways=pathways,interPath=interPath,size=size,\n",
    "                         immuneNonOnly=immuneNonOnly,nonToIm=nonToIm,dictIn=dictIn,cancersNum=cancersNum,titleIn=titleIn)\n",
    "    if indivCancers:\n",
    "        for place in tq(placeLs,desc='Making BN Graphs'):\n",
    "            graphLst2 = [p for p in graphLst if place in p]\n",
    "            __BNLearnHMsHelp(graphLst2,genesIn=genesIn,immuneDict=immuneDict,dropImmune=False,excel=excel,ylabels=ylabels,\n",
    "                             dropPure=False,thres=thres,dirThres=dirThres,pathways=pathways,interPath=interPath,size=size,\n",
    "                             immuneNonOnly=immuneNonOnly,nonToIm=nonToIm,dictIn=dictIn,cancersNum=cancersNum,titleIn=titleIn)\n",
    "    return 1\n",
    "def __BNLearnHMsHelp(graphLst,genesIn,immuneDict,dropImmune,dropPure,thres,dirThres,pathways,interPath,immuneNonOnly,\n",
    "                     nonToIm,dictIn,cancersNum,titleIn,excel,size,metric,ylabels):\n",
    "    dfDict={};dfDict2={};dfDict3={};dfTypeDict={}\n",
    "    for graph in graphLst:\n",
    "        place = graph.split(',')[0].split('\\\\')[-1].replace('Kobe Genes ','');placeDict={}\n",
    "        for gene in genesIn:\n",
    "            for gene2 in genesIn:\n",
    "                if not gene==gene2:placeDict[(gene,gene2)]=[]\n",
    "        dfDict[place]=placeDict.copy();dfDict2[place]=placeDict.copy();dfDict3[place]=placeDict.copy()\n",
    "        dfTypeDict[place]=placeDict.copy()\n",
    "    inputs=graphLst\n",
    "    out = Parallel(n_jobs=num_cores)(delayed(__parallelBNLearnHMs)(graph,immuneDict,thres,dictIn,interPath,immuneNonOnly,\n",
    "                                                                   nonToIm,dirThres,pathways) \n",
    "                                     for graph in inputs)\n",
    "    for dfPlace,place,corr in out:\n",
    "        for frm,to in dfDict[place]:\n",
    "            corrVal=np.nan\n",
    "            if frm in corr.columns and to in corr.columns:\n",
    "                corrVal=corr.loc[frm][to];df2=dfPlace[dfPlace['from']==frm];df2=df2[df2['to']==to]\n",
    "                if len(df2.index)>0:\n",
    "                    inVal=1;inVal2=round(corrVal,4);inValType = df2.loc[df2.index[0]]['Type']\n",
    "                    if corrVal<0:inVal=-1\n",
    "                else:\n",
    "                    inVal=np.nan;inVal2=np.nan;inValType=np.nan\n",
    "            else:\n",
    "                inVal=np.nan;inVal2=np.nan;inValType=np.nan\n",
    "            dfDict[place][(frm,to)]=corrVal;dfDict2[place][(frm,to)]=inVal;dfDict3[place][(frm,to)]=inVal2\n",
    "            dfTypeDict[place][(frm,to)]=inValType\n",
    "    df = pd.DataFrame.from_dict(dfDict);df2 = pd.DataFrame.from_dict(dfDict2);df3 = pd.DataFrame.from_dict(dfDict3)\n",
    "    dfType = pd.DataFrame.from_dict(dfTypeDict)\n",
    "    df2.dropna(how='all',inplace=True);df=df.loc[df2.index];df2=df2.fillna(0);df3=df3.loc[df2.index];\n",
    "    dfType=dfType.loc[df2.index];dfType.dropna(axis=1,how='all',inplace=True);idxLst=[]\n",
    "    for i,j in dfType.index:\n",
    "        for col in dfType.columns:\n",
    "            typ=dfType.loc[(i,j)][col] \n",
    "            if typ == 'Directed' or typ== 'Undirected':\n",
    "                if typ== 'Undirected':\n",
    "                    print(typ)\n",
    "                idxTyp=dfType.loc[(i,j)][col]\n",
    "                break\n",
    "        if idxTyp=='Directed':idx = i+' -> '+j\n",
    "        else:idx=i+' -- '+j\n",
    "        idxLst.append(idx)\n",
    "    del(dfType);del(dfTypeDict);gc.collect();df.index = idxLst;df2.index=idxLst;df3.index=idxLst\n",
    "    absDf2 = abs(df2);absDf2=absDf2.T;absNum = absDf2.sum() >= cancersNum;idxLst=list(absNum[absNum].index)\n",
    "    df=df.loc[idxLst];df2=df2.loc[idxLst];df3=df3.loc[idxLst];df=df.dropna();df3=df3.loc[df.index]\n",
    "    if len(df.index)>1:\n",
    "        if excel:\n",
    "            path1Lst=[];path2Lst=[]\n",
    "            for i in df4.index:\n",
    "                splt=i.split();frm=splt[0];to=splt[-1];path1=dictIn[frm];path2=dictIn[to]\n",
    "                path1Lst.append(path1);path2Lst.append(path2)\n",
    "            df4.insert(0,'To Gene Pathway',path2Lst);df4.insert(0,'From Gene Pathway',path1Lst)\n",
    "            title = 'Immune-Non Pairings, Confidence '+str(thres)+', edge in at least '\n",
    "            title += str(cancersNum)+' cancer areas'\n",
    "            title += ', undirected and directed.xlsx';df4.to_excel(title)\n",
    "        maxx=df.max().max();minn=df.min().min()\n",
    "        maxx = max(abs(maxx),abs(minn));minn=maxx*-1\n",
    "        cg = sb.clustermap(df,cmap=cmapSpecial,vmax=maxx,vmin=minn,xticklabels=1,yticklabels=ylabels,metric=metric,\n",
    "                           annot=df3,annot_kws={\"size\":10},figsize=size)\n",
    "        plt.setp(cg.ax_heatmap.get_yticklabels(),rotation=45,va='bottom')\n",
    "        title=titleIn+', Confidence '+str(thres)+', metirc '+metric+', edge in at least in '\n",
    "        title+= str(cancersNum)+' cancers, only BGE, v7';cg.fig.suptitle(title,size='x-large')\n",
    "        for t in cg.ax_heatmap.texts:\n",
    "            string = t.get_text()\n",
    "            if string == 'nan':t.set_text('')\n",
    "        plt.savefig('Graphs/'+title+'.png',bbox_inches = \"tight\",dpi=300);plt.close()\n",
    "    return 1\n",
    "\n",
    "def __parallelBNLearnHMs(graph,immuneDict,thres,dictIn,interPath,immuneNonOnly,nonToIm,dirThres,pathways):\n",
    "    g = __getMergedG([graph],immuneDict=immuneDict,dropImmune=False,dropPure=False,agnostic=False,\n",
    "                     thres=thres,nonToIm=nonToIm,dictIn=dictIn,\n",
    "                     thresFloor=0.1,interPath=interPath,immuneNonOnly=immuneNonOnly,dirThres=dirThres,\n",
    "                     pathways=pathways,below=False)\n",
    "    inputsLst=g[2];corr=__getCorrInputsLst(inputsLst)\n",
    "    setupOut = __setupHelpMakeGraphsCreate(g=g[0],undirected=True,dirThres=dirThres,colored=False,colorsLst=[],\n",
    "                                           blackList=False,blackListFile='',\n",
    "                                           colorDictIn={},colorImmuneDict={},onlyConnected=True)\n",
    "    Nodes,direct,undirect,colorDict,colorPathDict,topLs=setupOut\n",
    "    dfPlace = pd.concat([direct,undirect]);typeLst=[]\n",
    "    for i in range(len(direct.index)):typeLst.append('Directed')\n",
    "    for i in range(len(undirect.index)):typeLst.append('Undirected')\n",
    "    dfPlace['Type']=typeLst;place = graph.split(',')[0].split('\\\\')[-1].replace('Kobe Genes ','')\n",
    "    return (dfPlace,place,corr)\n",
    "def recursiveHelpPathFinder(i,targetLst,direct,doneLst,corr,allowNegCorr=True,allowPosCorr=True,numNegs=0):\n",
    "    ser=direct.loc[i]\n",
    "    if ser['to'] in targetLst:\n",
    "        correlation = corr.loc[ser['to']][ser['from']]\n",
    "        if correlation < 0:numNegs+=1\n",
    "        isOdd=numNegs%2!=0\n",
    "        if ((allowPosCorr and correlation >= 0) or (allowNegCorr and isOdd)):return [ser['to'],ser['from']], [i]\n",
    "        else:return False, []\n",
    "    else:\n",
    "        to=direct.loc[i]['to'];direct2=direct[direct['from']==to]\n",
    "        for newI in direct2.index:\n",
    "            if not newI in doneLst:\n",
    "                frm= direct.loc[i]['from'];to=direct.loc[i]['to'];correlation = corr.loc[to][frm]\n",
    "                if correlation < 0:numNegs+=1\n",
    "                path, lst = recursiveHelpPathFinder(i=newI,targetLst=targetLst,direct=direct,doneLst=doneLst,\n",
    "                                                    corr=corr,allowNegCorr=allowNegCorr,allowPosCorr=allowPosCorr,\n",
    "                                                    numNegs=numNegs)\n",
    "                if path:\n",
    "                    if not to in path:path.append(to)\n",
    "                    path.append(frm);lst.append(i)\n",
    "                    return path,lst\n",
    "        return False,[]\n",
    "# Import modules\n",
    "import http.client\n",
    "import json\n",
    "##### Function to run X2K\n",
    "### Input: a Python list of gene symbols\n",
    "### Output: a dictionary containing the results of X2K, ChEA, G2N, KEA.\n",
    "\n",
    "def run_X2K(input_genes, options={},useFile=False,file=''):\n",
    "    if useFile:\n",
    "        print('Will do')\n",
    "    else:\n",
    "        # Open HTTP connection\n",
    "        conn = http.client.HTTPConnection(\"amp.pharm.mssm.edu\")\n",
    "\n",
    "        # Set default options\n",
    "        default_options = {'text-genes': '\\n'.join(input_genes),\n",
    "                           'included_organisms': 'both',\n",
    "                           'TF-target gene background database used for enrichment': 'ChEA & ENCODE Consensus',\n",
    "                           'sort transcription factors by': 'p-value',\n",
    "                           'min_network_size': 10,\n",
    "                           'number of top TFs': 10,\n",
    "                           'path_length': 2,\n",
    "                           'min_number_of_articles_supporting_interaction': 0,\n",
    "                           'max_number_of_interactions_per_protein': 200,\n",
    "                           'max_number_of_interactions_per_article': 100,\n",
    "                           'enable_BioGRID': True,\n",
    "                           'enable_IntAct': True,\n",
    "                           'enable_MINT': True,\n",
    "                           'enable_ppid': True,\n",
    "                           'enable_Stelzl': True,\n",
    "                           'kinase interactions to include': 'kea 2018',\n",
    "                           'sort kinases by': 'p-value'}\n",
    "\n",
    "        # Update options\n",
    "        for key, value in options.items():\n",
    "            if key in default_options.keys() and key != 'text-genes':\n",
    "                default_options.update({key: value})\n",
    "        # Get payload\n",
    "        boundary = \"----WebKitFormBoundary7MA4YWxkTrZu0gW\"\n",
    "        payload = ''.join(\n",
    "            ['--' + boundary + '\\r\\nContent-Disposition: form-data; name=\\\"{key}\\\"\\r\\n\\r\\n{value}\\r\\n'.format(**locals())\n",
    "             for key, value in default_options.items()]) + '--' + boundary + '--'\n",
    "        # Get Headers\n",
    "        headers = {\n",
    "            'content-type': \"multipart/form-data; boundary=\" + boundary,\n",
    "            'cache-control': \"no-cache\",\n",
    "        }\n",
    "        # Initialize connection\n",
    "        # Get response\n",
    "        try:\n",
    "            conn.request(\"POST\", \"/X2K/api\", payload, headers)\n",
    "            res=conn.getresponse()\n",
    "            # Read response\n",
    "            data = res.read().decode('utf-8')\n",
    "            # Convert to dictionary\n",
    "            x2k_results = {key: json.loads(value) if key != 'input' else value for key, value in json.loads(data).items()}\n",
    "            # Clean results\n",
    "            x2k_results['ChEA'] = x2k_results['ChEA']['tfs'];x2k_results['G2N'] = x2k_results['G2N']['network']\n",
    "            x2k_results['KEA'] = x2k_results['KEA']['kinases'];x2k_results['X2K'] = x2k_results['X2K']['network']\n",
    "            return x2k_results\n",
    "        except:\n",
    "            return run_X2K(input_genes, options,useFile,file)\n",
    "\n",
    "def parallelGraphDict(gene,graphDict,dfPlace,meanDict,thres):\n",
    "    ser=dfPlace[gene]\n",
    "    out = Parallel(n_jobs=7)(delayed(__parallelGraphDictHelper)(gene=gene,n=n,ser=ser,meanDict=meanDict,thres=thres,\n",
    "                                                                graphDict=graphDict,outDict={}) for n in graphDict)\n",
    "    outDict={}\n",
    "    for d in out:\n",
    "        outDict.update(d)\n",
    "    return (gene,outDict)\n",
    "def __parallelGraphDictHelper(gene,n,ser,meanDict,thres,graphDict,outDict):\n",
    "    ls = graphDict[n]\n",
    "    if gene in ls:\n",
    "        outDict[n]=True\n",
    "    else:\n",
    "        mean = meanDict[n]\n",
    "        corP=ser.corr(mean,method='pearson');corS=ser.corr(mean,method='spearman');corr=(corP+corS)/2\n",
    "        if corr >= thres:\n",
    "            outDict[n]=True\n",
    "        else:\n",
    "            outDict[n]=False\n",
    "    return outDict\n",
    "def __helpMergeDfsCliques(df,dfPlace,title,frst=True,colLst=[],dfOut=[[],[]]):\n",
    "    colLst2=colLst.copy()\n",
    "    for col in df.columns:\n",
    "        clique = list(df[col].dropna());df2=dfPlace[clique].T;df2Mean=df2.mean()\n",
    "        df2Mean.index.name='Samples';df2Mean.name='Name'\n",
    "        if frst:\n",
    "            dfOut = df2Mean.to_frame();dfOut.index.name='Samples';frst=False\n",
    "        else:\n",
    "            dfOut=dfOut.merge(df2Mean,on='Samples')\n",
    "        colLst2.append(title+' '+str(col))\n",
    "    return (dfOut,colLst2)\n",
    "def __getNonToImmPath(depthOfPaths,immuneDict,g,dictIn,immuneNonOnly,nonToIm,rmvLen):\n",
    "    useImmDict=immuneDict.copy();outLst=[];useG=g.copy()\n",
    "    for n in range(depthOfPaths):\n",
    "        keep=interPathwayOnly(useG,immuneDict=useImmDict,dictIn=dictIn,immuneNonOnly=immuneNonOnly,\n",
    "                              nonToIm=nonToIm,rmvLen=rmvLen,pathways=True)\n",
    "        outLst.extend(keep.index);keepLst=list(set(list(keep['from'])))\n",
    "        for clique in keepLst:useImmDict[clique.split('_')[0]]=['red']\n",
    "        useGLst=[]\n",
    "        for i in useG.index:\n",
    "            if useG.loc[i]['to'] in keepLst:useGLst.append(i)\n",
    "        useG=g.loc[useGLst]\n",
    "    outLst=list(set(outLst));gOut = g.loc[outLst]\n",
    "    return gOut\n",
    "def removeCommonTFs(immTFIn,nonImmLst,removeTFs=[]):\n",
    "    immTF=immTFIn.copy();outLst=[];immDoneLst=[];outLst2=[]\n",
    "    if len(immTF)>1:\n",
    "        immSet=set(immTF['name'])\n",
    "        for i in range(len(nonImmLst)):\n",
    "            nonImmTF = nonImmLst[i];nonImmDoneLst=[]\n",
    "            if len(nonImmTF)>1:\n",
    "                nonImmSet=set(nonImmTF['name']);commonTFs= list(immSet.intersection(nonImmSet));commonTFs.extend(removeTFs)\n",
    "                for tf in commonTFs:\n",
    "                    immIdxLst=list(immTF[immTF['name']==tf].index);immDoneLst.extend(immIdxLst)\n",
    "                    immIdxLst=list(nonImmTF[nonImmTF['name']==tf].index);nonImmDoneLst.extend(immIdxLst)\n",
    "                nonImmTF2=nonImmTF.loc[nonImmDoneLst]#nonImm2 = getTF2(dfTF,removeTFs)\n",
    "                nonImmTF.drop(nonImmDoneLst,inplace=True)#;nonImmTF=nonImmTF[nonImmTF['type']=='tf']\n",
    "                outLst.append(nonImmTF);outLst2.append(nonImmTF2)\n",
    "        immDoneLst=list(set(immDoneLst))\n",
    "        immTF2=immTF.loc[immDoneLst];immTF.drop(immDoneLst,inplace=True)#;immTF=immTF[immTF['type']=='tf']\n",
    "        outLst.reverse();outLst.append(immTF);outLst2.reverse();outLst2.append(immTF2)\n",
    "    return outLst,outLst2\n",
    "def fixSourceTargetTFs(source,target,tfs=True,dataframe=True):\n",
    "    if tfs:\n",
    "        source=source[source['type']=='tf'];target=target[target['type']=='tf']\n",
    "    if dataframe:\n",
    "        sourceTFs=set(source['name']);targetTFs=set(target['name']);common=sourceTFs.intersection(targetTFs)\n",
    "        sourceTFs=list(sourceTFs);sourceTFs = [i.split('_')[0] for i in sourceTFs if not i in targetTFs]\n",
    "        targetTFs =list(targetTFs);targetTFs = [i.split('_')[0] for i in targetTFs if not i in sourceTFs]\n",
    "    else:\n",
    "        sourceTFs=source.copy();targetTFs=target.copy()\n",
    "    sourceTFs=','.join(sourceTFs);targetTFs=','.join(targetTFs)\n",
    "    return sourceTFs,targetTFs\n",
    "def masterOmniPath(globDir='Run BNLearn/Outputs/*Clique*',pathways=False,onlyBGE=False,onlyBDE=False,excludePre=True,\n",
    "                   mergedAll=False,thres=0.75,interPath=True,immuneNonOnly=True,nonToIm=True,dirThres=0.65,\n",
    "                   allowPosCorr=False,allowNegCorr=False,useFile=False,file=''):\n",
    "    directory='TF Anaylsis/Outputs/'\n",
    "    if allowNegCorr and not allowPosCorr:directory+='Negative Correlation, '\n",
    "    else:directory+='Any Correlation, '\n",
    "    if onlyBGE or onlyBDE:\n",
    "        if onlyBGE:directory+='BGE, '\n",
    "        else:directory+='BDE, '\n",
    "    directory+='Confidence '+str(thres)+', NonToImmune Paths'\n",
    "    if not os.path.exists(directory):os.makedirs(directory)\n",
    "    graphLst = __BNGraphsTinyBegin(globDir=globDir,pathways=pathways,onlyBGE=onlyBGE,onlyBDE=onlyBDE);placeLs = []\n",
    "    if(excludePre):graphLst = __removeLstFunc(graphLst,'PrePure')\n",
    "    for graph in graphLst:place = graph.split('\\\\')[1].split(',')[0].strip();placeLs.append(place)\n",
    "    placeLs=list(set(placeLs))\n",
    "    if mergedAll:graphLst=__removeLstFunc(graphLst,'Pre-BN')\n",
    "    immuneDict={};dictIn={}\n",
    "    for i in range(58):\n",
    "        immuneDict['Immune'+str(i)]=['Red'];dictIn['NonImmune'+str(i)]='NonImmune'+str(i)\n",
    "        dictIn['Immune'+str(i)]='Immune'+str(i);colorDictIn['NonImmune'+str(i)]=[0];colorDictIn['Immune '+str(i)]=[2]\n",
    "    immuneDict['Heat']='red';colorDictIn['Heat']=[1];colorsLst=(('set312',12),('pastel28',8),('pastel19',9));colorsLen=29\n",
    "    for graph in graphLst:\n",
    "        g = __getMergedG([graph],immuneDict=immuneDict,dropImmune=False,dropPure=False,agnostic=False,\n",
    "                         thres=thres,nonToIm=True,dictIn=dictIn,\n",
    "                         thresFloor=0.1,interPath=True,immuneNonOnly=True,dirThres=dirThres,\n",
    "                         pathways=pathways,below=False,allowPaths=True)\n",
    "        inputsLst=g[2];corr=__getCorrInputsLst(inputsLst)\n",
    "        setupOut = __setupHelpMakeGraphsCreate(g=g[0],undirected=True,dirThres=dirThres,colored=False,colorsLst=[],\n",
    "                                               blackList=False,blackListFile='',\n",
    "                                               colorDictIn={},colorImmuneDict={},onlyConnected=True)\n",
    "        Nodes,direct,undirect,colorDict,colorPathDict,topLs=setupOut\n",
    "        corr = __getCorrInputsLst(inputsLst);targetLst=[]\n",
    "        for i in list(set(direct['to'])):\n",
    "            if not 'Non' in i:targetLst.append(i)\n",
    "        doneLst=[];pathLst=[]\n",
    "        for i in direct.index:\n",
    "            if not i in doneLst and 'Non' in direct.loc[i]['from']:\n",
    "                path,lst = recursiveHelpPathFinder(direct=direct,i=i,doneLst=doneLst,targetLst=targetLst,\n",
    "                                                   corr=corr,allowPosCorr=allowPosCorr,allowNegCorr=allowNegCorr)\n",
    "                if path:\n",
    "                    doneLst.extend(lst);pathLst.append(path)\n",
    "        __masterOmniPathHelper(pathLst=pathLst,directory=directory,useFile=useFile,file=file,corr=corr)\n",
    "    return 1\n",
    "def runOmniPath(geneFrom,geneTo):\n",
    "    try:\n",
    "        OmniPathURL='https://omnipathdb.org/interactions/?genesymbols=1&source_target=AND&sources='+geneFrom\n",
    "        OmniPathURL+='&targets='+geneTo+'&fields=sources,references'\n",
    "        __r = requests.get(OmniPathURL);page = str(__r.content);df=__OmniPathHelperFunc(page)\n",
    "    except:\n",
    "        return runOmniPath(geneFrom,geneTo)\n",
    "    return df\n",
    "def __OmniPathHelperFunc(page):\n",
    "    totalLst=[];n=0\n",
    "    for line in page.split('\\\\n'):\n",
    "        cols=line.split('\\\\t');totalLst.append(cols)\n",
    "    if len(totalLst)>2:\n",
    "        for ls in totalLst:\n",
    "            if len(ls)>1:n+=1\n",
    "        totalLst=totalLst[:n]\n",
    "        try:\n",
    "            df=pd.DataFrame(totalLst);df.columns=df.loc[0];df=df.T;df.drop(columns=[0],inplace=True);df=df.T\n",
    "            return df\n",
    "        except:\n",
    "            return False\n",
    "    else: \n",
    "        return False\n",
    "def getTFs(imm,useFile,file):\n",
    "    splt=imm.split('Immune');tpy=splt[0];num=splt[1]\n",
    "    immFile='TF Anaylsis/Inputs\\\\'+tpy+'Immune Clique '+num+' Gene List.txt'\n",
    "    input_genes=readLst(immFile);x2k_results = run_X2K(input_genes,useFile=useFile,file=file)\n",
    "    x2k_tf=pd.DataFrame(x2k_results['X2K']['nodes'])\n",
    "    if len(x2k_tf.index)>0:\n",
    "        nameLst=[]\n",
    "        for name in list(x2k_tf['name']):\n",
    "            name=name.split('_')[0];nameLst.append(name)\n",
    "        x2k_tf['name']=nameLst\n",
    "    return x2k_tf\n",
    "def getTFsNonImmLst(nonImmLst,useFile,file):\n",
    "    output=[]\n",
    "    for nonImm in nonImmLst:\n",
    "        df=getTFs(nonImm,useFile,file);output.append(df)\n",
    "    return output\n",
    "def allLst(lst):\n",
    "    for elem in lst:\n",
    "        if not elem:return False\n",
    "    return True\n",
    "def getGeneFromUniport(geneID):\n",
    "    try:\n",
    "        url='https://www.uniprot.org/uniprot/'+geneID;__r = requests.get(url);page = str(__r.content)\n",
    "        gene=page.split(' -')[0].split('>')[-1]\n",
    "        return gene\n",
    "    except:\n",
    "        return getGeneFromUniport(geneID)\n",
    "            \n",
    "def __masterOmniPathHelper(pathLst,directory,useFile,file,corr,cutoff=20,tfs=True):\n",
    "    for path in tq(pathLst,desc='Paths'):\n",
    "        frst=True;imm = path[0];nonImmLst=path[1:]\n",
    "        x2k_tfImm=getTFs(imm,useFile,file);x2k_tfNonImmLst = getTFsNonImmLst(nonImmLst,useFile,file)\n",
    "        counts = pd.read_excel('Avi Results Counts.xlsx',index_col=0)\n",
    "        removeTFs=list(counts[counts['Number of Cliques']>cutoff].index)\n",
    "        lst,lst2=removeCommonTFs(x2k_tfImm,x2k_tfNonImmLst,removeTFs)\n",
    "        pathName=path.copy();pathName.reverse()\n",
    "        for i in range(len(lst)-1):\n",
    "            source=lst[i];target=lst[i+1]\n",
    "            sourceTFs,targetTFs=fixSourceTargetTFs(source,target,tfs=tfs);df=runOmniPath(sourceTFs,targetTFs)\n",
    "            if type(df)==pd.core.frame.DataFrame:\n",
    "                df['Clique Connection']=str(pathName[i])+' -> '+str(pathName[i+1])\n",
    "                df=checkConsistencyOfTFs(df,corr)\n",
    "                if frst:dfAll=df.copy();frst=False\n",
    "                else:dfAll = pd.concat([dfAll,df],ignore_index=True)\n",
    "        pathName=', '.join(pathName);sourceLst=[];targetLst=[]\n",
    "        if frst:print('Warning: No matches for any of the inputed TFs')\n",
    "        else:\n",
    "            dfAll=addSourcePathways(dfAll);dfAll=keepTFPaths(dfAll)\n",
    "            if len(dfAll.index)>0:dfAll.to_excel(directory+'/'+pathName+'.xlsx')\n",
    "    return 1\n",
    "def checkConsistencyOfTFs(df,corr):\n",
    "    keepLst=[]\n",
    "    for i in df.index:\n",
    "        connect=df.loc[i]['Clique Connection'];cliq1,cliq2=connect.split(' -> ');corVal = corr.loc[cliq1][cliq2]\n",
    "        fits=False\n",
    "        if corVal<0:\n",
    "            if int(df.loc[i]['is_inhibition']):fits=True\n",
    "        else:\n",
    "            if int(df.loc[i]['is_stimulation']):fits=True\n",
    "        if fits:keepLst.append(i)\n",
    "    df2=df.loc[keepLst]\n",
    "    return df2\n",
    "\n",
    "def keepTFPaths(df):\n",
    "    keepLst=[]\n",
    "    for i in df.index:\n",
    "        targ=df.loc[i]['target']\n",
    "        for j in df.index:\n",
    "            if targ == df.loc[j]['source'] and j>i:keepLst.extend([i,j])\n",
    "    keepLst=list(set(keepLst));keepLst.sort();df2=df.loc[keepLst]\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __fixGeneNamesUni(df):\n",
    "    sourceLst=[];targetLst=[]\n",
    "    lst=list(df.columns);lst=[lst[0].replace(\"b'\",'')]+lst[1:];df.columns=lst\n",
    "    genes=list(set(list(df['source'])+list(df['target'])));geneDict={}\n",
    "    for gene in genes:\n",
    "        geneDict[gene]=getGeneFromUniport(gene)\n",
    "    for i in df[\"source\"]:sourceLst.append(geneDict[i])\n",
    "    for i in df[\"target\"]:targetLst.append(geneDict[i])\n",
    "    df[\"source\"]=sourceLst;df[\"target\"]=targetLst\n",
    "    return df\n",
    "def addSourcePathways(df,useLst=['c5.go.bp']):\n",
    "    df=__fixGeneNamesUni(df);fullDict=getFullDict(outputLst=False,useLst=useLst)\n",
    "    fullDict2={};immuneLst= ['T-effector', 'IFNG induced', 'Antigen processing machinery']\n",
    "    for path in everyDict:\n",
    "        if path in immuneLst:\n",
    "            lst=__runGenes(everyDict[path])\n",
    "            for elem in lst:\n",
    "                if elem in fullDict2:fullDict2[elem].append(path)\n",
    "                else:fullDict2[elem]=[path]\n",
    "    blDictGenes={}\n",
    "    for path in fullDict:\n",
    "        lst=fullDict[path]\n",
    "        if len(lst)<100:\n",
    "            for elem in lst:\n",
    "                if elem in blDictGenes:blDictGenes[elem].append(path)\n",
    "                else:blDictGenes[elem]=[path]\n",
    "    kobeGenes = pd.read_excel('Genelist_desert.xlsx',index_col=0)\n",
    "    df2 = pd.read_csv('Pathways4model.csv',index_col=0);df2=df2.dropna()\n",
    "    genes=list(kobeGenes.index);genes = list(set(genes))\n",
    "    blDict, blDict2 = __helpGetBLDict(df2,'MANUAL CATEGORIES ',useGenes=True,genesIn=genes)\n",
    "    blDict, blDict2 = __helpGetBLDict(kobeGenes,'pathway',blDict,blDict2,usePathwayName=False,useGenes=True,genesIn=genes)\n",
    "    for path in everyDict:\n",
    "        lst=__runGenes(everyDict[path]);path=path.replace('-A','/A')\n",
    "        if path in blDict:blDict[path].extend(lst)\n",
    "        else:blDict[path]=lst\n",
    "    blDict2={}\n",
    "    for path in blDict:\n",
    "        lst = blDict[path]\n",
    "        for elem in lst:\n",
    "            if elem in blDict2:blDict2[elem].append(path)\n",
    "            else:blDict2[elem]=[path]\n",
    "    pathLst=[];numLst=[]\n",
    "    for gene in list(df['target']):\n",
    "        if gene in blDict2:\n",
    "            lst=blDict2[gene];num=len(lst)\n",
    "            pathLst.append(lst);numLst.append(num)\n",
    "        else:\n",
    "            pathLst.append([]);numLst.append(0)\n",
    "    df.insert(2,'Pathways with Target',numLst);df.insert(2,'# of Pathways with Target',pathLst);path31Lst=[]\n",
    "    for gene in list(df['source']):\n",
    "        if gene in blDict2:\n",
    "            lst=blDict2[gene];path31Lst.append(lst)\n",
    "        else:path31Lst.append(False)\n",
    "    blDictGenes2={}\n",
    "    for path in fullDict2:\n",
    "        lst=fullDict2[path]\n",
    "        for elem in lst:\n",
    "            if elem in blDictGenes2:blDictGenes2[elem].append(path)\n",
    "            else:blDictGenes2[elem]=[path]\n",
    "    sourceLst=list(df['source']);sourceGenesLst=[]\n",
    "    for elem in sourceLst:\n",
    "        if elem in blDictGenes:sourceGenes=blDictGenes[elem]\n",
    "        else:sourceGenes=[]\n",
    "        sourceGenesLst.append(sourceGenes)\n",
    "    surceLenLst=[]\n",
    "    for elem in sourceGenesLst:surceLenLst.append(len(elem))\n",
    "    df.insert(2,'Pathways with Source',sourceGenesLst);df.insert(2,'# of Pathways with Source',surceLenLst)\n",
    "    df.insert(2,'Source in 31 Special Pathways',path31Lst)\n",
    "    return df\n",
    "def multiInsert(dfIn,lst):\n",
    "    df=dfIn.copy()\n",
    "    for i,name,elem in lst:df.insert(i,name,elem)\n",
    "    return df\n",
    "def __parallelRunAvi(imm,immDf,nonDf,place,useFile=False,file='',outDict={},tfs=True):\n",
    "    try:\n",
    "        val=False;immNum=imm.split('_')[0];immTyp=immNum.split('une')[0]+'une';immNum=immNum.split('une')[-1]\n",
    "        if 'Non' in immTyp:\n",
    "            if immNum in nonDf.columns:\n",
    "                genes=list(nonDf[immNum].dropna());val=True\n",
    "        else:\n",
    "            if immNum in immDf.columns:\n",
    "                genes=list(immDf[immNum].dropna());val=True\n",
    "        if val:\n",
    "            try:\n",
    "                if tfs:\n",
    "                    imm_tf = pd.read_excel('TF Anaylsis/Avi Results/TFs/'+place+' '+imm+'.xlsx',index_col=0)\n",
    "                else:\n",
    "                    imm_tf = pd.read_excel('TF Anaylsis/Avi Results/Kinase/'+place+' '+imm+'.xlsx',index_col=0)\n",
    "            except FileNotFoundError:\n",
    "                imm_results = run_X2K(genes,useFile=useFile,file=file)\n",
    "                if tfs:\n",
    "                    imm_tf=pd.DataFrame(imm_results['X2K']['nodes'])\n",
    "                    imm_tf.to_excel('TF Anaylsis/Avi Results/TFs/'+place+' '+imm+'.xlsx')\n",
    "                else:\n",
    "                    imm_tf=pd.DataFrame(imm_results['KEA'])\n",
    "                    imm_tf.to_excel('TF Anaylsis/Avi Results/Kinase/'+place+' '+imm+'.xlsx')\n",
    "        else:imm_tf=pd.DataFrame()\n",
    "        outDict[imm]=imm_tf\n",
    "        return outDict\n",
    "    except TimeoutError:\n",
    "        return __parallelRunAvi(imm=imm,place=place,immDf=immDf,nonDf=nonDf,useFile=useFile,\n",
    "                                file=file,outDict=outDict,tfs=tfs)\n",
    "    return (immTyp,imm,imm_tf,nonImm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOmniParallel(imm,nonImm,dic,tfs):\n",
    "    imm_tf=dic[imm];non_tf=dic[nonImm]\n",
    "    if len(imm_tf.index)>1 and len(non_tf.index)>1:\n",
    "        sourceTFs,targetTFs=fixSourceTargetTFs(imm_tf,non_tf,tfs);omniRes=runOmniPath(sourceTFs,targetTFs)\n",
    "        if type(omniRes)==pd.core.frame.DataFrame:\n",
    "            if len(omniRes.index)>1:\n",
    "                omniRes['Clique Connection']=nonImm+' -> '+imm;omniRes.columns=['source']+list(omniRes.columns[1:])\n",
    "                omniRes=checkConsistencyOfTFs(omniRes,corr);omniRes=addSourcePathways(omniRes)\n",
    "                return omniRes\n",
    "    return pd.DataFrame()\n",
    "def getCliqueDf(file,immOrNon,ver='v7'):\n",
    "    fName=file.split('\\\\')[-1].replace(', '+ver,'')\n",
    "    lst=fName.split(' N ');fName=','.join([lst[0],' N '+lst[1]])\n",
    "    fName=fName.replace('Clique Overlapping','Overlapping Cliques, '+immOrNon)\n",
    "    df=pd.read_csv('Cliques/'+fName+'.csv',index_col=0)\n",
    "    return df\n",
    "def createCliques(placeLst,version=7,thres=0.6,title='Overlapping Cliques'):\n",
    "    kobeGenes = pd.read_excel('Genelist_desert.xlsx',index_col=0)\n",
    "    df2 = pd.read_csv('Pathways4model.csv',index_col=0);df2=df2.dropna()\n",
    "    useLst = ['c2.cp','c5.go.bp','h.all'];fullDict = getFullDict(outputLst=False,useLst=useLst);dict2={}\n",
    "    for i in df2.index:\n",
    "        if i in fullDict:\n",
    "            lst = fullDict[i];dict2[i]=lst\n",
    "    genes=list(kobeGenes.index)\n",
    "    for col in dict2:\n",
    "        lst = dict2[col];genes.extend(lst)\n",
    "    genes = list(set(genes))\n",
    "    blDict, blDict2 = __helpGetBLDict(df2,'MANUAL CATEGORIES ',useGenes=True,genesIn=genes)\n",
    "    blDict, blDict2 = __helpGetBLDict(kobeGenes,'pathway',blDict,blDict2,usePathwayName=False,useGenes=True,genesIn=genes)\n",
    "    removeLst=[];immuneLst= ['T-effector', 'IFNG induced', 'Antigen processing machinery']\n",
    "    for path in everyDict:\n",
    "        if path in immuneLst:\n",
    "            lst = __runGenes(everyDict[path])\n",
    "            if path in blDict:blDict[path].extend(lst)\n",
    "            else:blDict[path]=lst\n",
    "    immDict2={};nonImmDict2={}\n",
    "    for path in blDict:\n",
    "        lst=blDict[path]\n",
    "        if path in immuneLst:\n",
    "            for elem in lst:immDict2[elem]=path\n",
    "        else:\n",
    "            for elem in lst:nonImmDict2[elem]=path\n",
    "    immSet=set(immDict2.keys());nonSet=set(nonImmDict2.keys());removeLst=[]\n",
    "    for i in immDict2.keys():\n",
    "        if i in nonSet:removeLst.append(i)\n",
    "    for i in removeLst:del immDict2[i]\n",
    "    removeLst=[]\n",
    "    for i in nonImmDict2.keys():\n",
    "        if i in immSet:removeLst.append(i)\n",
    "    for i in removeLst:del nonImmDict2[i]\n",
    "    for place in tq(placeLst,desc='Creating Cliques'):\n",
    "        dfPlace = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        numSamples=len(dfPlace.columns)\n",
    "        titleImm=title+', Immune';titleNon=title+', Non-Immune'\n",
    "        __createCliquesHelper(dfPlace,immDict2,version=version,thres=thres,numSamples=numSamples,title=titleImm,place=place)\n",
    "        __createCliquesHelper(dfPlace,nonImmDict2,version=version,thres=thres,numSamples=numSamples,title=titleNon,place=place)\n",
    "    for place in tq(placeLst,desc='Saving'):\n",
    "        dfPlace = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        numSam=len(dfPlace.columns)\n",
    "        dfImm=pd.read_csv('Cliques/Overlapping Cliques, Immune, '+place+', N = '+str(numSam)+'.csv',index_col=0)\n",
    "        dfNonImm=pd.read_csv('Cliques/Overlapping Cliques, Non-Immune, '+place+', N = '+str(numSam)+'.csv',index_col=0)\n",
    "        dfPlace=dfPlace.T\n",
    "        dfOut,colLst = __helpMergeDfsCliques(dfImm,dfPlace,title='Immune',colLst=[])\n",
    "        dfOut,colLst = __helpMergeDfsCliques(dfNonImm,dfPlace,title='Non Immune',frst=False,colLst=colLst,dfOut=dfOut)\n",
    "        dfOut.columns = colLst;dfOut=dfOut.T;dfOut=__heatDF(dfOut,place=place)[0];dfOut=dfOut.T\n",
    "        dfOut.to_csv('Run BNLearn/Inputs/Clique Overlapping, '+place+' N = '+str(numSam)+', v'+str(version),sep='\\t')\n",
    "    return 1\n",
    "def __createCliquesHelper(dfPlace,blDict2,version,thres,title,numSamples,place):\n",
    "    geneLst = list(blDict2.keys());geneLst=list(set(geneLst));geneLst=__goodGenes(geneLst,dfPlace.index)\n",
    "    dfPlace = dfPlace.loc[geneLst].T;corrP=dfPlace.corr(method='pearson');corrS=dfPlace.corr(method='spearman')\n",
    "    corr = (corrP+corrS)/2;keep = corr>= thres;keepLst=[]\n",
    "    for i in keep.index:\n",
    "        ser = keep[i][keep[i]]\n",
    "        for j in ser.index:\n",
    "            if i!=j and not (i,j) in keepLst:keepLst.append((i,j))\n",
    "    G = nx.Graph();G.add_edges_from(keepLst);out = nx.find_cliques(G);ls = list(out);n=0;graphDict={};meanDict={}\n",
    "    for l in ls:\n",
    "        graphDict[n]=l;df2=dfPlace[l].T;mean=df2.mean();meanDict[n]=mean;n+=1\n",
    "    inputs=geneLst\n",
    "    out = Parallel(n_jobs=7)(delayed(parallelGraphDict)(gene,graphDict,dfPlace,meanDict,thres) for gene in inputs)\n",
    "    finalDict={}\n",
    "    for n in out[0][1]:finalDict[n]=[]\n",
    "    for gene, dic in out:\n",
    "        for n in dic:\n",
    "            if dic[n]:finalDict[n].append(gene)\n",
    "    finalDict2={}\n",
    "    for n in out[0][1]:finalDict2[n]=[]\n",
    "    for gene,dic in out:\n",
    "        for n in dic:\n",
    "            if dic[n] and not gene in finalDict2[n]:finalDict2[n].append(gene)\n",
    "    finalDict3={}\n",
    "    for k in sorted(finalDict2, key=lambda k: len(finalDict2[k]), reverse=True):\n",
    "        finalDict3[n] = finalDict2[k];n+=1\n",
    "    noLst=[];finalDict2={}\n",
    "    for n in finalDict3:\n",
    "        ls=finalDict3[n];ls2=[]\n",
    "        for elem in ls:\n",
    "            if not elem in noLst:ls2.append(elem)\n",
    "        finalDict2[n]=ls2;noLst.extend(ls2)\n",
    "    finalDict={};m=0\n",
    "    for n in finalDict2:\n",
    "        if len(finalDict2[n])>0:\n",
    "            finalDict[m]=finalDict2[n];m+=1\n",
    "    maxx=-1\n",
    "    for n in finalDict:\n",
    "        ls = finalDict[n]\n",
    "        if len(ls)>maxx:maxx=len(ls)\n",
    "    for n in finalDict:\n",
    "        ls=finalDict[n]\n",
    "        for i in range(maxx-len(ls)):ls.append('')\n",
    "        finalDict[n]=ls\n",
    "    title2=title+', '+place+', N = '+str(numSamples)\n",
    "    df = pd.DataFrame.from_dict(finalDict) ;df.to_csv(title2+'.csv')\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postOmniCleanup(df):\n",
    "    dict2={};immuneLst= ['T-effector', 'IFNG induced', 'Antigen processing machinery']\n",
    "    for path in everyDict:\n",
    "        if path in immuneLst:\n",
    "            lst=__runGenes(everyDict[path])\n",
    "            for elem in lst:\n",
    "                if elem in dict2:dict2[elem].append(path)\n",
    "                else:dict2[elem]=[path]\n",
    "    lst=[]\n",
    "    for i in df.index:\n",
    "        j = df.loc[i]['target']\n",
    "        if j in dict2:lst.append(i)\n",
    "    df=df.loc[lst];dropLst=[]\n",
    "    for n in range(len(df.index)):\n",
    "        i = df.index[n];ser=df.loc[i]\n",
    "        for m in range(n+1,len(df.index)):\n",
    "            j=df.index[m];ser2=df.loc[j]\n",
    "            if ser.equals(ser2):dropLst.append(ser2)\n",
    "    df=df.drop(dropLst)\n",
    "    return df\n",
    "def createOmniInputFile(outDict,pairLst,nonDf,place,corVal,fullDict,thres,includeNumKinase=False):\n",
    "    blDict2=getBlDict2(fullDict,removeExtra=True)\n",
    "    immDict={};nonDict={};immLst=[];nonLst=[]\n",
    "    immFiles=glob.glob('TF Anaylsis/Avi Results/Kinase/*'+place+'* Immune*')\n",
    "    if len(immFiles)==0:\n",
    "        raise\n",
    "    for file in immFiles:\n",
    "        fileName=file.split('\\\\')[-1].split('.')[0]\n",
    "        dfImm=pd.read_excel(file,index_col=0)\n",
    "        if len(dfImm.index)>0:\n",
    "            immDict[fileName]=(list(dfImm['name']),list(dfImm['pvalue']));immLst.extend(list(dfImm['name']))\n",
    "    nonFiles=glob.glob('TF Anaylsis/Avi Results/Kinase/*'+place+'*NonImm*')\n",
    "    for file in nonFiles:\n",
    "        fileName=file.split('\\\\')[-1].split('.')[0];dfNon=pd.read_excel(file,index_col=0)\n",
    "        if len(dfNon.index)>0:\n",
    "            nonDict[fileName]=(list(dfNon['name']),list(dfNon['pvalue']));nonLst.extend(list(dfNon['name']))\n",
    "    immSet=set(immLst);nonSet=set(nonLst);both=list(immSet.intersection(nonSet))\n",
    "    immUnique=[i for i in immSet if i not in both];nonUnique=[i for i in nonSet if i not in both]\n",
    "    outImmDict={}\n",
    "    for elem in immLst:\n",
    "        if elem in outImmDict:outImmDict[elem]+=1\n",
    "        else:outImmDict[elem]=1\n",
    "    outNonDict={}\n",
    "    for elem in nonLst:\n",
    "        if elem in outNonDict:outNonDict[elem]+=1\n",
    "        else:outNonDict[elem]=1\n",
    "    inputs=pairLst\n",
    "    dfLst= Parallel(n_jobs=7)(delayed(__parallelOmniInput)(outDict=outDict,nonImm=nonImm,imm=imm,fullDict=fullDict,\n",
    "                                                           nonDf=nonDf,includeNumKinase=includeNumKinase,thres=thres,\n",
    "                                                           outImmDict=outImmDict,outNonDict=outNonDict,blDict=blDict2) \n",
    "                              for nonImm,imm in inputs)\n",
    "    if len(dfLst)>0:\n",
    "        dfAll = pd.concat(dfLst,ignore_index=True)\n",
    "        lst=place.split(' ')\n",
    "        if 'Kidney' in place or 'Head' in place:place = ' '.join([lst[0],lst[1],lst[2]])\n",
    "        else:\n",
    "            if 'Brain' in place:place=lst[0]\n",
    "            else:place=' '.join([lst[0],lst[1]])\n",
    "        title='TF Anaylsis/Avi Results/Omni Inputs/'+place\n",
    "        title+=', OmniPath Input, NonImm-Imm Connections Cor '+str(corVal)+'.xlsx'\n",
    "        dfAll.to_excel(title)\n",
    "    return 1\n",
    "def __parallelOmniInput(outDict,nonImm,imm,nonDf,outImmDict,outNonDict,blDict,includeNumKinase,fullDict,thres):\n",
    "    immKin = outDict[imm];nonKin = outDict[nonImm]\n",
    "    print(immKin,nonKin);tr=ty\n",
    "    if len(immKin.columns)>0 and len(nonKin.columns)>0:\n",
    "        immKin=immKin[immKin['pvalue']<=thres];nonKin=nonKin[nonKin['pvalue']<=thres]\n",
    "    if len(immKin.index)>0 and len(nonKin.index)>0:\n",
    "        nonImmNum=nonImm.split('_')[0].split('ne')[-1];targetKin=set(immKin['name']);sourceKin=set(nonKin['name'])\n",
    "        targetLst = [g for g in targetKin if g not in sourceKin];sourceLst = [g for g in sourceKin if g not in targetKin]\n",
    "        sourceGenes=list(set(nonDf[nonImmNum].dropna()))\n",
    "        output =  omniInputHelper(targetLst,sourceLst,outImmDict,outNonDict,sourceGenes,blDict,fullDict=fullDict)\n",
    "        numInTarg,numInSource,sourceGLst,pathLstTarg,pathLstSource= output\n",
    "        df=pd.DataFrame()\n",
    "        df['Source NonImmune Genes']=sourceGLst\n",
    "        df['Source NonImmune Kinases']=sourceLst;df['Source Kinases Pathways']=pathLstSource\n",
    "        if includeNumKinase:\n",
    "            df['Source NonImmune Kinase Likely Immune']=numInSource\n",
    "        df['Target Immune Kinases']=targetLst;df['Target Kinases Pathways']=pathLstTarg\n",
    "        if includeNumKinase:\n",
    "            df['Target Immune Kinase Likely Immune']=numInTarg\n",
    "        df['Connection']=nonImm+' -> '+imm\n",
    "    else: df =pd.DataFrame()\n",
    "    return df\n",
    "\n",
    "def omniInputHelper(targetLst,sourceLst,outImmDict,outNonDict,sourceGenes,blDict,fullDict):\n",
    "    numInTarg,sourceGLst,pathLstTarg = omniInputHelper2(targetLst,outImmDict,outNonDict,sourceGenes,\n",
    "                                                        sourceG=True,blDict=blDict,fullDict=fullDict)\n",
    "    numInSource,_,pathLstSource = omniInputHelper2(sourceLst,outNonDict,outImmDict,sourceGenes,\n",
    "                                                   sourceG=False,blDict=blDict,fullDict=fullDict)\n",
    "    if len(targetLst)>len(sourceLst):\n",
    "        a=targetLst;b=(sourceLst,numInSource,[],pathLstSource)\n",
    "    else:\n",
    "        a=sourceLst;b=(targetLst,numInTarg,sourceGLst,pathLstTarg)\n",
    "    lst,numInImm,gLst,pathLst=b\n",
    "    for i in range(len(a)-len(b[0])):\n",
    "        numInImm.append(True)\n",
    "        gLst.append(sourceGenes);lst.append('')\n",
    "        pathLst.append([])\n",
    "    return numInTarg,numInSource,sourceGLst,pathLstTarg,pathLstSource\n",
    "\n",
    "def getImmuneLst(ciber=False,union=True):\n",
    "    if ciber:\n",
    "        ciberGenes=pd.read_csv('Cibersort Immune.txt',index_col=0,sep='\\t')\n",
    "        immLst=set(list(ciberGenes.index))\n",
    "    else:\n",
    "        iris=pd.read_csv('IRIS.csv',index_col=0);immLst=list(iris['name'])\n",
    "        immunone=pd.read_csv('ImmunomeDB.csv',index_col=0);immLst.extend(list(immunone['name']))\n",
    "        immport=pd.read_csv('Immport.csv',index_col=0);immLst.extend(list(immport['name']))\n",
    "        if union:\n",
    "            ciberGenes=pd.read_csv('Cibersort Immune.txt',index_col=0,sep='\\t')\n",
    "            immLst.extend(list(set(list(ciberGenes.index))))\n",
    "    return immLst\n",
    "def omniInputHelper2(lst,outDict1,outDict2,sourceGenes,sourceG,blDict,fullDict):\n",
    "    immLst=getImmuneLst()\n",
    "    sourceGLst=[];numIn1=[];pathLst=[]\n",
    "    for elem in lst:\n",
    "        if elem in immLst:\n",
    "            numIn1.append(True)\n",
    "        else:\n",
    "            numIn1.append(False)\n",
    "        if sourceG:\n",
    "            sourceGLst.append(sourceGenes)\n",
    "        if elem in blDict:\n",
    "            pathLst.append(blDict[elem])\n",
    "        else:\n",
    "            pathLst.append([])\n",
    "    pathLst=onlyKeepImportantPaths(pathLst,fullDict=fullDict)\n",
    "    return numIn1,sourceGLst,pathLst\n",
    "def getBlDict2(Dict,removeExtra=False):\n",
    "    blDict2={}\n",
    "    for path in Dict:\n",
    "        continuu=True\n",
    "        if removeExtra:\n",
    "            if 'ST' in path or 'PID' in path or 'BIO' in path:\n",
    "                continuu=False\n",
    "        if continuu:\n",
    "            lst=Dict[path]\n",
    "            for elem in lst:\n",
    "                if elem in blDict2:\n",
    "                    blDict2[elem].append(path)\n",
    "                else:\n",
    "                    blDict2[elem]=[path]\n",
    "    return blDict2\n",
    "\n",
    "def onlyKeepImportantPaths(pathLst,fullDict,lstLen=90):\n",
    "    outLst=[]\n",
    "    for lst in pathLst:\n",
    "        outPaths=onlyKeepImportantPathsHelper(lst,fullDict,lstLen)\n",
    "        outPaths=list(set(outPaths))\n",
    "        outLst.append(outPaths)\n",
    "    return outLst\n",
    "def onlyKeepImportantPathsHelper(lst,fullDict,lstLen):\n",
    "    outPaths=[]\n",
    "    for path2 in lst:\n",
    "        genes2=fullDict[path2];genes2=set(genes2)\n",
    "        if len(genes2)<lstLen:\n",
    "            continuu=True\n",
    "            for path1 in lst:\n",
    "                genes1=fullDict[path1];genes1=set(genes1)\n",
    "                if path2 != path1 and len(genes1)>lstLen:\n",
    "                    if path1 not in outPaths:\n",
    "                        outPaths.append(path1)\n",
    "                    count=len(genes1.intersection(genes2))\n",
    "                    total = count/len(genes2)\n",
    "                    if total > 0.6:\n",
    "                        continuu=False\n",
    "                else:\n",
    "                    continuu=False\n",
    "            if continuu:\n",
    "                outPaths.append(path2)\n",
    "    lstLen=lstLen-10\n",
    "    if len(outPaths)<4 and lstLen>0:\n",
    "        outPaths=onlyKeepImportantPathsHelper(lst,fullDict,lstLen)\n",
    "    return outPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helpPlotClusterNonImm(i,df,path,version,metric,size,show=True,addTitle='',spltNum=1,spltLst=[],\n",
    "                          allDf=False,Colors=(),addTitle2='',legendTitle='Pathway'):\n",
    "    if len(df.columns)>0:\n",
    "        if spltNum<1:\n",
    "            spltNum=1\n",
    "        out='Graphs'\n",
    "        if not os.path.exists(out):os.makedirs(out)\n",
    "        out+='/'\n",
    "        sizeY = max(7 - (len(df.columns)/20),1)\n",
    "        annotSize= max(4 - len(df.columns)/20,1)\n",
    "        if spltNum==1 and len(df.columns)>2:\n",
    "            row_cluster=True;col_cluster=True\n",
    "        else:\n",
    "            row_cluster=False;col_cluster=False\n",
    "        if allDf:\n",
    "            dfColors1,colors1Dict,dfColors2,colors2Dict=Colors\n",
    "            colorLst1=[];colorLst2=[]\n",
    "            for path in dfColors1:\n",
    "                colorLst1.append(colors1Dict[path])\n",
    "            for path in dfColors2:\n",
    "                colorLst2.append(colors2Dict[path])\n",
    "            colorLst=[colorLst1,colorLst2]\n",
    "            colors1Dict.update(colors2Dict)\n",
    "            \n",
    "            cg = sb.clustermap(df,vmax=1,cmap=cmapSpecial,vmin=-1,xticklabels=0,yticklabels=1,\n",
    "                               row_cluster=row_cluster,col_cluster=col_cluster,col_colors=colorLst,\n",
    "                               figsize=size,metric=metric,cbar_pos=(0, 0.5, 0.05, 0.15))\n",
    "            sizeY=2\n",
    "            for x,y in zip(colors1Dict.keys(),colors1Dict.values()):\n",
    "                cg.ax_heatmap.plot(0, 0, color=y, label=x, linewidth=6, solid_capstyle=\"butt\")\n",
    "            cg.ax_heatmap.legend(loc=(-0.5,0), title=legendTitle)\n",
    "        else:   \n",
    "            cg = sb.clustermap(df,vmax=1,cmap=cmapSpecial,vmin=-1,xticklabels=1,yticklabels=1,\n",
    "                               row_cluster=row_cluster,col_cluster=col_cluster,\n",
    "                               figsize=size,metric=metric,annot=True,annot_kws={\"size\":annotSize})\n",
    "        if sizeY < 2:\n",
    "            plt.close()\n",
    "            if spltNum==1:\n",
    "                row = cg.dendrogram_row.reordered_ind;col = cg.dendrogram_col.reordered_ind\n",
    "                df = __setCluster(df,row,col)\n",
    "            else:\n",
    "                spltNum-=1\n",
    "            splt=int(len(df.columns)/2)\n",
    "            df1Cols=df.columns[:splt];df2Cols=df.columns[:splt]\n",
    "            df1= df[df1Cols];df2=df[df2Cols]\n",
    "            Colors1=Colors[:splt];Colors2=Colors[splt:]\n",
    "            spltNum,spltLst=helpPlotClusterNonImm(i,df1,path,version,metric,addTitle=' Part '+str(spltNum),\n",
    "                                                  spltNum=spltNum+1,show=show,spltLst=spltLst,allDf=allDf,Colors=Colors1)\n",
    "            spltNum,spltLst=helpPlotClusterNonImm(i,df2,path,version,metric,addTitle=' Part '+str(spltNum),\n",
    "                                                  spltNum=spltNum+1,show=show,spltLst=spltLst,allDf=allDf,Colors=Colors2)\n",
    "            return spltNum,spltLst\n",
    "        else:\n",
    "            title=i+' to Immune Genes, Correlation, v'+str(version)+', '+metric+addTitle2+addTitle\n",
    "            cg.fig.suptitle(title,size=15)\n",
    "            plt.setp(cg.ax_heatmap.get_yticklabels(),va='bottom',size=7)\n",
    "            plt.setp(cg.ax_heatmap.get_xticklabels(),ha='right',size=sizeY,rotation='45')\n",
    "            cg.ax_heatmap.set_xlabel('Non-Immune Immune Pairings',size=12);cg.ax_heatmap.set_ylabel('Cancer Areas',size=12)\n",
    "            cg.ax_row_dendrogram.set_visible(False);cg.ax_col_dendrogram.set_visible(False)\n",
    "            title=out+title;\n",
    "            if not allDf:cg.ax_heatmap.set_title(i+', '+path,size=7)\n",
    "            plt.savefig(title+'.pdf',bbox_inches = \"tight\",dpi=170);spltLst.append(title+'.pdf')\n",
    "            if show:plt.show()\n",
    "            else:plt.close()\n",
    "    return spltNum+1,spltLst\n",
    "\n",
    "def plotCorrImmuneNon(place,version,size=(9,6),metric='cosine'):\n",
    "    blDict,blDict2=__getBLDict(False)\n",
    "    immuneGenes=[];nonGenes=[]\n",
    "    immuneLst=['T-effector','IFNG induced','Antigen processing machinery']\n",
    "    for path in blDict:\n",
    "        lst=blDict[path]\n",
    "        if path in immuneLst:\n",
    "            immuneGenes.extend(lst)\n",
    "        else:\n",
    "            nonGenes.extend(lst)\n",
    "    immuneGenes=list(set(immuneGenes))\n",
    "    nonGenes=list(set(nonGenes))\n",
    "    df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "    df = __heatDF(df,place,insert=0,zscore=True)[0];df=__pureDf(df)\n",
    "    immGenesP=__goodGenes(immuneGenes,df.index);nonGenesP=__goodGenes(nonGenes,df.index)\n",
    "    immGenesP.extend(['Purity Scores','Heat Scores'])\n",
    "    genes=list(set(immGenesP+nonGenesP))\n",
    "    df.index.name='Non-Immune Genes';df=df.loc[genes];df=df.T\n",
    "    corP=df.corr(method='pearson');corS=df.corr(method='spearman')\n",
    "    cor=(corP+corS)/2;cor=cor.loc[immGenesP][nonGenesP];cor.index.name='Immune Genes'\n",
    "    out='Graphs/'+place\n",
    "    if not os.path.exists(out):os.makedirs(out)\n",
    "    out+='/'\n",
    "    cg = sb.clustermap(cor,vmax=1,cmap=cmapSpecial,vmin=-1,xticklabels=0,yticklabels=1,\n",
    "                       figsize=size,metric=metric)\n",
    "    title=place+', v'+str(version)+', NonImmune to Immune Correlation, '+metric\n",
    "    cg.fig.suptitle(title,size=12)\n",
    "    plt.setp(cg.ax_heatmap.get_yticklabels(),va='bottom',size=10,rotation='0')\n",
    "    cg.ax_heatmap.set_xlabel('Non-Immune Genes',size=15);cg.ax_heatmap.set_ylabel('Immune Genes',size=15)\n",
    "    col = cg.dendrogram_col.reordered_ind;row= list(range(len(cor.index)));cor2=__setCluster(cor,row,col)\n",
    "    lst=list(cor2.columns);lstTitle='Order of Non-Immune Genes for '+title\n",
    "    saveLst(lst,out+lstTitle+'.txt');title=out+title\n",
    "    plt.savefig(title+'.png',bbox_inches = \"tight\",dpi=170);plt.close()\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getBLDict(useSuperSet=True):\n",
    "    kobeGenes = pd.read_excel('Genelist_desert.xlsx',index_col=0)\n",
    "    df2 = pd.read_csv('Pathways4model.csv',index_col=0);df2=df2.dropna()\n",
    "    useLst = ['c2.cp','c5.go.bp','h.all'];fullDict = getFullDict(outputLst=False,useLst=useLst);dict2={};dict2Out={}\n",
    "    for i in df2.index:\n",
    "        if i in fullDict:\n",
    "            lst = fullDict[i];dict2[i]=lst\n",
    "            for elem in lst:\n",
    "                dict2Out[elem]=i\n",
    "    genes=list(kobeGenes.index)\n",
    "    for col in dict2:\n",
    "        lst = dict2[col];genes.extend(lst)\n",
    "    genes = list(set(genes))\n",
    "    blDict, blDict2 = __helpGetBLDict(df2,'MANUAL CATEGORIES ',useGenes=True,genesIn=genes)\n",
    "    blDict, blDict2 = __helpGetBLDict(kobeGenes,'pathway',blDict,blDict2,usePathwayName=False,useGenes=True,genesIn=genes)\n",
    "    if useSuperSet:\n",
    "        for path in everyDict:\n",
    "            lst=list(set(__runGenes(everyDict[path])))\n",
    "            path=path.replace('-A','/A')\n",
    "            if path in blDict:\n",
    "                lst0=blDict[path];lst0.extend(lst);lst=list(set(lst0))\n",
    "            blDict[path]=lst\n",
    "        blDict2={}\n",
    "        for path in blDict:\n",
    "            lst=blDict[path]\n",
    "            for elem in lst:\n",
    "                if elem in blDict2:blDict2[elem].append(path)\n",
    "                else:blDict2[elem]=[path]\n",
    "    return blDict,blDict2,dict2Out\n",
    "def plotImmVsHeat(place,version):\n",
    "    df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "    df = __heatDF(df,place,insert=0,zscore=True)[0];df=__pureDf(df)\n",
    "    immGenesP=__goodGenes(immuneGenes,df.index);immGenesP.extend(['Purity Scores','Heat Scores'])\n",
    "    dfImm=df.loc[immGenesP];dfImm=dfImm.T\n",
    "    titleLst=[]\n",
    "    for gene in dfImm.columns:\n",
    "        if gene !='Purity Scores' and gene!='Heat Scores':\n",
    "            g1=dfImm[gene];g2=dfImm['Heat Scores']\n",
    "            plt.plot(g1,g2,'o');plt.xlabel('Heat Score (Z-Score)');plt.ylabel(gene)\n",
    "            title=gene+' vs Heat, '+place+' v8';plt.title(title)\n",
    "            plt.savefig('Graphs/'+title+'.pdf',bbox_inches = \"tight\",dpi=300);plt.close()\n",
    "            titleLst.append('Graphs/'+title+'.pdf')\n",
    "    name='Graphs/'+place+', v'+str(version)+', Immune Genes vs Heat Scatter Plots'\n",
    "    __mergePDFs(titleLst,name,erase=True)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPathInOmni(sourceG,targetG,maxSteps,pathsWanted):\n",
    "    return findPathInOmniHelper(sourceG,targetG,maxSteps,step=0,lst=[],doneLst=[],found=0,pathsWanted=pathsWanted)\n",
    "def findPathInOmniHelper(sourceG,targetG,maxSteps=4,step=0,lst=[],doneLst=[],found=0,pathsWanted=1):\n",
    "    if step > maxSteps:\n",
    "        return False,[],targetG\n",
    "    else:\n",
    "        try:\n",
    "            OmniPathURL='https://omnipathdb.org/interactions/?genesymbols=1&sources='+sourceG\n",
    "            OmniPathURL+='&fields=sources,references'\n",
    "            __r = requests.get(OmniPathURL);page = str(__r.content);df=__OmniPathHelperFunc(page)\n",
    "            \n",
    "            step+=1\n",
    "            doneLst.append(sourceG)\n",
    "            if type(df)==pd.core.frame.DataFrame:\n",
    "                if targetG in list(df['target_genesymbol']):\n",
    "                    connect = df[df['target_genesymbol']==targetG]\n",
    "                    lst.append(connect)\n",
    "                    return True,lst,targetG\n",
    "                else:\n",
    "                    outLst=[]\n",
    "                    if step <= maxSteps:\n",
    "                        for row in df.index:\n",
    "                            lst2=lst.copy();ser=df.loc[row];lst2.append(ser)\n",
    "                            gene = df.loc[row]['target_genesymbol']\n",
    "                            if not gene in doneLst:\n",
    "                                val, out,g = findPathInOmniHelper(gene,targetG,maxSteps=maxSteps,step=step,lst=lst2,\n",
    "                                                                  doneLst=doneLst,found=found,pathsWanted=pathsWanted)\n",
    "                                if val:\n",
    "                                    found+=1\n",
    "                                    outLst.append(out)\n",
    "                                    if found>pathsWanted:\n",
    "                                        break\n",
    "                    if len(outLst)>0:\n",
    "                        return True,outLst,targetG\n",
    "                    else:\n",
    "                        return False,outLst,targetG\n",
    "            else:\n",
    "                return False,[],targetG\n",
    "        except:\n",
    "            findPathInOmniHelper(sourceG,targetG,maxSteps,step,lst,doneLst,found,pathsWanted)\n",
    "def findAndSavePaths(sourceKin,targetKin,maxSteps,pathsWanted,place,connect):\n",
    "    directory='TF Anaylsis/Outputs/OmniPaths/'+str(maxSteps+1)+' Steps'\n",
    "    if not os.path.exists(directory):os.makedirs(directory)\n",
    "    directory+='/'+place\n",
    "    if not os.path.exists(directory):os.makedirs(directory)\n",
    "    outDict={}\n",
    "    for sourceG in tq(sourceKin,desc=connect):\n",
    "        inputs=targetKin\n",
    "        out = Parallel(n_jobs=10)(delayed(findPathInOmni)(sourceG,targetG,maxSteps=maxSteps,\n",
    "                                                          pathsWanted=pathsWanted) for targetG in inputs)\n",
    "        for tup in out:\n",
    "            if tup:\n",
    "                val,path,g = tup\n",
    "                if val:\n",
    "                    df=recurGetSer(path)\n",
    "                    outDict[sourceG+' '+g]=df\n",
    "    for pair in outDict:\n",
    "        dfAll = outDict[pair]\n",
    "        name=directory+'/'+pair+' '+connect+'.xlsx'\n",
    "        name=name.replace(' -> ',' ')\n",
    "        dfAll.to_excel(name)\n",
    "    return 1\n",
    "def parallelFindAndSaveOmni(df,connect,maxSteps,pathsWanted,place):\n",
    "    dfCliq=df[df['Connection']==connect]\n",
    "    dfCliqSource = dfCliq[dfCliq['Source NonImmune Kinase Likely Immune']==False]\n",
    "    dfCliqTarg = dfCliq[dfCliq['Target Immune Kinase Likely Immune']]\n",
    "    sourceKin = list(dfCliqSource['Source NonImmune Kinases'].dropna())\n",
    "    targetKin = list(dfCliqTarg['Target Immune Kinases'].dropna())\n",
    "    if len(sourceKin)>0 and len(targetKin)>0:\n",
    "        findAndSavePaths(sourceKin,targetKin,maxSteps,pathsWanted,place,connect)\n",
    "    return 1\n",
    "\n",
    "def recurGetSer(path,done=True):\n",
    "    outPut=[]\n",
    "    for elem in path:\n",
    "        if type(elem) is list:\n",
    "            out2 = recurGetSer(elem,False)\n",
    "            outPut.extend(out2)\n",
    "        else:\n",
    "            if type(elem) is pd.core.series.Series:\n",
    "                elem=pd.DataFrame(elem).T\n",
    "            if \"b'source\" in elem.columns and \"target\" in elem.columns:\n",
    "                elem=elem.drop(columns=[\"b'source\",\"target\"])\n",
    "            outPut.append(elem)\n",
    "    if done:\n",
    "        df = pd.concat(outPut,ignore_index=True)\n",
    "        return df\n",
    "    else:\n",
    "        return outPut\n",
    "    \n",
    "def getImmandNonDict():\n",
    "    blDict0,blDict20,dict31=__getBLDict(False);immuneGenes=[];nonGenes=[]\n",
    "    immuneLst=['T-effector','IFNG induced','Antigen processing machinery']\n",
    "    notLst=['FGFR3', 'ACVR1', 'PCSK9', 'ACAT1', 'CISD1'];blDict={};blDict2={}\n",
    "    for path in blDict0:\n",
    "        lst=list(set(blDict0[path]))\n",
    "        if not path in notLst:\n",
    "            blDict[path] = lst\n",
    "            for elem in lst:\n",
    "                if elem in blDict2:blDict2[elem].append(path)\n",
    "                else:blDict2[elem]=[path]\n",
    "    nonGenesDict={};immGenesDict={}\n",
    "    for path in blDict:\n",
    "        lst=blDict[path]\n",
    "        if path in immuneLst:\n",
    "            immuneGenes.extend(lst)\n",
    "            for elem in lst:\n",
    "                immGenesDict[elem]=path\n",
    "        else:\n",
    "            nonGenes.extend(lst)\n",
    "            for elem in lst:\n",
    "                nonGenesDict[elem]=path\n",
    "    immuneGenes=list(set(immuneGenes));nonGenes=list(set(nonGenes))\n",
    "    return immGenesDict,nonGenesDict,immuneGenes,nonGenes\n",
    "\n",
    "def plotImmuneNonGenes(plotNonImmCorr=False,plotAll=False,makeBN=False,version=7,size=(12,8),metric='cosine',numCancers=4,\n",
    "                       negThres=-0.2,placeLst=[],placeLstBN=[],bnTitle='Kobe Genes',panCancer=True,onlyKobe=False):\n",
    "    immGenesDict,nonGenesDict,immuneGenes,nonGenes = getImmandNonDict();dfLst=[];immuneGenesNameDict={}\n",
    "    kobeGenes = pd.read_excel('Genelist_desert.xlsx',index_col=0);kobeGenes=list(kobeGenes.index)\n",
    "    immuneGenesNameDict['Purity Scores']='Puirty Scores';immuneGenesNameDict['Heat Scores']='Heat Scores'\n",
    "    for imm in immuneGenes:\n",
    "        path=immGenesDict[imm].split(' ')[0];immuneGenesNameDict[imm]=imm+'_'+path\n",
    "    for place in tq(placeLst,desc='dfLst'):\n",
    "        df = pd.read_csv('Purity/TPM/v'+str(version)+'/TCGA_'+place+'_tpm.tsv',index_col=0,sep='\\t')\n",
    "        df = __heatDF(df,place,insert=0,zscore=True)[0];df=__pureDf(df)\n",
    "        immGenesP=__goodGenes(immuneGenes,df.index);nonGenesP=__goodGenes(nonGenes,df.index)\n",
    "        immGenesP.extend(['Purity Scores','Heat Scores']);genes=list(set(immGenesP+nonGenesP))\n",
    "        df.index.name='Non-Immune Genes';df=df.loc[genes];df=df.T\n",
    "        corP=df.corr(method='pearson');corS=df.corr(method='spearman')\n",
    "        cor=(corP+corS)/2;cor=cor.loc[immGenesP][nonGenesP];cor.index.name='Immune Genes'\n",
    "        dfLst.append((place,cor))\n",
    "    frst=True\n",
    "    for place,df in dfLst:\n",
    "        if frst:\n",
    "            immGenes=list(df.index);nonGenes=list(df.columns);frst=False\n",
    "        else:\n",
    "            immGenes=__goodGenes(immGenes,df.index);nonGenes=__goodGenes(nonGenes,df.columns)\n",
    "    if plotNonImmCorr:\n",
    "        total=0\n",
    "        for i in tq(nonGenes,desc='Plotting'):\n",
    "        #def _parallelPlotImmNonCorr(i,dfLst,immGenes)\n",
    "            corDict={};geneOutLst=[];dfLst2=[]\n",
    "            for place,df in dfLst:\n",
    "                df=df.T;ser=list(df.loc[i][immGenes]);corDict[place]=ser\n",
    "            nameLst=[]\n",
    "            for imm in immGenes:\n",
    "                name=immuneGenesNameDict[imm];nameLst.append(name)\n",
    "            df = pd.DataFrame.from_dict(corDict, orient='index',columns=nameLst)\n",
    "            df.index.name='Cancer Area';df=df.T;df.index.name='Immune Genes';df=df.T\n",
    "            negCorDf=df[df<=negThres];keepLst=[];n=0\n",
    "            for col in negCorDf.columns:\n",
    "                numNeg=np.count_nonzero(~np.isnan(negCorDf[col]))\n",
    "                if numNeg >= len(negCorDf.index)/4:n+=1\n",
    "            if n >= numCancers: continuu=True\n",
    "            else: continuu=False\n",
    "            if continuu:\n",
    "                path = nonGenesDict[i]\n",
    "                pathTitle=i+' '+path;pathTitle=pathTitle.replace('/','-')\n",
    "                if i in dict31:\n",
    "                    path+=', '+dict31[i]\n",
    "                path=path.replace('/','-')\n",
    "                spltNum,spltLst=helpPlotClusterNonImm(i,df,path,size,version,metric,show=False,spltLst=[],spltNum=0)\n",
    "                if spltNum > 2:\n",
    "                    name=spltLst[0].replace(' Part 1','').replace('.pdf','')\n",
    "                    __mergePDFs(spltLst,name,erase=True);spltLst=[name+'.pdf']\n",
    "                geneOutLst.extend(spltLst);path=path.replace('/','-')\n",
    "                name='Graphs/'+pathTitle+', to Imm Genes, v7, cosine, Neg Corr '+str(negThres)+' in Half Cancer Areas in '\n",
    "                name+=str(numCancers)+' Imm Genes'\n",
    "                __mergePDFs(geneOutLst,name,erase=True)\n",
    "                total+=1\n",
    "    if plotAll or makeBN:\n",
    "        dfLst2=[]\n",
    "        for i in tq(nonGenes,desc='Filtering Genes'):\n",
    "        #def _parallelPlotImmNonCorr(i,dfLst,immGenes)\n",
    "            corDict={};geneOutLst=[]\n",
    "            for place,df in dfLst:\n",
    "                df=df.T;ser=list(df.loc[i][immGenes]);corDict[place]=ser\n",
    "            nameLst=[]\n",
    "            for imm in immGenes:\n",
    "                name=immuneGenesNameDict[imm]\n",
    "                nameLst.append(name)\n",
    "            df = pd.DataFrame.from_dict(corDict, orient='index',columns=immGenes)\n",
    "            df.index.name='Cancer Area';df=df.T;df.index.name='Immune Genes';df=df.T\n",
    "            negCorDf=df[df<=negThres];keepLst=[];n=0\n",
    "            for col in negCorDf.columns:\n",
    "                numNeg=np.count_nonzero(~np.isnan(negCorDf[col]))\n",
    "                if numNeg >= len(negCorDf.index)/4:n+=1\n",
    "            if n >= numCancers:\n",
    "                dfLst2.append((i,df))\n",
    "            #else:\n",
    "            #    if onlyKobe:\n",
    "            #        dfLst2.append((i,df))\n",
    "        if makeBN:\n",
    "            for tpy in tq(set(immGenesDict.values()),desc='Making BN Files'):\n",
    "                bnTitle2 = bnTitle+' '+tpy\n",
    "                genesIn=[]\n",
    "                for non, df in dfLst2:\n",
    "                    #if nonGenesDict[non]=='Fatty acid':\n",
    "                    genesIn.append(non)\n",
    "                for col in df.columns:\n",
    "                    if not 'Scores' in col and immGenesDict[col]==tpy:\n",
    "                        genesIn.append(col)\n",
    "                genesIn=list(set(genesIn))\n",
    "                \n",
    "                setupBNLearnGenes(placeLstBN,runVLst=[version],panCancer=panCancer,onlyKobeGenes=False,genesIn=genesIn,\n",
    "                                  tqOn=False,areaTitle=bnTitle2)\n",
    "        if plotAll:\n",
    "            seenImmLst=[];seenNonLst=[]\n",
    "            dfAllLst={};dfColors1=[];dfColors2=[]\n",
    "            #immGenesDict['Purity Scores']='Purity Scores'\n",
    "            immGenesDict['Heat Scores']='Heat Scores'\n",
    "            for non, df in dfLst2:\n",
    "                for col in df.columns:\n",
    "                    if not 'Purity' in col:\n",
    "                        if (not onlyKobe) or (non in kobeGenes and col in kobeGenes):\n",
    "                            if not non in seenNonLst:\n",
    "                                seenNonLst.append(non)\n",
    "                            if not col in seenImmLst:\n",
    "                                seenImmLst.append(col)\n",
    "                            ser=df[col]\n",
    "                            dfAllLst[non+', '+col]=ser\n",
    "                            if onlyKobe:\n",
    "                                dfColors1.append(non)\n",
    "                                dfColors2.append(col)\n",
    "                            else:\n",
    "                                dfColors1.append(nonGenesDict[non])\n",
    "                                dfColors2.append(immGenesDict[col])\n",
    "            print(len(seenImmLst))\n",
    "                            \n",
    "            colors2=['red','orange','maroon','tomato','darksalmon','sienna','coral','pink','gold','yellow','fuchsia','brown']\n",
    "            colors2.extend(['orangered','crimson','black'])\n",
    "            colors1=['blue','green','gray','olive','cyan','gold','palegreen','teal','dodgerblue','lightskyblue','deepskyblue']\n",
    "            colors1.extend(['skyblue','steelblue','darkseagreen','violet','purple'])\n",
    "            colors1Dict=dict(zip(set(dfColors1),colors1))\n",
    "            colors2Dict=dict(zip(set(dfColors2),colors2))\n",
    "            colorLst1=[];colorLst2=[]\n",
    "            for path in dfColors1:\n",
    "                colorLst1.append(colors1Dict[path])\n",
    "            for path in dfColors2:\n",
    "                colorLst2.append(colors2Dict[path])\n",
    "            dfAll = pd.DataFrame.from_dict(dfAllLst)\n",
    "            colors=(dfColors1,colors1Dict,dfColors2,colors2Dict)\n",
    "            addTitle = ', # Pairs '+str(len(dfAll.columns))+', # NonImmune '+str(len(seenNonLst))\n",
    "            tittleFront='NonImmune'\n",
    "            if onlyKobe:\n",
    "                titleFront='Only Kobe NonImmune'\n",
    "            spltNum,spltLst = helpPlotClusterNonImm(titleFront,df=dfAll,path='',version=version,size=size,metric=metric,\n",
    "                                                    show=False,addTitle2=addTitle,legendTitle='Genes',\n",
    "                                                    spltLst=[],spltNum=0,allDf=True,Colors=colors)\n",
    "            geneOutLst=[]\n",
    "            if spltNum > 2:\n",
    "                name=spltLst[0].replace(' Part 1','').replace('.pdf','')\n",
    "                __mergePDFs(spltLst,name,erase=True);spltLst=[name+'.pdf']\n",
    "            geneOutLst.extend(spltLst);path=path.replace('/','-')\n",
    "            pathTitle='All NonImm Imm Gene Pairings'\n",
    "            if onlyKobe:\n",
    "                'All Kobe NonImm Imm Gene Pairings'\n",
    "            name='Graphs/'+pathTitle+', v'+str(version)+', cosine, Neg Corr '+str(negThres)+' in '\n",
    "            name+=str(numCancers)+' Cancer Areas in '+str(numCancers)+' Imm Genes'\n",
    "            __mergePDFs(geneOutLst,name,erase=True)\n",
    "            dfAll.to_excel(name+'.xlsx')\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BNLearnCleanLists(frm,immGenesDict,nonGenesDict,immOrNonLst):\n",
    "    if frm in immGenesDict:\n",
    "        immOrNonLst.append(' Immune, '+immGenesDict[frm])\n",
    "    else:\n",
    "        if frm in nonGenesDict:\n",
    "            immOrNonLst.append('Non-Immune, '+nonGenesDict[frm])\n",
    "        else:\n",
    "            immOrNonLst.append(frm)\n",
    "    return 1\n",
    "def cleanBNLearn(directory='Run BNLearn/Outputs/*Sparse.*',cleaned=True,pruned=True):\n",
    "    immGenesDict,nonGenesDict,immuneGenes,nonGenes = getImmandNonDict()\n",
    "    dfLst=[]\n",
    "    immuneGenesNameDict={}\n",
    "    immuneGenesNameDict['Purity.Scores']='Puirty Scores';immuneGenesNameDict['Heat.Scores']='Heat Scores'\n",
    "    for imm in immuneGenes:\n",
    "        path=immGenesDict[imm].split(' ')[0]\n",
    "        immuneGenesNameDict[imm]=imm+'_'+path\n",
    "        \n",
    "    for file in glob.glob(directory):\n",
    "        df = pd.read_csv(file,index_col=0)\n",
    "        df=df[df['strength']>0.3]\n",
    "        df=df[df['direction']>0.5]\n",
    "        file=file.replace('.csv',', Cleaned.csv')\n",
    "        immOrNonLstFrm=[];immOrNonLstTo=[]\n",
    "        for row in df.index:\n",
    "            frm=df.loc[row]['from'].replace('.','-')\n",
    "            to=df.loc[row]['to'].replace('.','-')\n",
    "            BNLearnCleanLists(frm,immGenesDict,nonGenesDict,immOrNonLstFrm)\n",
    "            BNLearnCleanLists(to,immGenesDict,nonGenesDict,immOrNonLstTo)     \n",
    "        df.insert(2,'To Type',immOrNonLstTo)\n",
    "        df.insert(1,'From Type',immOrNonLstFrm)\n",
    "        if cleaned:\n",
    "            df.to_csv(file)\n",
    "\n",
    "        keepLst=[]\n",
    "        for i in df.index:\n",
    "            val=False\n",
    "            frmType=df.loc[i]['From Type'];toType=df.loc[i]['To Type']\n",
    "            if 'Non-Imm' in frmType and ' Immune' in toType:\n",
    "                val=True\n",
    "            else:\n",
    "                if ('Heat' in frmType or 'Heat' in toType) or ('Cancer' in frmType or 'Cancer' in toType):\n",
    "                    val=True\n",
    "            if val:\n",
    "                keepLst.append(i)\n",
    "        df2 = df.loc[keepLst]\n",
    "        file=file.replace('Cleaned','Pruned')\n",
    "        if pruned:\n",
    "            df2.to_csv(file)\n",
    "    return 1\n",
    "\n",
    "def fasterOmniConnection(geneLst):\n",
    "    splt=int(round(len(geneLst)/800,0))\n",
    "    if splt:\n",
    "        dfLst=[]\n",
    "        for i in range(splt):\n",
    "            gLst = geneLst[i*800:i+1*800]\n",
    "            gS = ','.join(gLst)\n",
    "            df=fasterOmniConnectionHelper(gS)\n",
    "            if type(df)==pd.core.frame.DataFrame:\n",
    "                dfLst.append(df)\n",
    "        if len(dfLst)>0:\n",
    "            dfAll = pd.concat(dfLst)\n",
    "            dfAll.index=range(len(dfAll.index))\n",
    "        else:\n",
    "            dfAll = False\n",
    "        return dfAll\n",
    "    else:\n",
    "        gS = ','.join(geneLst)\n",
    "        df=fasterOmniConnectionHelper(gS)\n",
    "        if type(df)==pd.core.frame.DataFrame:\n",
    "            dfAll=df\n",
    "        else:\n",
    "            dfAll=False\n",
    "    return dfAll\n",
    "def fasterOmniConnectionHelper(gS):\n",
    "    try:\n",
    "        OmniPathURL='https://omnipathdb.org/interactions/?genesymbols=1&sources='+gS\n",
    "        OmniPathURL+='&fields=sources,references'\n",
    "        __r = requests.get(OmniPathURL);page = str(__r.content);df=__OmniPathHelperFunc(page)\n",
    "        return df\n",
    "    except:\n",
    "        return fasterOmniConnectionHelper(gS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOmnipathPathsFaster(sourceGene,targetGene,directory,maxSteps,useYellow=False,recivers=[]):\n",
    "    name=directory+'/'+sourceGene+' '+targetGene+'.xlsx';name=name.replace(' -> ',' ')\n",
    "    if os.path.exists(name):\n",
    "        out=(False,[],sourceGene)\n",
    "    else:\n",
    "        useYellow=not(useYellow)\n",
    "        doneLst=[targetGene]\n",
    "        gLst=[sourceGene]\n",
    "        rowsDict={};connectionsDict={}\n",
    "        foundTarget=False;foundYellow=False\n",
    "        for num in range(maxSteps):\n",
    "            gLst = [i for i in gLst if not i in doneLst]\n",
    "            df = fasterOmniConnection(gLst)\n",
    "            if type(df)==pd.core.frame.DataFrame:\n",
    "                for row in df.index:\n",
    "                    ser=df.loc[row]\n",
    "                    surce = ser['source_genesymbol']\n",
    "                    targ = ser['target_genesymbol']\n",
    "                    if not surce in doneLst and surce != targetGene:\n",
    "                        rowsDict[(surce,targ)]=ser\n",
    "                        if surce in connectionsDict:\n",
    "                            connectionsDict[surce].append(targ)\n",
    "                        else:\n",
    "                            connectionsDict[surce]=[targ]\n",
    "                doneLst.extend(gLst)\n",
    "                if any(reciv in list(df['target_genesymbol']) for reciv in recivers):\n",
    "                    foundYellow=True\n",
    "                if targetGene in list(df['target_genesymbol']):\n",
    "                    foundTarget=True\n",
    "                gLst=list(df['target_genesymbol'])\n",
    "            else:break\n",
    "        if foundTarget and (foundYellow or useYellow):\n",
    "            out=recurFindConnections(sourceGene,targetGene,connectionsDict,rowsDict,maxSteps)\n",
    "        else:out=(False,[],sourceGene)\n",
    "    return out\n",
    "def cleanOmniConnectionLst(lst):\n",
    "    while True:\n",
    "        out=[];allGood=True;n=-1\n",
    "        for i in range(len(lst)-1):\n",
    "            n=i;_,g1 = lst[i];g2,__= lst[i+1]\n",
    "            if g1 != g2:allGood=False\n",
    "            else:out.append(lst[i])\n",
    "        out.append(lst[n+1])\n",
    "        if allGood:break\n",
    "        lst = out\n",
    "    return out\n",
    "def getBottomLst(lst):\n",
    "    if type(lst[0])==list and len(lst)==1:\n",
    "        return getBottomLst(lst[0])\n",
    "    else:\n",
    "        return lst\n",
    "def recurFindConnections(startG,findG,connectionsDict,rowsDict,maxNum):\n",
    "    return recurFindConnectionsHelper(startG,findG,connectionsDict,rowsDict,lst=[],doneLst=[findG],maxNum=maxNum)\n",
    "def recurFindConnectionsHelper(gene,findG,connectionsDict,rowsDict,lst,doneLst,num=0,maxNum=4):\n",
    "    if num > maxNum or not gene in connectionsDict:\n",
    "        return False,[], findG\n",
    "    else:\n",
    "        doneLst.append(gene)\n",
    "        if findG in connectionsDict[gene]:\n",
    "            lst.append((gene,findG))\n",
    "            lst = cleanOmniConnectionLst(lst)\n",
    "            rowsLst=[]\n",
    "            for g1,g2 in lst:\n",
    "                rowsLst.append(rowsDict[(g1, g2)])\n",
    "            return True, rowsLst,findG\n",
    "        else:\n",
    "            num+=1\n",
    "            outLst=[]\n",
    "            for i in connectionsDict[gene]:\n",
    "                if not i in doneLst:\n",
    "                    lst.append((gene,i))\n",
    "                    val, out, g = recurFindConnectionsHelper(gene=i,findG=findG,connectionsDict=connectionsDict,\n",
    "                                                             rowsDict=rowsDict,lst=lst,doneLst=doneLst,num=num)\n",
    "                    if val:\n",
    "                        outLst.append(out)\n",
    "                    else:\n",
    "                        lst=lst[:-1]\n",
    "                else:\n",
    "                    val=False\n",
    "            if len(outLst)>0:\n",
    "                return True,outLst,findG\n",
    "            else:\n",
    "                return False,[],findG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def runOmniSearch(maxSteps,useRecivers=False,directory='TF Anaylsis/Avi Results/Omni Inputs/'):\n",
    "    maxSteps -=1\n",
    "    recivers=[]\n",
    "    if useRecivers:\n",
    "        dfRec=pd.read_csv('OmniPath Ligands Transmitters and Receivers.csv',index_col=0)\n",
    "        dfRec1=set(dfRec[dfRec['receiver']].index)\n",
    "        dfRec2=set(dfRec[dfRec['transmitter']].index)\n",
    "        keepList = list(set(dfRec1.union(dfRec2)))\n",
    "        dfRec=dfRec.loc[keepList]\n",
    "        recivers2=list(dfRec['genesymbol'].dropna())\n",
    "        recivers2=list(set(recivers2))\n",
    "        for i in recivers2:\n",
    "            if ':' in i:\n",
    "                lst = i.split(':')[1].split('_')\n",
    "                recivers.extend(lst)\n",
    "            else:\n",
    "                recivers.append(i)\n",
    "    globDir =directory+'*'\n",
    "    outPutDict={}\n",
    "    for file in tq(glob.glob(globDir),desc='Overall'):\n",
    "        df=pd.read_excel(file,index_col=0)\n",
    "        if len(df.index)>0:\n",
    "            place=file.split('\\\\')[-1].split(',')[0]\n",
    "            dfImm = df[df['Target Immune Kinase Likely Immune']]\n",
    "            inputs = tq(set(df['Connection']),desc=place)\n",
    "            countDict={}\n",
    "            for connect in inputs:\n",
    "                count=0\n",
    "                dfCliq=df[df['Connection']==connect]\n",
    "                dfCliqSource = dfCliq[dfCliq['Source NonImmune Kinase Likely Immune']==False]\n",
    "                dfCliqTarg = dfCliq[dfCliq['Target Immune Kinase Likely Immune']]\n",
    "                sourceKin = list(dfCliqSource['Source NonImmune Kinases'].dropna())\n",
    "                targetKin = list(dfCliqTarg['Target Immune Kinases'].dropna())\n",
    "                totalPathsLst=[];pathLenLst=[];yellowNumsLst=[];isYellowLst=[]\n",
    "                if len(sourceKin)>0 and len(targetKin)>0:\n",
    "                    directory='TF Anaylsis/Outputs/OmniPaths/'+str(maxSteps+1)+' Steps'\n",
    "                    if not os.path.exists(directory):os.makedirs(directory)\n",
    "                    directory+='/'+place\n",
    "                    if not os.path.exists(directory):os.makedirs(directory)\n",
    "                    outDict={}                \n",
    "                    for sourceG in sourceKin:\n",
    "                        geneInputs=targetKin\n",
    "                        out = Parallel(n_jobs=10)(delayed(findOmnipathPathsFaster)(sourceG,targetG,maxSteps=maxSteps,\n",
    "                                                                                   directory=directory,\n",
    "                                                                                   useYellow=useRecivers,recivers=recivers)\n",
    "                                                  for targetG in geneInputs)\n",
    "                        for tup in out:\n",
    "                            if tup:\n",
    "                                val,path,g = tup\n",
    "                                name=directory+'/'+sourceG+' '+g+'.xlsx';name=name.replace(' -> ',' ')\n",
    "                                if val and not os.path.exists(name):\n",
    "                                    dfAll=recurGetSer(path)\n",
    "                                    if len(dfAll.index)>0:\n",
    "                                        count+=1\n",
    "                                        dfAll,totalPaths,pathLens,yellowNums,isYellows=cleanupOmniDf(dfAll,recivers,g)\n",
    "                                        dfAll.to_excel(name)\n",
    "                                        totalPathsLst.append(totalPaths);pathLenLst.extend(pathLens)\n",
    "                                        yellowNumsLst.extend(yellowNums);isYellowLst.extend(isYellows)\n",
    "                possiblePaths=len(sourceKin)*len(targetKin)                       \n",
    "                countDict[connect]=(count,sourceKin,targetKin,totalPathsLst,pathLenLst,yellowNumsLst,isYellowLst)\n",
    "            \n",
    "            #saveCount = pd.DataFrame.from_dict(countDict,orient='index',\n",
    "            #                                   columns=['# Kinase Pairs with at least 1 Path','# Total Kinase Pairs'])\n",
    "            #countTitle='TF Anaylsis/Outputs/OmniPaths/'+str(maxSteps+1)\n",
    "            #countTitle+=' Steps/'+place+' Number of gene pairs with paths and ligand recivers in each clique match'\n",
    "            #saveCount.to_csv(countTitle)\n",
    "            outPutDict[place]=(len(inputs),countDict)\n",
    "    return outPutDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanupOmniDf(dfAllIn,recivers,targetGene):\n",
    "    dfAll=dfAllIn.copy()\n",
    "    foundLst = list(dfAll[dfAll['target_genesymbol']==targetGene].index)\n",
    "    nName=0\n",
    "    groupLst=[]\n",
    "    pathLen=[]\n",
    "    frst=True\n",
    "    for n in range(len(foundLst)):\n",
    "        if frst:\n",
    "            elem = foundLst[n]\n",
    "            pathLen.append(elem)\n",
    "            for i in range(elem+1):\n",
    "                groupLst.append(n)\n",
    "            frst=False\n",
    "        else:\n",
    "            elem=foundLst[n]\n",
    "            elemPrev=foundLst[n-1]\n",
    "            pathLen.append(elem-elemPrev)\n",
    "            for i in range(elemPrev+1,elem+1):\n",
    "                groupLst.append(n)\n",
    "        nName+=1\n",
    "    dfAll.insert(0,'Path Group',groupLst)\n",
    "    totalPaths = nName\n",
    "    yellowNumLst,isYellowLst=countYellowsinOmniPaths(dfAll,recivers)\n",
    "    return dfAll,totalPaths,pathLen,yellowNumLst,isYellowLst\n",
    "\n",
    "def countYellowsinOmniPaths(dfAll,recivers):\n",
    "    yellowNumLst=[];isYellowLst=[]\n",
    "    for i in set(list(dfAll['Path Group'])):\n",
    "        dfPath=dfAll[dfAll['Path Group']==i]\n",
    "        yellowNum=0\n",
    "        for elem in list(dfPath['target_genesymbol']):\n",
    "            if elem in recivers:\n",
    "                yellowNum+=1\n",
    "        yellowNumLst.append(yellowNum)\n",
    "        isYellowLst.append(yellowNum > 0)\n",
    "    return yellowNumLst,isYellowLst\n",
    "\n",
    "def createAndRunOmniSearch(corVal=-0.3,thres=0.01,tfs=False,globDir='Run BNLearn/Inputs/*Clique*',runOmni=False):\n",
    "    useFile=False;file=''\n",
    "    inputsLst=glob.glob(globDir)\n",
    "    useLst = ['c2.cp','h.all']\n",
    "    fullDict = getFullDict(outputLst=False,useLst=useLst)\n",
    "    blDict2=getBlDict2(fullDict,removeExtra=True)\n",
    "    for file in tq(inputsLst,desc='Overall'):\n",
    "        place=file.split(',')[-2].split('N =')[0].strip()\n",
    "        immDf=getCliqueDf(file,immOrNon='Immune');nonDf=getCliqueDf(file,immOrNon='Non-Immune')\n",
    "        corr=__getCorrInputsLst([file],clique=True)\n",
    "        df=pd.read_csv(file,index_col=0,sep='\\t')\n",
    "        df.columns=corr.columns\n",
    "        pair1Lst=[];pair2Lst=[];pairLst=[]\n",
    "        for col in corr.columns:\n",
    "            for col2 in corr.index:\n",
    "                if 'Heat' not in col and 'Heat' not in col2:\n",
    "                    if ('Non' in col and 'Non' not in col2):\n",
    "                        corValCheck=corr.loc[col][col2]\n",
    "                        if corValCheck < corVal:\n",
    "                            pair1Lst.append(col);pair2Lst.append(col2)\n",
    "                            pairLst.append((col,col2))\n",
    "        pair1Set=list(set(pair1Lst));pair2Set=list(set(pair2Lst))\n",
    "        aviRunLst=list(pair1Set)+list(pair2Set)\n",
    "        inputs=aviRunLst\n",
    "        outDict={}\n",
    "        out=Parallel(n_jobs=7,backend=\"threading\")(delayed(__parallelRunAvi)\n",
    "                                                   (imm,immDf,nonDf,useFile=useFile,file=file,outDict=outDict,\n",
    "                                                    tfs=tfs,place=place) for imm in inputs)\n",
    "        print(len(outDict),len(pairLst))\n",
    "        createOmniInputFile(outDict=outDict,pairLst=pairLst,nonDf=nonDf,place=place,corVal=corVal,\n",
    "                            fullDict=fullDict,includeNumKinase=True,thres=thres)\n",
    "    if runOmni:\n",
    "        x=1\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotKinasePairsHM(directory='TF Anaylsis/Outputs/OmniPaths/10 Steps/Lung adenocarcinoma/*'):\n",
    "    recivers=[]\n",
    "    dfRec=pd.read_csv('OmniPath Ligands Transmitters and Receivers.csv',index_col=0)\n",
    "    dfRec1=set(dfRec[dfRec['receiver']].index)\n",
    "    dfRec2=set(dfRec[dfRec['transmitter']].index)\n",
    "    keepList = list(set(dfRec1.union(dfRec2)))\n",
    "    dfRec=dfRec.loc[keepList]\n",
    "    recivers2=list(dfRec['genesymbol'].dropna())\n",
    "    recivers2=list(set(recivers2))\n",
    "    for i in recivers2:\n",
    "        if ':' in i:\n",
    "            lst = i.split(':')[1].split('_')\n",
    "            recivers.extend(lst)\n",
    "        else:\n",
    "            recivers.append(i)\n",
    "\n",
    "    files = glob.glob(directory)\n",
    "    lungApairLst=[]\n",
    "    for file in tq(files,desc='Finding Kinase Pairs'):\n",
    "        genes=file.split('\\\\')[-1].replace('.xlsx','').split()\n",
    "        try:\n",
    "            df = pd.read_excel(file,index_col=0)\n",
    "            if any(reciv in list(df['target_genesymbol']) for reciv in recivers):\n",
    "                lungApairLst.append((genes[0],genes[1]))\n",
    "        except:\n",
    "            os.remove(file)\n",
    "    dfLst=[]\n",
    "    for folder in glob.glob('TF Anaylsis/Avi Results/Omni Inputs/*'):\n",
    "        if not '~$' in folder:\n",
    "            place = folder.split('\\\\')[-1].split(',')[0]\n",
    "            try:\n",
    "                dfPlace = pd.read_excel(folder,index_col=0)\n",
    "                if len(dfPlace.index)>0:\n",
    "                    dfLst.append((place,dfPlace))\n",
    "            except:\n",
    "                bad=1\n",
    "\n",
    "    placeDict={}\n",
    "    placeLst1=[]\n",
    "    for place, dfPlace in tq(dfLst,desc='Counting # of Cancers'):\n",
    "        sourceKinLst=[];targetKinLst=[]\n",
    "        inputs = set(dfPlace['Connection'])\n",
    "        place = place.replace('and ','')\n",
    "        placeLst1.append(place)\n",
    "        for connect in inputs:\n",
    "            dfCliq=dfPlace[dfPlace['Connection']==connect]\n",
    "            dfCliqSource = dfCliq[dfCliq['Source NonImmune Kinase Likely Immune']==False]\n",
    "            try:\n",
    "                dfCliqTarg = dfCliq[dfCliq['Target Immune Kinase Likely Immune']]\n",
    "            except:\n",
    "                dfCliqTarg = dfCliq[dfCliq['Target Immune Kinase Likely Immune']==1]\n",
    "            sourceKin = list(dfCliqSource['Source NonImmune Kinases'].dropna())\n",
    "            targetKin = list(dfCliqTarg['Target Immune Kinases'].dropna())\n",
    "\n",
    "            sourceKinLst.extend(sourceKin);targetKinLst.extend(targetKin)\n",
    "        sourceKinLst=set(sourceKinLst);targetKinLst=set(targetKinLst)\n",
    "        for source,target in lungApairLst:\n",
    "            if source in sourceKinLst and target in targetKinLst:val=1\n",
    "            else:val=0\n",
    "            if (source+' -> '+target) in placeDict:placeDict[(source+' -> '+target)].append(val)\n",
    "            else:placeDict[(source+' -> '+target)]=[val]\n",
    "    plotDf = pd.DataFrame.from_dict(placeDict,orient='index',columns=placeLst1)\n",
    "    plotDf=plotDf.T\n",
    "\n",
    "    c1Lst=[]\n",
    "    for place in plotDf.index:\n",
    "        if any(c in place for c in c1):\n",
    "            c1Lst.append(place)\n",
    "    c1Df= plotDf.loc[c1Lst]\n",
    "    indxLst=list(c1Df.sum()[c1Df.sum() >= 2].index)\n",
    "    plotAllC1=plotDf[indxLst]\n",
    "\n",
    "    indxLst=list(plotDf.sum()[plotDf.sum() >= 12].index)\n",
    "    plot12Can=plotDf[indxLst]\n",
    "\n",
    "    indxLst=list(plotDf.sum()[plotDf.sum() >= 14].index)\n",
    "    plot14Can=plotDf[indxLst]\n",
    "    plotLst=[(plotDf,'All '+str(len(plotDf.columns))+' Kinase Pairs in Lung Aderno',0),\n",
    "             (plot14Can,str(len(plot14Can.columns))+' Kinase Pairs in at least 14 Cancers',1),\n",
    "             (plot12Can,str(len(plot12Can.columns))+' Kinase Pairs in at least 12 Cancers',1),\n",
    "             (plotAllC1,str(len(plotAllC1.columns))+' Kinase Pairs in 2 C1 Cancers',1)]\n",
    "\n",
    "    for df, title,xticks in tq(plotLst,desc='plotting'):\n",
    "        if len(df.columns)>0:\n",
    "            try:\n",
    "                cg = sb.clustermap(df,cmap='YlGn',standard_scale=None,metric='cosine',vmin=0,vmax=1,\n",
    "                                   yticklabels=1,xticklabels=xticks,row_cluster=False)\n",
    "                plt.setp(cg.ax_heatmap.get_xticklabels(),size=6,rotation=45,ha='right')\n",
    "                plt.setp(cg.ax_heatmap.get_yticklabels(),rotation=45,va='bottom')\n",
    "                cg.ax_heatmap.set_ylabel('Cancers');cg.ax_heatmap.set_xlabel('Kinase Pairs')\n",
    "                cg.fig.suptitle(title)\n",
    "                plt.savefig(title+'.png')\n",
    "                plt.show()\n",
    "            except:\n",
    "                print(df);tr=ty\n",
    "    return plot12Can,plotAllC1,plotDf,plot14Can\n",
    "def onlyInhibitors(df):\n",
    "    cols = [i for i in df.columns if 'Inhibitor' in i]\n",
    "    df2 = df[cols]\n",
    "    keepLst=[]\n",
    "    for i in df2.index:\n",
    "        row=df2.loc[i]\n",
    "        lst=list(row.values)\n",
    "        for j in range(len(lst)):\n",
    "            if '' in lst:\n",
    "                lst.remove('')\n",
    "        summ=0\n",
    "        for elem in lst:\n",
    "            if elem:\n",
    "                summ+=1\n",
    "                break\n",
    "        if summ > 0:\n",
    "            keepLst.append(i)\n",
    "    dfOut = df.loc[keepLst]\n",
    "    return dfOut\n",
    "def createFullOmniCSV(lst):\n",
    "    outDict={}\n",
    "    name2=0\n",
    "    for i in tq(lst,desc='Creating CSV'):\n",
    "        g1,g2 = i.split(' -> ')\n",
    "        fileName = 'TF Anaylsis/Outputs/OmniPaths/10 Steps/Lung adenocarcinoma/'+g1+' '+g2+'.xlsx'\n",
    "        path = pd.read_excel(fileName,index_col=0)\n",
    "        name2=int(name2);name2 +=1;name2=str(name2)\n",
    "        paths=set(path['Path Group'])\n",
    "        inputs = zip(paths,range(len(paths)))\n",
    "        out = Parallel(n_jobs=7,backend=\"threading\")(delayed(__superOmniCSVHelper)(path,group,outDict,name,name2,g2)\n",
    "                                                     for group,name in inputs)\n",
    "    fullCSV = getFullOmniDF(outDict)\n",
    "    fullCSV = addinDBtoOmni(fullCSV)\n",
    "    fullCSV = noRepeatsFullCSV(fullCSV)\n",
    "    onlyInhib = onlyInhibitors(fullCSV)\n",
    "    return fullCSV,onlyInhib\n",
    "def getFullOmniDF(outDict):\n",
    "    maxx=0\n",
    "    for i in outDict:\n",
    "        num = len(outDict[i])\n",
    "        if num > maxx:\n",
    "            maxx = num\n",
    "    for i in outDict:\n",
    "        lst = outDict[i]\n",
    "        for n in range(maxx-len(lst)):\n",
    "            lst.append('')\n",
    "        outDict[i]=lst\n",
    "    fullCSV = pd.DataFrame.from_dict(outDict, orient='index')\n",
    "    numGenes = int(len(fullCSV.columns)/4)\n",
    "    colLst=[]\n",
    "    for i in range(numGenes):\n",
    "        cols=['Kinase '+str(i),str(i)+' InterCell',str(i)+' Likely Immune',str(i)+' Inhibitor']\n",
    "        colLst.extend(cols)\n",
    "    fullCSV.columns = colLst\n",
    "    fullCSV.index = range(len(fullCSV.index))\n",
    "    return fullCSV\n",
    "\n",
    "def noRepeatsFullCSV(fullCSV):\n",
    "    geneCols=[]\n",
    "    for i in fullCSV.columns:\n",
    "        if 'Kinase' in i:\n",
    "            geneCols.append(i)\n",
    "    genes=fullCSV[geneCols]\n",
    "\n",
    "    keepDict={}\n",
    "    for i in genes.index:\n",
    "        row=genes.loc[i]\n",
    "        name=''\n",
    "        for elem in row:\n",
    "            if not elem is np.nan:\n",
    "                name+=','+str(elem)\n",
    "        keepDict[name]=i\n",
    "    fullCSV = fullCSV.loc[list(keepDict.values())]\n",
    "    fullCSV.index = range(len(fullCSV.index))\n",
    "    return fullCSV\n",
    "\n",
    "def getReciversLst():\n",
    "    recivers=[];transmitters=[];both=[]\n",
    "    dfRec=pd.read_csv('OmniPath Ligands Transmitters and Receivers.csv',index_col=0)\n",
    "    dfRec1=set(dfRec[dfRec['receiver']].index)\n",
    "    dfRec2=set(dfRec[dfRec['transmitter']].index)\n",
    "    keepList = list(set(dfRec1.union(dfRec2)))\n",
    "    dfRecB=dfRec.loc[keepList]\n",
    "    recivers2=list(dfRecB['genesymbol'].dropna())\n",
    "    recivers2=list(set(recivers2))\n",
    "    for i in recivers2:\n",
    "        if ':' in i:\n",
    "            lst = i.split(':')[1].split('_')\n",
    "            both.extend(lst)\n",
    "        else:\n",
    "            both.append(i)\n",
    "    dfRec1 = dfRec.loc[dfRec1]\n",
    "    recivers2=list(dfRec1['genesymbol'].dropna())\n",
    "    recivers2=list(set(recivers2))\n",
    "    for i in recivers2:\n",
    "        if ':' in i:\n",
    "            lst = i.split(':')[1].split('_')\n",
    "            recivers.extend(lst)\n",
    "        else:\n",
    "            recivers.append(i)\n",
    "    dfRec2 = dfRec.loc[dfRec2]        \n",
    "    recivers2=list(dfRec2['genesymbol'].dropna())\n",
    "    recivers2=list(set(recivers2))\n",
    "    for i in recivers2:\n",
    "        if ':' in i:\n",
    "            lst = i.split(':')[1].split('_')\n",
    "            transmitters.extend(lst)\n",
    "        else:\n",
    "            transmitters.append(i)\n",
    "    return both,recivers,transmitters\n",
    "\n",
    "def __superOmniCSVHelper(path,group,outDict,name,name2,g2):\n",
    "    pathGroup = path[path['Path Group']==group]\n",
    "    both,recivers,transmitters = getReciversLst()\n",
    "    immuneLst=getImmuneLst()\n",
    "    groupLst=[]\n",
    "    last=False\n",
    "    for i in pathGroup.index:\n",
    "        row=pathGroup.loc[i]\n",
    "        if row['target_genesymbol']==g2:\n",
    "            last=True\n",
    "        kinase = row['source_genesymbol']\n",
    "\n",
    "        isYellow=''\n",
    "        if kinase in transmitters:isYellow+= 'Is an InterCell Transmitter'\n",
    "        if kinase in both:isYellow+=' and '\n",
    "        if kinase in recivers:isYellow+= 'Is an InterCell Reciver'\n",
    "\n",
    "        isImmune=False\n",
    "        if kinase in immuneLst:\n",
    "            isImmune=True\n",
    "        inhibitor=row['is_inhibition'].value\n",
    "        lst=[kinase,isYellow,isImmune,inhibitor]\n",
    "        if last:\n",
    "            isYellow=''\n",
    "            if g2 in transmitters:isYellow+= 'Is an InterCell Transmitter'\n",
    "            if g2 in recivers and g2 in transmitters:isYellow+=' and '\n",
    "            if g2 in recivers:isYellow+= 'Is an InterCell Reciver'\n",
    "            isImmune = g2 in immuneLst\n",
    "            lst.extend([g2,isYellow,isImmune,False])\n",
    "        groupLst.extend(lst)\n",
    "        outDict[str(name2)+' '+str(name)+' '+str(i)]=groupLst\n",
    "    return\n",
    "def addinDBtoOmni(dfIn):\n",
    "    df=dfIn.copy()\n",
    "    useLst = ['c2.cp','h.all']\n",
    "    fullDict = getFullDict(outputLst=False,useLst=useLst)\n",
    "\n",
    "    geneDict={}\n",
    "    for path in fullDict:\n",
    "        lst=fullDict[path]\n",
    "        for elem in lst:\n",
    "            if elem in geneDict:\n",
    "                geneDict[elem].append(path)\n",
    "            else:\n",
    "                geneDict[elem]=[path]\n",
    "    cols =[i for i in df.columns if 'Kinase' in i]\n",
    "    dfCols=df[cols]\n",
    "    n=0\n",
    "    n2=0\n",
    "    odd=True\n",
    "    lstLst=[];n3=0\n",
    "    for col in dfCols.columns:\n",
    "        n+=4;n+=n3;kLst=[]\n",
    "        genes=list(dfCols[col])\n",
    "        for g in genes:\n",
    "            if g in geneDict:kLst.append(geneDict[g])\n",
    "            else:kLst.append('')\n",
    "        lstLst.append((n,kLst,n2))\n",
    "        n2+=1\n",
    "        if odd:n3=1\n",
    "        else:n3=0\n",
    "    for insert,lst,n2 in lstLst:df.insert(insert,str(n2)+' Databases',lst)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of colorLst input colorLst=[('set312',12),('pastel28',8)]\n",
    "# a list of tuples, where the first element tells which color scheme you want to use, \n",
    "# and the 2nd element tells the length of unique colors in that color shceme\n",
    "# color scheme names refer to these colors: http://graphviz.org/doc/info/colors.html\n",
    "# 'Heat' and 'Purity' do not need to be included in immGenesDict or nonGenesDict\n",
    "def getUseandColorDict(colorLst,immGenesDict={},nonGenesDict={},defaultDicts=True):\n",
    "    if defaultDicts:\n",
    "        immGenesDict,nonGenesDict,immuneGenes,nonGenes = getImmandNonDict()\n",
    "    useDict={}\n",
    "    dicLst=[immGenesDict,nonGenesDict]\n",
    "    for dic in dicLst:\n",
    "        for i in dic:\n",
    "            elem = dic[i]\n",
    "            i=i.replace('-','')\n",
    "            useDict[i]=elem\n",
    "    useDict['Heat']='Heat';useDict['Purity']='Purity'\n",
    "    useDict['CancerArea']='Cancer Area'\n",
    "    colorDict={}\n",
    "    for elem in set(immGenesDict.values()):\n",
    "        colorDict[elem]=(0,'red')\n",
    "    n=1;colorNum=0\n",
    "    colorTup=colorLst[colorNum]\n",
    "    colorSchemeName,colorLen=colorTup\n",
    "    for i in set(nonGenesDict.values()):\n",
    "        colorDict[i]=(n,colorSchemeName)\n",
    "        n+=1\n",
    "        if n > colorLen:\n",
    "            n=1\n",
    "            colorNum+=1\n",
    "            colorTup=colorLst[colorNum]\n",
    "            colorSchemeName,colorLen=colorTup\n",
    "    colorDict['Heat']=(0,'orangered');colorDict['Purity']=(0,'grey');colorDict['Cancer Area']=(0,'aliceblue')\n",
    "    return useDict,colorDict\n",
    "\n",
    "def nonPathsplotBNimmuneNonHMsHelper(dfLst,nonGenes,immuneGenes):\n",
    "    pairDict={};frst=True\n",
    "    for place,df in dfLst:\n",
    "        for non in nonGenes:\n",
    "            non2=non.replace('-','.')\n",
    "            for imm in immuneGenes:\n",
    "                df2=df[df['from']==non2] \n",
    "                df2=df2[df2['to']==imm]\n",
    "                if len(df2.index)>0:\n",
    "                    if df2['direction'].values[0]>= 0.35:\n",
    "                        strength=df2['strength'].values[0]\n",
    "                    else:\n",
    "                        strength=0\n",
    "                else:\n",
    "                    strength=0\n",
    "                if frst:\n",
    "                    pairDict[non+' --> '+imm]=[strength]\n",
    "                else:\n",
    "                    pairDict[non+' --> '+imm].append(strength)\n",
    "        frst=False\n",
    "    return pairDict\n",
    "\n",
    "\n",
    "def pathsPathsplotBNimmuneNonHMsHelperParallel(place,df,nonGenes,immuneGenes,thres,pathwaysDict,immGenesDict,\n",
    "                                               nonGenesDict,grandparents):\n",
    "    badPath = 'REACTOME_RESPIRATORY_ELECTRON_TRANSPORT_ATP_SYNTHESIS'\n",
    "    badPath2='REACTOME_PRESYNAPTIC_DEPOLARIZATION_AND_CALCIUM'\n",
    "    badPath3='WP_MITOCHONDRIAL_COMPLEX_I_ASSEMBLY_MODEL_OXPHOS'\n",
    "    placeDict={}\n",
    "    for non in nonGenes:\n",
    "        non2=non.replace('-','.')\n",
    "        for imm in immuneGenes:\n",
    "            df2=df[df['from']==non2] \n",
    "            df2=df2[df2['to']==imm]\n",
    "            if len(df2.index)>0:\n",
    "                strength=df2['strength'].values[0];direction=df2['direction'].values[0]\n",
    "            else:strength=0;direction=0\n",
    "            immPath = immGenesDict[imm]\n",
    "            try:\n",
    "                nonPath = pathwaysDict[non]\n",
    "            except:\n",
    "                nonPath = nonGenesDict[non]\n",
    "            if grandparents:\n",
    "                fullPathLst=[]\n",
    "                df3 = df[df['to']==non2]\n",
    "                if len(df3.index)>0:\n",
    "                    for ances in df3['from']:\n",
    "                        ances2=ances.replace('.','-')\n",
    "                        if ances2 in nonGenes:\n",
    "                            df4=df3[df3['from']==ances]\n",
    "                            strength3 = df4['strength'].values[0];direction3=df4['direction'].values[0]\n",
    "                            try:\n",
    "                                ancesPath = pathwaysDict[ances2]\n",
    "                            except:\n",
    "                                ancesPath = nonGenesDict[ances2]\n",
    "                            \n",
    "                            if badPath in ancesPath:\n",
    "                                ancesPath = badPath\n",
    "                            if badPath in nonPath:\n",
    "                                nonPath = badPath\n",
    "                            if badPath2 in ancesPath:\n",
    "                                ancesPath = badPath2\n",
    "                            if badPath2 in nonPath:\n",
    "                                nonPath = badPath2\n",
    "                            if badPath3 in ancesPath:\n",
    "                                ancesPath = badPath3\n",
    "                            if badPath3 in nonPath:\n",
    "                                nonPath = badPath3\n",
    "                                \n",
    "                            fullPath = ancesPath+' --> '+nonPath+' --> '+immPath\n",
    "                            fullPathLst.append((fullPath,strength,strength3,direction3))\n",
    "            else:\n",
    "                if badPath in nonPath:\n",
    "                    nonPath = badPath\n",
    "                if badPath2 in nonPath:\n",
    "                    nonPath = badPath2\n",
    "                if badPath3 in nonPath:\n",
    "                    nonPath = badPath3\n",
    "                fullPath=nonPath+' --> '+immPath\n",
    "                fullPathLst=[(fullPath,stregnth,0,0)]\n",
    "            for fullPath,stregnth1,strength2,direction2 in fullPathLst:\n",
    "                if not fullPath in placeDict:\n",
    "                    placeDict[fullPath]=0\n",
    "                if strength >= thres and direction >= 0.35:\n",
    "                    if not grandparents or (strength2 >= thres and direction2 >=0.35):\n",
    "                        placeDict[fullPath]+=1\n",
    "    return placeDict\n",
    "\n",
    "def pathsPathsplotBNimmuneNonHMsHelper(dfLst,nonGenes,immuneGenes,thres,pathwaysDict,\n",
    "                                       immGenesDict,nonGenesDict,grandparents,showProg):\n",
    "    pairDict={};frst=True\n",
    "    inputs=dfLst\n",
    "    if showProg:\n",
    "        inputs=tq(dfLst,desc='Finding Pairings')\n",
    "    dictLst = Parallel(n_jobs=7)(delayed(pathsPathsplotBNimmuneNonHMsHelperParallel)\n",
    "                                 (place,df,nonGenes,immuneGenes,thres,pathwaysDict,immGenesDict,\n",
    "                                  nonGenesDict,grandparents)\n",
    "                                 for place,df in inputs)\n",
    "    for placeDict in dictLst:\n",
    "        for pair in placeDict:\n",
    "            if frst:\n",
    "                pairDict[pair]=[placeDict[pair]]\n",
    "            else:\n",
    "                pairDict[pair].append(placeDict[pair])\n",
    "        frst=False\n",
    "    return pairDict\n",
    "\n",
    "def plotBNimmuneNonHMs(files,title,showProg=False,thres=0,pathways=False,show=False,makeExcel=False,grandparents=False,\n",
    "                       pruned=False,superPruned=False):\n",
    "    df2 = pd.read_csv('Pathways4model.csv',index_col=0);df2=df2.dropna()\n",
    "    useLst = ['c2.cp','c5.go.bp','h.all'];fullDict = getFullDict(outputLst=False,useLst=useLst);dict2={}\n",
    "    pathwaysDict={}\n",
    "    for i in df2.index:\n",
    "        if i in fullDict:\n",
    "            for gene in fullDict[i]:\n",
    "                pathwaysDict[gene]=i\n",
    "    immGenesDict,nonGenesDict,immuneGenes,nonGenes = getImmandNonDict()\n",
    "    num=0;dfLst=[]\n",
    "    for file in files:\n",
    "        place=file.split(',')[1].strip();tpy=file.split(',')[-1].replace('.csv','')\n",
    "        place+= ' '+tpy\n",
    "        df=pd.read_csv(file,index_col=0)\n",
    "        dfLst.append((place,df))\n",
    "    pLst=[]\n",
    "    for place,df in dfLst:\n",
    "        place=place.replace(' HC','').replace('Cell Carcinoma','').replace('carcinoma','')\n",
    "        pLst.append(place)\n",
    "    if pathways:\n",
    "        pairDict=pathsPathsplotBNimmuneNonHMsHelper(dfLst,nonGenes,immuneGenes,thres,pathwaysDict,\n",
    "                                                    immGenesDict,nonGenesDict,grandparents,showProg)\n",
    "    else:\n",
    "        pairDict=nonPathsplotBNimmuneNonHMsHelper(dfLst,nonGenes,immuneGenes)\n",
    "        \n",
    "    dfAll = pd.DataFrame.from_dict(pairDict,orient='index',columns=pLst)\n",
    "    dfAllKeep=dfAll.T\n",
    "    num25thPercent=0.00001\n",
    "    if pruned:\n",
    "        l=list(dfAllKeep.sum())\n",
    "        num25thPercent = sum(l)/(len(l)*0.75)\n",
    "    if superPruned:\n",
    "        l=list(dfAllKeep.sum())\n",
    "        num25thPercent = sum(l)/(len(l)*0.5)\n",
    "    keepLst=list(dfAllKeep.sum()[dfAllKeep.sum() >= num25thPercent].index)\n",
    "    dfAll = dfAll.loc[keepLst]\n",
    "    \n",
    "    if pathways:\n",
    "        nonGenesDict.update(pathwaysDict)\n",
    "    nonPaths=[];immPaths=[]\n",
    "    for genes in dfAll.index:\n",
    "        gLst = genes.split(' --> ')\n",
    "        if pathways:\n",
    "            nonPath = gLst[0]\n",
    "            immPath = gLst[1]\n",
    "        else:\n",
    "            nonPath=nonGenesDict[gLst[0]];immPath=immGenesDict[gLst[1]]\n",
    "        nonPaths.append(nonPath)\n",
    "        immPaths.append(immPath)\n",
    "    nonPaths=set(nonPaths);immPaths=set(immPaths)\n",
    "    colors2=['red','black','white']\n",
    "    colors1=['blue','green','purple','brown','pink','gray','olive','cyan','gold','palegreen','yellow','fuchsia','teal']\n",
    "    colors1.extend(['rosybrown','lightcorel','saddlebrown','goldenrod','darkgoldenrod','olivedrab','yellowgreen','turquoise'])\n",
    "    colors1.extend(['darkseagreen','darkkhaki','lawngreen','peachpuff','sandybrown','darkolivegreen','burlywood','lime'])\n",
    "    colors1.extend(['aquamarine','orchid'])\n",
    "    colorsNonDict=dict(zip(nonPaths,colors1))\n",
    "    colorsImmDict=dict(zip(immPaths,colors2))\n",
    "    \n",
    "    if grandparents:\n",
    "        ancesPaths = set(list(nonPaths)+list(immPaths))\n",
    "        colorsNonDict=dict(zip(ancesPaths,colors1))\n",
    "        colorsImmDict=dict(zip(ancesPaths,colors1))\n",
    "    \n",
    "    nonColors=[];immColors=[]\n",
    "    for genes in dfAll.index:\n",
    "        gLst = genes.split(' --> ')\n",
    "        if pathways:\n",
    "            nonColor = colorsNonDict[gLst[0]]\n",
    "            immColor = colorsImmDict[gLst[1]]\n",
    "        else:\n",
    "            nonColor=colorsNonDict[nonGenesDict[gLst[0]]];immColor=colorsImmDict[immGenesDict[gLst[1]]]\n",
    "        nonColors.append(nonColor)\n",
    "        immColors.append(immColor)\n",
    "    colors=[nonColors,immColors]\n",
    "    if not grandparents:\n",
    "        colorsNonDict.update(colorsImmDict)\n",
    "    if grandparents:\n",
    "        title=title.replace('Pairs','Grandparent Tuples')\n",
    "    if pathways:\n",
    "        cmap='Greens'\n",
    "    else:\n",
    "        cmap='Oranges'\n",
    "    try:\n",
    "        cg = sb.clustermap(dfAll,cmap=cmap,standard_scale=None,metric='cosine',vmin=0,\n",
    "                           yticklabels=0,xticklabels=1,row_colors=colors,cbar_pos=(1, 0.8, 0.05, 0.15))\n",
    "    except:\n",
    "        plt.close()\n",
    "        cg = sb.clustermap(dfAll,cmap=cmap,standard_scale=None,metric='euclidean',vmin=0,\n",
    "                           yticklabels=0,xticklabels=1,row_colors=colors,cbar_pos=(1, 0.8, 0.05, 0.15))\n",
    "    cg.ax_col_dendrogram.set_visible(False)\n",
    "    for x,y in zip(colorsNonDict.keys(),colorsNonDict.values()):\n",
    "        cg.ax_heatmap.plot(0, 0, color=y, label=x, linewidth=6, solid_capstyle=\"butt\")\n",
    "    cg.ax_heatmap.legend(loc=(1.05,0.05), title=\"Pathway\")\n",
    "    plt.setp(cg.ax_heatmap.get_xticklabels(),size=7,rotation=45,ha='right')\n",
    "    plt.setp(cg.ax_heatmap.get_yticklabels(),rotation=45,va='bottom')\n",
    "    \n",
    "    ylabel='NonImm Immune Pairs'\n",
    "    if grandparents:\n",
    "        ylabel=ylabel.replace('Pairs','Ancestor Tuples')\n",
    "    title+=' Number of Pairs '+str(len(dfAll.index))\n",
    "    cg.ax_heatmap.set_ylabel(ylabel);cg.ax_heatmap.set_xlabel('Cancers')\n",
    "    cg.fig.suptitle(title,size=10,x=0.55);figure = plt.gcf()\n",
    "    if pathways:\n",
    "        location='Graphs/Confidence above '+str(thres)+'/'+title+'.png'\n",
    "    else:\n",
    "        location='Graphs/'+title+'.png'\n",
    "    plt.savefig(location,bbox_inches=\"tight\",dpi=100)\n",
    "        \n",
    "    if show:plt.show()\n",
    "    else:plt.close()\n",
    "    title2=title.replace('HM of ','')\n",
    "    if pathways:\n",
    "        location='Graphs/Confidence above '+str(thres)+'/'+title2+' CSV version.xlsx'\n",
    "    else:\n",
    "        location='Graphs/'+title2+' CSV version.xlsx'\n",
    "    if makeExcel:dfAll.to_excel(location)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeOmniInputFilesImmune(ciber=False,union=False,directory='TF Anaylsis/Avi Results/Omni Inputs/*Lung a*'):\n",
    "    errors=''\n",
    "    immLst = getImmuneLst(ciber=ciber,union=union)\n",
    "    for file in glob.glob(directory):\n",
    "        if not '$' in file:\n",
    "            try:\n",
    "                df= pd.read_excel(file,index_col=0)\n",
    "                sourceLst=[];targetLst=[]\n",
    "                for i in df['Source NonImmune Kinases']:\n",
    "                    if i in immLst or i is np.nan:\n",
    "                        sourceLst.append(True)\n",
    "                    else:\n",
    "                        sourceLst.append(False)\n",
    "                for i in df['Target Immune Kinases']:\n",
    "                    if i in immLst or i is np.nan:\n",
    "                        targetLst.append(True)\n",
    "                    else:\n",
    "                        targetLst.append(False)\n",
    "                df['Source NonImmune Kinase Likely Immune']=sourceLst\n",
    "                df['Target Immune Kinase Likely Immune']=targetLst\n",
    "                df.to_excel(file)\n",
    "            except:\n",
    "                errors+='Unable to open file '+str(file)+'\\n'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f500fc952de4b87b73c922320e5aab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837cb1ca01c84c7c9fd292e1a5b7ac65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7d0ae0062c4b1292a0b7ccd9cb9bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca254bf717842a79b370ae66104ea8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kobePlaceLst1=kobePlaceLst(thres=30,cares=True)\n",
    "# recommened palceLsts for most functions \n",
    "placeLst=kobePlaceLst(cares=False,thres=30)\n",
    "placeLst2=kobePlaceLst(cares=False,thres=1)\n",
    "placeLst3=kobePlaceLst(cares=False,thres=105)\n",
    "\n",
    "c1=['Adrenocortical','Breast HR','Lung','Thyroid','Skin']\n",
    "c1Lst=[]\n",
    "for pl in placeLst:\n",
    "    for elem in c1:\n",
    "        if elem in pl:\n",
    "            c1Lst.append(pl)\n",
    "c1Lst=list(set(c1Lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __superOmniCSVHelperPar(i,outDict,name2):\n",
    "    g1,g2 = i.split(' ')\n",
    "    fileName = 'TF Anaylsis/Outputs/OmniPaths/10 Steps/Lung adenocarcinoma/'+g1+' '+g2+'.xlsx'\n",
    "    path = pd.read_excel(fileName,index_col=0)\n",
    "    paths=set(path['Path Group'])\n",
    "    inputs = zip(paths,range(len(paths)))\n",
    "    out = Parallel(n_jobs=7,backend=\"threading\")(delayed(__superOmniCSVHelper)(path,group,outDict,name,name2,g2)\n",
    "                                                 for group,name in inputs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fef941a28c438fb062c6c7de8be2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for v in [8]:\n",
    "    for file in tq(glob.glob('Purity/TPM/v'+str(v)+'/*')):\n",
    "        place=file.split('_')[1]\n",
    "        df=pd.read_csv(file,index_col=0,sep='\\t')\n",
    "        df,_,_ = __heatDF(df)\n",
    "        df.to_excel('Share Data/V'+str(v)+' Data/'+place+'_tpm_V'+str(v)+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
